<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[浏览器攻击]]></title>
    <url>%2F2019%2F09%2F11%2F%E6%B5%8F%E8%A7%88%E5%99%A8%E6%94%BB%E5%87%BB%2F</url>
    <content type="text"><![CDATA[浏览器跨域JavaScript出于安全方面的考虑做的同源策略的限制，不允许跨域访问其他资源。跨域请求成功后，浏览器会拦截服务器端返回的结果 同源:域名、协议、端口均相同。举例来说，`http://www.example.com/dir/page.html`这个网址，协议是`http://`，域名是`www.example.com`，端口是`80`（默认端口可以省略） CSRF攻击攻击者指挥用户攻击目标网站 graph LR user-->|1,username&password|target(目标网站) target-->|2,OK&set cookie|user user-.->|3,目标cookie存在,访问攻击者站点|tacker[攻击者站点] tacker-.->|4,让用户请求目标网站执行特定操作|user user-.->|5,利用自己的权限做攻击操作|target sequenceDiagram participant attacker as 攻击者站点 participant user as 用户 participant target as 目标站点 user->>+target:1,request,username&password target-->>user:2,response,set-cookie user->>+attacker:3,request,请求攻击者站点 attacker-->>-user:4,response,指挥用户访问目标站点 user->>-target:5,request,利用自己的权限发起攻击操作 XSS攻击伪装用户自己发起攻击 sequenceDiagram participant attacker as 攻击者站点 participant user as 用户 participant target as 目标站点 attacker-->>user:1,request,发送含有攻击代码的目标站点链接 user->>+target:2,request,携带攻击代码,请求目标站点 target-->>user:3,response,目标站点执行后返回用户数据 user->>attacker:4,request,在用户不知情时将cookie,session发送给攻击者 attacker->>-target:5,request,伪装用户访问目标站点]]></content>
      <categories>
        <category>safe</category>
      </categories>
      <tags>
        <tag>safe</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[监控系统预测和异常判断]]></title>
    <url>%2F2019%2F09%2F06%2F%E7%9B%91%E6%8E%A7%E7%B3%BB%E7%BB%9F%E9%A2%84%E6%B5%8B%E5%92%8C%E5%BC%82%E5%B8%B8%E5%88%A4%E6%96%AD%2F</url>
    <content type="text"><![CDATA[监控系统预测和异常判断基于算法的 IT 运维平台(Algorithmic IT operations platforms) 机器学习 数学统计 方差分析可以用来判断几组观察到的数据或者处理的结果是否存在显著差异。 在方差分析中，我们把要考察其均值是否存在显著差异的指标变量称为响应变量，对响应变量取值有影响的其他变量称为因素。例如，信用卡消费水平和治疗效果为响应变量，地区和药品则为因素。在方差分析中，因素的取值应为离散型的，其不同的取值称为水平。例如，每一个具体地区或者每一种药品都对应着一个水平。根据因素的个数，方差分析可以分为单因素方差分析和多因素方差分析 正态分布像一只倒扣的钟。两头低，中间高，左右对称。大部分数据集中在平均值，小部分在两端。 异常判断异常情形 少量 大量 间断 连续 周期 指数平滑法是一种特殊的加权平均法，加权的特点是对离预测值较近的历史数据给予较大的权数，对离预测期较远的历史数据给予较小的权数，权数由近到远按指数规律递减，所以，这种预测方法被称为指数平滑法。它可分为一次指数平滑法、二次指数平滑法及更高次指数平滑法。 异常算法skyline 一共提供了 7 个异常检测算法，如果有 5 个以上认为是异常，那么 skyline就认为这个序列异常了. 异常检测算法实际写在了 src/analyzer/algorithms.py first_hour_average、 simple_stddev_from_moving_average、 stddev_from_moving_average、 mean_subtraction_cumulation、 least_squares histogram_bins、 grubbs、 median_absolute_deviation、 Kolmogorov-Smirnov_test first_hour_average这是最简单的。先求本周期内最前面的第一个小时的平均值和标准差，然后和最新的三个值的平均值(tail_avg()，这是后面多数算法都通用的做法)做比较。如果 tail_avg 和 第一小时平均值的差距大于 3 倍的标准差，那么认定为异常。 simple_stddev_from_moving_average把上面算法的范围扩大化，求的是整个周期内全部数据的平均值和标准差。 stddev_from_moving_average在上面算法的基础上，采用指数加权移动平均值。对周期内采点数量较少的情况更好一些。 mean_subtraction_cumulation做法是这样的： 排除最后一个值； 求剩余序列的平均值； 全序列减去上面这个平均值； 求剩余序列的标准差； 判断全序列最后一个值是否大于 3 倍的标准差 在代码中本来还计算了一次序列的指数加权移动平均值，但是算完了却没用，感觉怪怪的。 least_squares采用最小二乘法拟近时间序列，然后用实际值减去拟近值得到新序列。然后判断新序列的最后三个值的平均值是否大于 3 倍的新序列标准差。 所谓最小二乘法，简单说就是对一个 [x, y] 序列，会有一对常数 [m, c]，让 Y = mx + c 等式中的 Y 和 y 在全序列上最接近。 histogram_bins将整个周期序列的数据按照直方图统计法归入 15 个直方中，然后看最后三个值的平均值属于这 15 个直方的具体哪个。如果这个直方中包含的数据小于 20 个，判断为异常。 从算法中可以知道，如果周期内数据量不够，很容易被判断为异常的。 grubbs将整个周期序列的数据按照格拉布斯法求异常值。 标准的格拉布斯法是这样的： 从小到大排序； 求序列的平均值和标准差； 计算最小值和最大值与平均值的差距，更大的那个为可疑值； 可疑值减去平均值，再除以标准差，如果大于格拉布斯临界值，那么就是异常值； 排除异常值，对剩余序列循环做 1-5 步骤。 这里只用判断时间序列的最后是否异常，所以直接将最后三个值的平均值作为可疑值判断是否异常即可。 2013 年 07 月 23 日更新 新增了一个异常算法，现在有 8 个了，要通过 6 个才算真异常。 新增的是”绝对中值偏差法” median_absolute_deviation具体实现是：序列的最后一个值，比该序列的绝对中值大 6 倍以上，即判断为异常。 注意这里是中值，不是平均值。 2013 年 08 月 14 日更新 新增一个异常算法，现在有 9 个了。 新增的是”柯尔莫诺夫-斯米尔诺夫检验法” Kolmogorov-Smirnov_test具体实现是：计算序列内最近十分钟的数值的ks测试分布，然后计算序列中最近一个小时前到十分钟前这 50 分钟的数值的ks测试分布；如果两个分布相差较大，即判断为异常。 预测预测算法时序存储 rrdtool 和 graphite]]></content>
      <categories>
        <category>monitor</category>
      </categories>
      <tags>
        <tag>monitor,alert</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[keepalived]]></title>
    <url>%2F2019%2F09%2F04%2Fkeepalived%2F</url>
    <content type="text"><![CDATA[keepalivedgraph TB keepalived_module-->core keepalived_module-->check keepalived_module-->vrrp]]></content>
      <categories>
        <category>lb</category>
      </categories>
      <tags>
        <tag>lb,keepalived</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[VRRP协议]]></title>
    <url>%2F2019%2F09%2F04%2FVRRP%E5%8D%8F%E8%AE%AE%2F</url>
    <content type="text"><![CDATA[VRRP协议Skew time(秒)=(256－Backup路由器的优先级)/256 Master_Down_Interval(秒)=(3×VRRP报文的发送时间间隔)+Skew time sequenceDiagram participant up as 上层路由器 participant m as master router Note left of m: 00-00-5E-00-01-{VRID} & VIP & 优先级 participant s as backup router loop interval m-->>s: vrrp 通告报文 I'm alive! end loop interval s-->>m:BFD检测快速切换 end loop interval m-->>up:NQA检测调整自身优先级 end graph TB vr((virtual_router))-->rr0((real_router_0)) vr-->rr1((real_router_1)) vr-->rr2((real_router_2))]]></content>
      <categories>
        <category>network</category>
      </categories>
      <tags>
        <tag>network,vrrp</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[pgp加密]]></title>
    <url>%2F2019%2F09%2F01%2Fpgp%E5%8A%A0%E5%AF%86%2F</url>
    <content type="text"><![CDATA[pgp加密GnuPG 是一个用来进行非对称加密(PGP)的免费软件，简称GPG PGP是一个基于RSA公匙加密体系的邮件加密软件]]></content>
      <categories>
        <category>pgp,gpg</category>
      </categories>
      <tags>
        <tag>pgp,gpg</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[elasticsearch_dsl使用]]></title>
    <url>%2F2019%2F08%2F30%2Felasticsearch-dsl%E4%BD%BF%E7%94%A8%2F</url>
    <content type="text"><![CDATA[123456789101112131415161718192021222324252627282930313233POST /_search&#123;&quot;size&quot;: 0,&quot;aggs&quot;: &#123; &quot;by_grp&quot; : &#123; &quot;terms&quot;: &#123; &quot;field&quot;: &quot;grpId&quot;, &quot;size&quot;: 0 &#125;, &quot;aggs&quot;: &#123; &quot;twitter_count&quot;: &#123; &quot;range&quot;: &#123; &quot;field&quot;: &quot;twitter.followers&quot;, &quot;ranges&quot;: [ &#123; &quot;to&quot; : 501&#125;, &#123; &quot;from&quot; : 501, &quot;to&quot; : 1001&#125;, &#123; &quot;from&quot; : 1001, &quot;to&quot; : 5001&#125;, &#123; &quot;from&quot; : 5001&#125; ] &#125;, &quot;aggs&quot; : &#123; &quot;email_addy&quot;: &#123; &quot;terms&quot; : &#123; &quot;field&quot;: &quot;email.value&quot;, &quot;size&quot;: 0 &#125; &#125; &#125; &#125; &#125; &#125;&#125;&#125; 12345678910s.aggs.bucket('by_grp', 'terms', field='grpId', size=0) \.bucket('twitter_count', 'range', field='twitter.followers', ranges=[ &#123;'to': 5001&#125;, &#123;'from': 5001, 'to': 10001&#125;, &#123;'from': 10001, 'to': 50001&#125;, &#123;'from': 50001&#125; ]) \.bucket('email_addy', 'terms', field='email.value', size=0)]]></content>
      <categories>
        <category>elasticsearch</category>
      </categories>
      <tags>
        <tag>elasticsearch</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[消息队列]]></title>
    <url>%2F2019%2F08%2F28%2Fmq%2F</url>
    <content type="text"><![CDATA[消息传输模型 [1to1]点对点(point-to-point) [MtoM]生产消费(produce-queue-consumer) [1toM]发布订阅(PUBSUB) 广播(subscriber拿相同的消息) request-reply应答 队列分发(每个subscriber拿到的不一样) 考量标准三个维度上去考量，吞吐量、时延、可靠性 nats本身没有实现存储,可靠性要客户端服务端实现]]></content>
      <categories>
        <category>mq</category>
      </categories>
      <tags>
        <tag>mq</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[nginx优化]]></title>
    <url>%2F2019%2F08%2F28%2Fnginx%E4%BC%98%E5%8C%96%2F</url>
    <content type="text"><![CDATA[nginx信号： TERM,INT快速关闭 HUP 平滑重启，加载配置(重启旧进程) USR1 重新打开日志，切日志 USR2 平滑升级 -&gt; WINCH 从容关闭worker -&gt; QUIT 从容关闭master config: worker_rlimit_nofile 51200; worker_connections 51200; 12345678910111213141516171819202122232425262728293031323334[root@centos-server modules]# rpm -ql nginx/etc/logrotate.d/nginx/etc/nginx/etc/nginx/conf.d/etc/nginx/conf.d/default.conf/etc/nginx/fastcgi_params/etc/nginx/koi-utf/etc/nginx/koi-win/etc/nginx/mime.types/etc/nginx/modules/etc/nginx/nginx.conf/etc/nginx/scgi_params/etc/nginx/uwsgi_params/etc/nginx/win-utf/etc/sysconfig/nginx/etc/sysconfig/nginx-debug/usr/lib/systemd/system/nginx-debug.service/usr/lib/systemd/system/nginx.service/usr/lib64/nginx/usr/lib64/nginx/modules/usr/libexec/initscripts/legacy-actions/nginx/usr/libexec/initscripts/legacy-actions/nginx/check-reload/usr/libexec/initscripts/legacy-actions/nginx/upgrade/usr/sbin/nginx/usr/sbin/nginx-debug/usr/share/doc/nginx-1.16.0/usr/share/doc/nginx-1.16.0/COPYRIGHT/usr/share/man/man8/nginx.8.gz/usr/share/nginx/usr/share/nginx/html/usr/share/nginx/html/50x.html/usr/share/nginx/html/index.html/var/cache/nginx/var/log/nginx 123456[root@centos-server nginx]# nginx -Vnginx version: nginx/1.16.0built by gcc 4.8.5 20150623 (Red Hat 4.8.5-36) (GCC)built with OpenSSL 1.0.2k-fips 26 Jan 2017TLS SNI support enabledconfigure arguments: --prefix=/etc/nginx --sbin-path=/usr/sbin/nginx --modules-path=/usr/lib64/nginx/modules --conf-path=/etc/nginx/nginx.conf --error-log-path=/var/log/nginx/error.log --http-log-path=/var/log/nginx/access.log --pid-path=/var/run/nginx.pid --lock-path=/var/run/nginx.lock --http-client-body-temp-path=/var/cache/nginx/client_temp --http-proxy-temp-path=/var/cache/nginx/proxy_temp --http-fastcgi-temp-path=/var/cache/nginx/fastcgi_temp --http-uwsgi-temp-path=/var/cache/nginx/uwsgi_temp --http-scgi-temp-path=/var/cache/nginx/scgi_temp --user=nginx --group=nginx --with-compat --with-file-aio --with-threads --with-http_addition_module --with-http_auth_request_module --with-http_dav_module --with-http_flv_module --with-http_gunzip_module--with-http_gzip_static_module --with-http_mp4_module --with-http_random_index_module --with-http_realip_module --with-http_secure_link_module --with-http_slice_module --with-http_ssl_module --with-http_stub_status_module --with-http_sub_module --with-http_v2_module --with-mail --with-mail_ssl_module --with-stream --with-stream_realip_module --with-stream_ssl_module --with-stream_ssl_preread_module --with-cc-opt='-O2 -g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector-strong --param=ssp-buffer-size=4 -grecord-gcc-switches -m64 -mtune=generic -fPIC' --with-ld-opt='-Wl,-z,relro -Wl,-z,now -pie' Nginx 监控 1#netstat -n | awk &apos;/^tcp/ &#123;++S[$NF]&#125; END &#123;for(a in S) print a, S[a]&#125;&apos; 上面是一个实际网站的配置实例，其中灰色文字为配置说明。上述配置中，首先我们定义了一个 location ~ ^/NginxStatus/，这样通过 http://localhost/NginxStatus/ 就可以监控到 Nginx 的运行信息，显示的内容如下： Active connections: 70server accepts handled requests 14553819 14553819 19239266Reading: 0 Writing: 3 Waiting: 67 NginxStatus 显示的内容意思如下： active connections – 当前 Nginx 正处理的活动连接数。 server accepts handled requests -- 总共处理了 14553819 个连接 , 成功创建 14553819 次握手 ( 证明中间没有失败的 ), 总共处理了 19239266 个请求 ( 平均每次握手处理了 1.3 个数据请求 )。 reading -- nginx 读取到客户端的 Header 信息数。 writing -- nginx 返回给客户端的 Header 信息数。 waiting -- 开启 keep-alive 的情况下，这个值等于 active - (reading + writing)，意思就是 Nginx 已经处理完正在等候下一次请求指令的驻留连接。123456789101112131415procs -----------memory---------- ---swap-- -----io---- --system-- -----cpu----- r b swpd free buff cache si so bi bo in cs us sy id wa st 1 0 22720 2010244 169688 2594920 0 0 0 0 33433 16822 2 21 77 0 0 2 0 22720 2010492 169688 2594952 0 0 0 412 34205 17057 3 21 76 0 0 1 0 22720 2010864 169688 2593692 0 0 0 0 33576 16732 3 21 77 0 0 1 0 22720 2009624 169696 2595632 0 0 0 404 33831 16805 3 20 77 0 0 1 0 22720 2009500 169696 2594784 0 0 0 0 33843 16680 3 21 77 0 0[root@192-168-171-146 nginx]# vmstat 5procs -----------memory---------- ---swap-- -----io---- --system-- -----cpu----- r b swpd free buff cache si so bi bo in cs us sy id wa st 0 0 22420 2207684 70400 2497512 0 0 7 56 2 1 1 5 93 0 0 1 0 22420 2205872 70416 2500324 0 0 0 130 31450 15395 2 7 92 0 0 1 0 22420 2203248 70432 2504292 0 0 0 110 31637 15802 2 7 91 0 0 0 0 22420 2202296 70448 2506236 0 0 0 134 31459 15605 2 7 91 0 0 0 0 22420 2202064 70460 2505480 0 0 0 447 31511 15458 2 7 91 1 0 worker_cpu_affinity配置是写在/etc/nginx/nginx.conf里面的。 2核是 01，四核是0001，8核是00000001，有多少个核，就有几位数，1表示该内核开启，0表示该内核关闭。 8核CPU，开户8个进程 worker_processes 8;worker_cpu_affinity 00000001 00000010 00000100 00001000 00010000 00100000 01000000 10000000;0001表示启用第一个CPU内核，0010表示启用第二个CPU内核，依此类推worker_processes最多开启8个，8个以上性能提升不会再提升了，而且稳定性变得更低，所以8个进程够用了。 优化TCP/IP连接，减少TIME-WAIT的命令（一）TCP/IP连接的状态和对应的个数： 1netstat -an | awk '/^tcp/ &#123;++s[$NF]&#125; END &#123;for(a in s) print a, s[a]&#125;' （二）提升服务器的负载能力： 123456# vim /etc/sysctl.confnet.ipv4.tcp_syncookies = 1net.ipv4.tcp_tw_reuse = 1net.ipv4.tcp_tw_recycle = 1net.ipv4.tcp_fin_timeout = 5 参数说明：{net.ipv4.tcp_syncookies = 1 表示开启SYN Cookies。当出现SYN等待队列溢出时，启用cookies来处理，可防范少量SYN攻击，默认为0，表示关闭；net.ipv4.tcp_tw_reuse = 1 表示开启重用。允许将TIME-WAIT sockets重新用于新的TCP连接，默认为0，表示关闭；net.ipv4.tcp_tw_recycle = 1 表示开启TCP连接中TIME-WAIT sockets的快速回收，默认为0，表示关闭；net.ipv4.tcp_fin_timeout 修改系统默认的 TIMEOUT 时间。}（三）优化TCP/IP的可使用端口范围，进一步提升服务器的并发能力（针对tcp流量比较大的服务器）net.ipv4.tcp_keepalive_time = 1200net.ipv4.ip_local_port_range = 10000 65000net.ipv4.tcp_max_syn_backlog = 8192net.ipv4.tcp_max_tw_buckets = 5000 参数说明：{net.ipv4.tcp_keepalive_time = 1200 表示当keepalive起用的时候，TCP发送keepalive消息的频度。缺省是2小时，改为20分钟。 net.ipv4.ip_local_port_range = 10000 65000 表示用于向外连接的端口范围。缺省情况下很小：32768到61000，改为10000到65000。(注意：这里不要将最低值设的太低，否则可能会占用掉正常的端口！)net.ipv4.tcp_max_syn_backlog = 8192 表示SYN队列的长度，默认为1024，加大队列长度为8192，可以容纳更多等待连接的网络连接数。 net.ipv4.tcp_max_tw_buckets = 5000 表示系统同时保持TIME_WAIT的最大数量，如果超过这个数字，TIME_WAIT将立刻被清除并打印警告信息。默认为180000，改为5000。对于Apache、Nginx等服务器，上几行的参数可以很好地减少TIME_WAIT套接字数量，但是对于 Squid，效果却不大。此项参数可以控制TIME_WAIT的最大数量，避免Squid服务器被大量的TIME_WAIT拖死。}（四）修改 linux kernel 的 tcp time wait的时间（适用于大量短连接的情况）在 $KERNEL/include/net/tcp.h里面，有下面的行： #define TCP_TIMEWAIT_LEN (60HZ) / how long to wait to destroy TIME-WAIT * state, about 60 seconds */ 而这个宏是真正控制 TCP TIME_WAIT 状态的超时时间的。如果我们希望减少 TIME_WAIT 状态的数目(从而节省一点点内核操作时间)，那么可以把这个数值设置低一些，根据我们的测试，设置为 10 秒比较合适，也就是把上面的修改为： #define TCP_TIMEWAIT_LEN (10*HZ) /* how long to wait to destroy TIME-WAIT * state, about 60 seconds */ 然后重新编译内核，重启系统即可发现短连接造成的TIME_WAIT状态大大减少： netstat -ant | grep -i time_wait |wc -l 一般情况都可以至少减少2/3。也能相应提高系统应对短连接的速度 net.ipv4.tcp_syncookies = 1net.ipv4.tcp_tw_reuse = 1net.ipv4.tcp_tw_recycle = 1net.ipv4.tcp_fin_timeout = 5参数说明：{net.ipv4.tcp_syncookies = 1 表示开启SYN Cookies。当出现SYN等待队列溢出时，启用cookies来处理，可防范少量SYN攻击，默认为0，表示关闭；net.ipv4.tcp_tw_reuse = 1 表示开启重用。允许将TIME-WAIT sockets重新用于新的TCP连接，默认为0，表示关闭；net.ipv4.tcp_tw_recycle = 1 表示开启TCP连接中TIME-WAIT sockets的快速回收，默认为0，表示关闭；net.ipv4.tcp_fin_timeout 修改系统默认的 TIMEOUT 时间。} Nginx做web服务器linux内核参数优化 Nginx提供web服务时Linux内核参数调整是必不可少的，其中在优化方面就需要我们格外的注意。在下面就是对Linux内核参数优化的详细介绍，希望大家有所收获。 关于Linux内核参数的优化： net.ipv4.tcp_max_tw_buckets = 6000 timewait的数量，默认是180000。 net.ipv4.ip_local_port_range = 1024 65000 允许系统打开的端口范围。 net.ipv4.tcp_tw_recycle = 1 启用timewait快速回收。 net.ipv4.tcp_tw_reuse = 1 开启重用。允许将TIME-WAIT sockets重新用于新的TCP连接。 net.ipv4.tcp_syncookies = 1 开启SYN Cookies，当出现SYN等待队列溢出时，启用cookies来处理。 net.core.somaxconn = 262144 web应用中listen函数的backlog默认会给我们内核参数的net.core.somaxconn限制到128，而Nginx内核参数定义的NGX_LISTEN_BACKLOG默认为511，所以有必要调整这个值。 net.core.netdev_max_backlog = 262144 每个网络接口接收数据包的速率比内核处理这些包的速率快时，允许送到队列的数据包的最大数目。 net.ipv4.tcp_max_orphans = 262144 系统中最多有多少个TCP套接字不被关联到任何一个用户文件句柄上。如果超过这个数字，孤儿连接将即刻被复位并打印出警告信息。这个限制仅仅是为了防止简单的DoS攻击，不能过分依靠它或者人为地减小这个值，更应该增加这个值(如果增加了内存之后)。 net.ipv4.tcp_max_syn_backlog = 262144 记录的那些尚未收到客户端确认信息的连接请求的最大值。对于有128M内存的系统而言，缺省值是1024，小内存的系统则是128。 net.ipv4.tcp_timestamps = 0 时间戳可以避免序列号的卷绕。一个1Gbps的链路肯定会遇到以前用过的序列号。时间戳能够让内核接受这种“异常”的数据包。这里需要将其关掉。 net.ipv4.tcp_synack_retries = 1 为了打开对端的连接，内核需要发送一个SYN并附带一个回应前面一个SYN的ACK。也就是所谓三次握手中的第二次握手。这个设置决定了内核放弃连接之前发送SYN+ACK包的数量。 net.ipv4.tcp_syn_retries = 1 在内核放弃建立连接之前发送SYN包的数量。 net.ipv4.tcp_fin_timeout = 1 如果套接字由本端要求关闭，这个参数决定了它保持在FIN-WAIT-2状态的时间。对端可以出错并永远不关闭连接，甚至意外当机。缺省值是60秒。2.2 内核的通常值是180秒，你可以按这个设置，但要记住的是，即使你的机器是一个轻载的WEB服务器，也有因为大量的死套接字而内存溢出的风险，FIN- WAIT-2的危险性比FIN-WAIT-1要小，因为它最多只能吃掉1.5K内存，但是它们的生存期长些。 net.ipv4.tcp_keepalive_time = 30 当keepalive起用的时候，TCP发送keepalive消息的频度。缺省是2小时。 12345678910111213141516171819202122232425[root@192-168-171-146 conf]# ss -sTotal: 12814 (kernel 12920)TCP: 16857 (estab 12572, closed 4096, orphaned 153, synrecv 0, timewait 4096/0), ports 1300Transport Total IP IPv6- 12920 - - RAW 0 0 0 UDP 9 6 3 TCP 12761 12757 4 INET 12770 12763 7 FRAG 0 0 0[root@192-168-171-146 conf]# ss -sTotal: 44751 (kernel 44980)TCP: 48780 (estab 44533, closed 4096, orphaned 139, synrecv 0, timewait 4096/0), ports 2188Transport Total IP IPv6- 44980 - - RAW 0 0 0 UDP 9 6 3 TCP 44684 44680 4 INET 44693 44686 7 FRAG 0 0 0]]></content>
      <categories>
        <category>nginx</category>
      </categories>
      <tags>
        <tag>nginx</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[kernel参数]]></title>
    <url>%2F2019%2F08%2F27%2Fkernel%E5%8F%82%E6%95%B0%2F</url>
    <content type="text"><![CDATA[内核参数vm.max_map_count1sysctl -w vm.max_map_count=262144 Elasticsearch uses a mmapfs directory by default to store its indices. The default operating system limits on mmap counts is likely to be too low, which may result in out of memory exceptions. mmapfs The MMap FS type stores the shard index on the file system (maps to Lucene MMapDirectory) by mapping a file into memory (mmap). Memory mapping uses up a portion of the virtual memory address space in your process equal to the size of the file being mapped. Before using this class, be sure you have allowed plenty of virtual address space.]]></content>
      <categories>
        <category>kernel</category>
      </categories>
      <tags>
        <tag>linux,kernel</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[elasticsearch 笔记]]></title>
    <url>%2F2019%2F08%2F26%2Felasticsearch-%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[ELASTICSEARCH官方文档笔记分布式文档存储 序列化json文档,KV包含数据 full-text searche全文索引实时搜索(An inverted index lists every unique word that appears in any document and identifies all of the documents each word occurs in.) When dynamic mapping is enabled, Elasticsearch automatically detects and adds new fields to the index. 相同的字段可以标记为多个类型以便不同的分析方法 aggregations operate 和 search requests可并行执行 搜索数据REST API接口管理集群,索引和搜索数据(Elasticsearch client,kibana developer console, command line) ​ The Elasticsearch REST APIs support structured queries, full text queries, and complex queries that combine the two. 全文索引将按关联性返回搜索结果 Query DSL SQL-style queries 分析数据聚合功能 key metrics, patterns, and trends 机器学习弹性调度cluster node shard 自由添加node,自动平衡As the cluster grows (or shrinks), Elasticsearch automatically migrates shards to rebalance the cluster. index(逻辑组)-&gt;shards(物理)-&gt;nodes graph LR index(Index逻辑组)-->shards shards-->primary_shards primary_shards-->replicas_shards(replicas shards只读) primary_cluster-->CCR(Cross-cluster replication) CCR-->replicated_cluster(replicated cluster只读) ## CAT API12345678$ curl -X GET "127.0.0.1:9200/_cat/health?v&amp;pretty"epoch timestamp cluster status node.total node.data shards pri relo init unassign pending_tasks max_task_wait_time active_shards_percent1566820997 12:03:17 cluster-name green 15 9 6073 6039 0 0 0 0 - 100.0%$ curl -X GET "127.0.0.1:9200/_cat/indices?v&amp;pretty" |morehealth status index uuid pri rep docs.count docs.deleted store.size pri.store.sizegreen open logstash-xxx-2019.08.22 1NcDlWKNQxKK529JwuQxFg 5 0 308686 0 548.3mb 548.3mbgreen open bbbb-2019.07.02 NTzO-PQESb2YrrUPzs0fVA 5 0 161398 0 99mb 99mbgreen open logstash-cccc-2019.08.26 -1DGNXaFRiqcowhhQ4Y2Tg 5 0 1364938 0 178.4mb 178.4mb 1$ GET /customer/_doc/1单个文档获取 bluk api (batch document operations)批量操作上传数据 123# https://github.com/elastic/elasticsearch/blob/master/docs/src/test/resources/accounts.json?raw=truecurl -H "Content-Type: application/json" -XPOST "localhost:9200/bank/_bulk?pretty&amp;refresh" --data-binary "@accounts.json"curl "localhost:9200/_cat/indices?v" search,analyze and machine learningsearch跟sql不同,这里没有游标等概念,查询完就结束了 REST request url 12345678910111213141516171819202122232425262728293031323334GET /bank/_search?q=*&amp;sort=account_number:asc&amp;pretty&#123; "took" : 63, //查询使用的时间(微秒) "timed_out" : false, //是否超时 "_shards" : &#123; //返回查询的shard信息 "total" : 5, "successful" : 5, "skipped" : 0, "failed" : 0 &#125;, "hits" : &#123; //查询结果 "total" : &#123; //查询匹配 "value": 1000, //总数 "relation": "eq" //关联 &#125;, "max_score" : null, "hits" : [ &#123; //实际结果列表 "_index" : "bank", "_type" : "_doc", "_id" : "0", "sort": [0], "_score" : null, "_source" : &#123;"account_number":0,"balance":16623,"firstname":"Bradshaw","lastname":"Mckenzie","age":29,"gender":"F","address":"244 Columbus Place","employer":"Euron","email":"bradshawmckenzie@euron.com","city":"Hobucken","state":"CO"&#125; &#125;, &#123; "_index" : "bank", "_type" : "_doc", "_id" : "1", "sort": [1], "_score" : null, "_source" : &#123;"account_number":1,"balance":39225,"firstname":"Amber","lastname":"Duke","age":32,"gender":"M","address":"880 Holmes Lane","employer":"Pyrami","email":"amberduke@pyrami.com","city":"Brogan","state":"IL"&#125; &#125;, ... ] &#125;&#125; REST request body match_all 1234567891011GET /bank/_search &#123; //使用QUERY DSL "query": &#123; "match_all": &#123;&#125; &#125;, "sort": [ &#123; "account_number": "asc" &#125; ], // "sort": &#123; "balance": &#123; "order": "desc" &#125; &#125; "size": 1, //默认为10 "from": 10, //指定开始的结果,默认为0,对于分布显示结果很有用 "_source": ["account_number", "balance"],//代替默认的_source返回字段&#125; match 1234GET /bank/_search&#123; "query": &#123; "match": &#123; "account_number": 20 &#125; &#125;&#125; match_phrase匹配短语 1234GET /bank/_search&#123; "query": &#123; "match_phrase": &#123; "address": "mill lane" &#125; &#125;&#125; bool must(and) should(or) must_not(not) filter range analyzeterm是代表完全匹配，即不进行分词器分析，文档中必须包含整个搜索的词汇 12345678910111213141516171819202122GET /bank/_search&#123; "size": 0, //不显示搜索结果 "aggs": &#123; "group_by_state": &#123; "terms": &#123; //terms aggregation聚合方式 "field": "state.keyword", "size": 5 //默认显示10条记录 "order": &#123; //指定排序 "average_balance": "desc" &#125; &#125;, "aggs":&#123; //嵌套 "average_balance": &#123; "avg": &#123; "field": "balance" &#125; &#125; &#125; &#125; &#125;&#125; 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081&#123; "took": 8, "timed_out": false, "_shards": &#123; "total": 1, "successful": 1, "skipped": 0, "failed": 0 &#125;, "hits": &#123; "total": &#123; "value": 1000, "relation": "eq" &#125;, "max_score": 1.0, "hits": [ &#123; "_index": "bank", "_type": "_doc", "_id": "1", "_score": 1.0, "_source": &#123; "account_number": 1, "balance": 39225, "firstname": "Amber", "lastname": "Duke", "age": 32, "gender": "M", "address": "880 Holmes Lane", "employer": "Pyrami", "email": "amberduke@pyrami.com", "city": "Brogan", "state": "IL" &#125; &#125; ] &#125;, "aggregations": &#123; "group_by_state": &#123; "doc_count_error_upper_bound": -1, "sum_other_doc_count": 923, "buckets": [ &#123; "key": "CO", "doc_count": 14, "average_balance": &#123; "value": 32460.35714285714 &#125; &#125;, &#123; "key": "NE", "doc_count": 16, "average_balance": &#123; "value": 32041.5625 &#125; &#125;, &#123; "key": "AZ", "doc_count": 14, "average_balance": &#123; "value": 31634.785714285714 &#125; &#125;, &#123; "key": "MT", "doc_count": 17, "average_balance": &#123; "value": 31147.41176470588 &#125; &#125;, &#123; "key": "VA", "doc_count": 16, "average_balance": &#123; "value": 30600.0625 &#125; &#125; ] &#125; &#125;&#125; 安装ELASTICSEARCH自带一个openjdk,可能过JAVA_HOME变量修改成自部署JAVA版本 1234567891011121314[root@dab238b13031 elasticsearch]# ls -1LICENSE.txtNOTICE.txtREADME.textilebin //执行文件config //配置文件data //shard数据目录jdk //自带jdk版本liblogs //日志modulesplugins //插件,每个插件都有一个子目录[root@dab238b13031 elasticsearch]# ls jdk/bin conf include jmods legal lib release docker版本基础镜像基于centos7 123docker run -p 9200:9200 -p 9300:9300 -e "discovery.type=single-node" docker.elastic.co/elasticsearch/elasticsearch:7.3.1$ grep vm.max_map_count /etc/sysctl.confvm.max_map_count=262144 运行 123# 后台,添加命令行配置# 配置文件 config/elasticsearch.yml./bin/elasticsearch -d -Ecluster.name=my_cluster -Enode.name=node_1 检测是否在运行 123456789101112131415161718curl -X GET "localhost:9200/?pretty"&#123; "name": "dab238b13031", "cluster_name": "docker-cluster", "cluster_uuid": "mNH6fmV0RE2WVvavM-9bFA", "version": &#123; "number": "7.3.1", "build_flavor": "default", "build_type": "docker", "build_hash": "4749ba6", "build_date": "2019-08-19T20:19:25.651794Z", "build_snapshot": false, "lucene_version": "8.1.0", "minimum_wire_compatibility_version": "6.8.0", "minimum_index_compatibility_version": "6.0.0-beta1" &#125;, "tagline": "You Know, for Search"&#125; 配置配置文件和敏感配置后需要重启 三个配置文件:默认在config目录下,可ES_PATH_CONF=/path/to/my/config修改 elasticsearch.yml for configuring Elasticsearch jvm.options for configuring Elasticsearch JVM settings 7-9:-Xmx2g 冒号前是java版本范围 log4j2.properties Log4j 2 for configuring Elasticsearch logging 12345678910111213141516171819202122[root@dab238b13031 elasticsearch]# ls -1 bin/elasticsearchelasticsearch-certgenelasticsearch-certutilelasticsearch-clielasticsearch-cronevalelasticsearch-envelasticsearch-enveelasticsearch-keystore //用于创建敏感配置elasticsearch-migrateelasticsearch-nodeelasticsearch-pluginelasticsearch-saml-metadataelasticsearch-setup-passwordselasticsearch-shardelasticsearch-sql-clielasticsearch-sql-cli-7.3.1.jarelasticsearch-syskeygenelasticsearch-usersx-pack-envx-pack-security-envx-pack-watcher-env 敏感配置(POST _nodes/reload_secure_settings加载)添加string 1cat /file/containing/setting/value | bin/elasticsearch-keystore add --stdin the.setting.name.to.set 添加文件 1bin/elasticsearch-keystore add-file the.setting.name.to.set /path/example-file.json 删除 1bin/elasticsearch-keystore remove the.setting.name.to.remove INDEX生命周期策略管理https://www.elastic.co/guide/en/elasticsearch/reference/current/using-policies-rollover.html 机器学习(默认是开启听)xpack.ml.enabled heap size默认1G Xms (minimum heap size) and Xmx (maximum heap size) Set Xmx and Xms to no more than 50% of your physical RAM 大heap利于内部缓存,但会带来长GC暂停. 系统内存太小影响文件缓存 系统配置1elasticsearch - nofile 65535 1sudo swapoff -a //禁用swap 1sysctl -w vm.max_map_count=262144 ulimit -u 4096 JVM会缓存解析10秒,ES覆盖为60秒,反向解析10秒 Aggregations四类 bucketing分组 terms size 先收集所有shard上的一定数量的响应,然后再汇总一起,结果不是很精准 Numeric value (1000000000000000000000) out of range of int (-2147483648 - 2147483647)\n at [Source: org.elasticsearch.transport.netty4.ByteBufStreamInput@4af5e4f0; line: 16, column: 54]” composite [composite] aggregation cannot be used with a parent aggregation metric度量 avg/加权avg matrix矩阵(在多个字段基础上产生矩阵) pipeline管道(在其它聚合基础上再次聚合) Each bucket may be sorted based on its _key, _count or its sub-aggregations. 聚合嵌套功能十分强大 1234567891011// 语法结构 aggregations或aggs"aggregations" : &#123; "&lt;aggregation_name&gt;" : &#123; "&lt;aggregation_type&gt;" : &#123; &lt;aggregation_body&gt; &#125; [,"meta" : &#123; [&lt;meta_data_body&gt;] &#125; ]? [,"aggregations" : &#123; [&lt;sub_aggregation&gt;]+ &#125; ]? &#125; [,"&lt;aggregation_name_2&gt;" : &#123; ... &#125; ]*&#125;]]></content>
      <categories>
        <category>elastic</category>
      </categories>
      <tags>
        <tag>elastic,elasticsearch</tag>
      </tags>
  </entry>
  <entry>
    <title></title>
    <url>%2F2019%2F08%2F26%2Fnginx%E5%AE%9E%E8%B7%B5%2F</url>
    <content type="text"><![CDATA[nginx笔记第三章 场景实践篇静态web服务跨域访问服务器允许网站请求其它域名的内容. 12add_header Access-Control-Allow-Orgin http://example.com;add_header Access-Control-Allow-Methods POST,GET,PUT,DELETE,OPTIONS; 防盗链nginx支持简单方式 http Referer(Module ngx_http_referer_module) 12345678referer_hash_bucket_size 64;referer_hash_max_size 2048;valid_referers none | blocked | server_names | string ...;# 匹配为empty string,不匹配为1# none为空# blocked是被代理或防火墙删除了http://或https://后剩余的url# server_names其中之一# string ... 其它匹配字符串 1234567# 注意:valid_referers and $valid_referer单复数格式valid_referers none blocked server_names *.example.com example.* www.example.org/galleries/ ~\.google\.;if ($valid_referer)&#123; return 403;&#125; 代理服务http https rtmp icmp/pop/smtp 正向代理(客户端)反向代理(服务端)ngx_http_proxy_module Syntax: proxy_pass URL; //http,https,socket Default: — Context: location, if in location, limit_except]]></content>
      <categories>
        <category>nginx</category>
      </categories>
      <tags>
        <tag>nginx</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[LINUX常用工具集]]></title>
    <url>%2F2019%2F08%2F23%2FLINUX%E5%B8%B8%E7%94%A8%E5%B7%A5%E5%85%B7%E9%9B%86%2F</url>
    <content type="text"><![CDATA[网络监控: NetHogs是一个开源的命令行工具（类似于Linux的top命令），用来按进程或程序实时统计网络带宽使用率。]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[c primer plus 学习笔记]]></title>
    <url>%2F2019%2F08%2F20%2Fc-primer-plus-%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[c primer plus 学习笔记第一章 认识C语言 第二章 C语言概述C语言的基本模块: 函数 形参:变量 实参:值 C语言重要特性 转义序列escape sequence 占位符 C语言的结构 程序(由多个函数组成) 头文件 #include&lt;stdio.h&gt;包含一个文件,C编译器的预处理指令#(头文件可定义一些常量,函数名,实际代码在另一个库文件中,头文件相当于组织程序) /*注释*/ //注释 分号结尾; 函数 函数头 int main(void)int返回类型,main是主函数,void表示空参数 返回类型 函数名 形式参数 函数体 声明 int num;变量(variable)标识符(identifer)声明(declaration) -&gt;mem位置,数据类型 关键字 变量名: C99/C11变量标识符最长63个字符,外部标识符最长31个字符 大小写字母,数字,_,不能以数字开头 所有变量必须先声明才能使用 语句 跳转语句 赋值表达式(存储值到内存空间) return语句 返回值 第三章 数据和C数据 承载信息的数字和符号 常量constant 程序运行过程中不改变; 编译器根据书写形态自动判断数据类型 变量variable 可变或被赋值 声明时需要指定类型 基本类型关键字: 数据类型按存储方式分两大数据类型: 浮点数范围&gt;整数 整数类型没有小数位的数 graph TB char(char: '4', 'ABC')-->encode(encode:ASCII,EBCDIC,CJK字符集,Unicode,UTF-8...) encode-->int int-->进制(进制:16,8,2..) 进制-->bit int char _Bool1 bit. 1为true,0为false 浮点数类型类似实数 分两部分存储 7.0=0.7E1 指数部分1 小数部分0.7 任何区间实数无穷多,计算机无法存储所有值,只存储近似值,会损失精度 字节byte=8bit 字:计算机寻址单位 整数类型 占位长度 short 16bit int 16bit/32bit long 32bit long long 64bit 程序中超出最大值会重新开始计算,类似汽车里程表 C语言数据类型(分配合适内存空间) scanf(“%f”, &amp;indentifer)将输入的值赋值给标识符indentifer &amp; 找到指定变量标识符的地址 printf中转换说明决定了数据的显示方式,而不是存储方式. char 字符常量:使用‘ ’引起来表示字符,编译器会识别并根据编码转换成整数值;也可以直接把编码赋值给变量标记符 不带引号是变量标识符 “ ”表示字符串 转义序列 第四章 字符串和格式化输入/输出(数据表示)数组array存储字符串,占用连续的字节空间. 4.2字符串(字符序列)(双引号)存储: char类型的array中 数组: 1char id[40] //40字节空间的char类型array sizeof():以字节为单位给出对象大小 strlen():计算字符串的字符长度 4.3常量和C预处理器符号常量symbolic constant(编译时替换compile-time subsitution=明示常量manifest constant) 12#define NAME value // 一般大写或c_/k_开头#define pi 3.1415926 const限定符,表示变量为只读 1const int NAME = value; //NAME不可更改, 用起来比define灵活 printf()/scanf() I/O函数 使用转换说明符(conversion specification)转换成可显示的形式. 第五章 运算符,表达式expression和语句statement(数据处理)数据处理: 算术运算 数值比较 修改变量 逻辑组合关系 大多语句由表达式构成;表达式可能包含子表达式; 一条语句是一条完整的计算机指令.带(;)号 循环123while(condition)&#123; block&#125; 基本运算符赋值运算符= 使用赋值的思想才能解释 i = i + 1 对象定位值(可修改的左值)variable = value 目的:把值(数据对象)存储到内存位置上 加法运算符+ 二元运算符需要两个运算对象 一元运算符正号+ 减法运算符- 二元运算符`需要两个运算对象 一元运算符负号- 乘法运算符*除法运算符/截断:整数除法的小数位被丢弃 C99使用趋零截断,-3.8转换成-3 运算符优先级 其它运算符sizeof(type/variable) 返回size_t(无符号整数类型)类型的值 1typedef double real; //typedef 为double创建别名real 求模运算符 % 常用于根据求模结果是否为0控制流程 ​ 负数使用趋零截断,以每个对象的符号为正负取结果为正负 递增运算符++/递减运算符 - - 前后辍只有自身没有运算符或赋值运算符时结果都是一样的,但复合运算时会影响结果. 前辍模式: 1a_post = 2 * a++ // a_post = 2a, a = a + 1 后辍模式: 1pre_b = 2 * ++b // b = b + 1, pre_b = 2b 第六章 C控制语句:循环,嵌套循环程序流: 语句序列 循环 分支 三种循环:(入口循环:for/while;出口循环:do while) for 123for(initialize；test；update)&#123; //使用分号分割,支持使用逗号一次处理多个变量 statement&#125; graph TB init-->test test-->成功 成功-->for_body test-->失败 失败-->update update-->test while 每次迭代都会调用判断循环条件 123456expression //初始化while (entry condition) //测试&#123; statement(简单/&#123;复合&#125;) expression //更新&#125; 第一次循环称为一次迭代 do while 当while循环前需要执行循环体的逻辑时,出口循环可以更简洁. 1234do &#123; statement&#125;while (expression); condition: 非0为真 0为假 赋值运算符=,+=,-=,*=,/=,%= 数组array/列表listC编译器不检查数组索引的合理性,可能会将赋值超过索引的值存储在其它位置,可能破坏其它数据并导致程序出错. 数组可以使用下标subscript,索引indice,偏移量offset表示 1float ary[15];声明数组,含有15个float元素 第九章 函数函数声明(函数原型funcation prototype)-&gt;函数定义 sequenceDiagram participant main as 主调函数 participant call as 被调函数 opt 驱动程序 main->>call:实参 end opt 栈stack main->>main:参数 main->>call:被调函数从stack中读取参数值 end call-->>call:形参 call-->>main:return 递归recursion函数调用自身]]></content>
      <categories>
        <category>c</category>
      </categories>
      <tags>
        <tag>c</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[centos 7 关闭笔记本合盖挂起功能]]></title>
    <url>%2F2019%2F08%2F13%2Fcentos-7-%E5%85%B3%E9%97%AD%E7%AC%94%E8%AE%B0%E6%9C%AC%E5%90%88%E7%9B%96%E6%8C%82%E8%B5%B7%E5%8A%9F%E8%83%BD%2F</url>
    <content type="text"><![CDATA[centos 7 关闭笔记本合盖挂起功能家里有一台dell的老笔记本，安装了centos7系统使用。默认系统配置把笔记本电脑屏合上后会造成挂起，网络断开。笔记本不能合盖，放置占位，也会造成灰尘进入键盘等总之不是很方便。systemd可以处理ACPI事件，这个默认配置可以通过修改systemd-logind.service的行为修改。 123456789101112131415161718192021222324252627282930313233343536[root@server ~]# vi /etc/systemd/logind.conf# This file is part of systemd.## systemd is free software; you can redistribute it and/or modify it# under the terms of the GNU Lesser General Public License as published by# the Free Software Foundation; either version 2.1 of the License, or# (at your option) any later version.## Entries in this file show the compile time defaults.# You can change settings by editing this file.# Defaults can be restored by simply deleting this file.## See logind.conf(5) for details.[Login]#NAutoVTs=6#ReserveVT=6#KillUserProcesses=no#KillOnlyUsers=#KillExcludeUsers=root#InhibitDelayMaxSec=5#HandlePowerKey=poweroff#HandleSuspendKey=suspend#HandleHibernateKey=hibernate#HandleLidSwitch=suspendHandleLidSwitch=ignore #这个合盖操作修改为ignore，合盖时不做任务操作。#HandleLidSwitchDocked=ignore#PowerKeyIgnoreInhibited=no#SuspendKeyIgnoreInhibited=no#HibernateKeyIgnoreInhibited=no#LidSwitchIgnoreInhibited=yes#IdleAction=ignore#IdleActionSec=30min#RuntimeDirectorySize=10%#RemoveIPC=no#UserTasksMax= 行为可以是 ignore、poweroff、reboot、halt、suspend、hibernate、hybrid-sleep、lock 或 kexec。 123[root@server ~]# systemctl list-units |grep logindsystemd-logind.service loaded active running Login Service[root@server ~]# systemctl restart systemd-logind 重启服务后合上笔记本，网络不受影响。 123[root@server ~]# ping 192.168.3.1PING 192.168.3.1 (192.168.3.1) 56(84) bytes of data.64 bytes from 192.168.3.1: icmp_seq=1 ttl=64 time=0.557 ms]]></content>
      <categories>
        <category>centos</category>
      </categories>
      <tags>
        <tag>centos</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[git study]]></title>
    <url>%2F2019%2F08%2F12%2Fgit-study%2F</url>
    <content type="text"><![CDATA[git study Git 对待数据的方法: Git 对待数据更像是一个快照流,没有更改的直接保留一个链接到原来的文件 subversion存储每个版本与初始文件的差异 git近乎所有操作都在本地执行,所以速度很快.其它CCVS离线后基本做不了什么 git存储sha-1校验和( 40 个十六进制字符),并以此做索引引用. GIT三种状态 已修改 modified -&gt; 工作目录 已暂存 staged(版本标记) -&gt; 暂存区 已提交 commited(存储到数据库) -&gt; 仓库 GIT三个工作区工作目录,暂存区,仓库 GIT安装1[Mon Aug 12 talen@tp-arch-tianfei ~]$ sudo pacman -S git GIT 配置配置路径git config 有三个配置文件路径 系统配置/etc/gitconfig 1git config --system 当前用户配置 ~/.gitconfig 或 ~/config/git/config 1git config --global 当前仓库配置 .git/config 配置用户信息如要配置当前用户或系统层配置,添加–global或–system参数 12$ git config user.name "Tianfei hao"$ git config user.email haotianfei@example.com 检查配置1$ git config --list GIT基础1234567891011121314151617git initgit addgit rm 删除工作区的文件 --cached只删除staged中的文件 --force适用于已经删除工作区文件,但已经提交到staged中的文件git mv 重命名文件git commit -a //跳过add,将staged的文件暂存一并提交 --amendgit clonegit statusgit diff // modified与staged对比git diff --cached/--staged //staged与commited对比git log -p 显示diff -数字 显示最近几次的提交 --stat 每一次提交的统计信息 .gitignore 文件忽略跟踪 空行,#开头会被忽略 使用标准glob模式匹配( shell 所使用的简化了的正则表达式) * 匹配任意字符 [abc] 方括号内任意字符 ? 单个任意字符 [0-9] 范围 a/**/z 中间任意目录 使用/开头防止递归,/结尾表示目录 !表示取反]]></content>
      <categories>
        <category>git</category>
      </categories>
      <tags>
        <tag>git</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[arch linux pacman清理]]></title>
    <url>%2F2019%2F08%2F06%2Farch-linux-pacman%E6%B8%85%E7%90%86%2F</url>
    <content type="text"><![CDATA[pacman清理已经安装的包缓存文件 12345678910pacman -Scc[Tue Aug 06 talen@tp-arch-tianfei pkg]$ sudo pacman -Scc[sudo] password for talen:Cache directory: /var/cache/pacman/pkg/:: Do you want to remove ALL files from cache? [y/N] yremoving all files from cache...Database directory: /var/lib/pacman/:: Do you want to remove unused repositories? [Y/n] yremoving unused sync repositories...]]></content>
      <categories>
        <category>arch</category>
      </categories>
      <tags>
        <tag>arch</tag>
        <tag>pacman</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[linux终端中文显示问题修复]]></title>
    <url>%2F2019%2F08%2F05%2Flinux%E7%BB%88%E7%AB%AF%E4%B8%AD%E6%96%87%E6%98%BE%E7%A4%BA%E9%97%AE%E9%A2%98%E4%BF%AE%E5%A4%8D%2F</url>
    <content type="text"><![CDATA[12345678910111213141516171819202122232425[talen@tp-arch-tianfei nginx]$ ls'Mastering Nginx.pdf''Nginx 1 Web Server Implementation Cookbook.pdf''Nginx Essentials.pdf''Nginx From Beginner to Pro.pdf''Nginx HTTP Server, Third Edition.pdf''Nginx Module Extension.pdf''Nginx'$'\346\225\231\347\250\213\344\273\216\345\205\245\351\227\250\345\210\260\347\262\276\351\200\232''('$'\350\277\220\347\273\264\347\224\237\345\255\230\346\227\266\351\227\264''TTLSA'$'\345\207\272\345\223\201'').pdf' nginx nginx-kernel.txt nginx-pdf nginx.conf.info nginx.dot'nginx: See Active connections _ Connections Per Seconds.html' nginx__try_files nginx_architecture.png nginx_conf.dot nginx_setup.dot'nginx'$'\347\254\254\344\270\211\346\226\271\346\250\241\345\235\227''.txt''nginx'$'\347\274\226\350\257\221\345\217\202\346\225\260''.txt'''$'\345\206\263\346\210\230''Nginx'$'\357\274\232'' '$'\347\263\273\347\273\237\345\215\267'' - '$'\351\253\230\346\200\247\350\203\275''Web'$'\346\234\215\345\212\241\345\231\250\350\257\246\350\247\243\344\270\216\350\277\220\347\273\264''(jb51.net).pdf'''$'\345\256\236\346\210\230''Nginx_'$'\345\217\226\344\273\243''Apache'$'\347\232\204\351\253\230\346\200\247\350\203\275''Web'$'\346\234\215\345\212\241\345\231\250''.'$'\345\274\240\345\256\264''.'$'\346\211\253\346\217\217\347\211\210''.pdf'''$'\345\256\236\346\210\230''nginx'''$'\346\267\261\345\205\245\345\211\226\346\236\220''Nginx.pdf'''$'\346\267\261\345\205\245\347\220\206\350\247\243''Nginx'$'\346\250\241\345\235\227\345\274\200\345\217\221\344\270\216\346\236\266\346\236\204\350\247\243\346\236\220''.pdf' 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677[talen@tp-arch-tianfei nginx]$ localeLANG=CLC_CTYPE="C"LC_NUMERIC="C"LC_TIME="C"LC_COLLATE="C"LC_MONETARY="C"LC_MESSAGES="C"LC_PAPER="C"LC_NAME="C"LC_ADDRESS="C"LC_TELEPHONE="C"LC_MEASUREMENT="C"LC_IDENTIFICATION="C"LC_ALL=[talen@tp-arch-tianfei nginx]$ locale -aCPOSIX[talen@tp-arch-tianfei nginx]$ sudo vim /etc/locale.gen[talen@tp-arch-tianfei nginx]$ cat /etc/locale.gen |grep -v '#'en_US.UTF-8 UTF-8 zh_CN.GBK GBK zh_CN.UTF-8 UTF-8 [talen@tp-arch-tianfei nginx]$ sudo locale-gen Generating locales... en_US.UTF-8... done zh_CN.GBK... done zh_CN.UTF-8... doneGeneration complete.[talen@tp-arch-tianfei nginx]$ locale -aCPOSIXen_US.utf8zh_CN.gbkzh_CN.utf8[talen@tp-arch-tianfei nginx]$ sudo localectl set-locale LANG=en_US.UTF-8[talen@tp-arch-tianfei nginx]$ locale &gt; ~/.config/locale.conf[talen@tp-arch-tianfei nginx]$ sed -i 's/=.*/="en_US.UTF-8"/' ~/.config/locale.conf [talen@tp-arch-tianfei ~]$ localeLANG=CLC_CTYPE="C"LC_NUMERIC="C"LC_TIME="C"LC_COLLATE="C"LC_MONETARY="C"LC_MESSAGES="C"LC_PAPER="C"LC_NAME="C"LC_ADDRESS="C"LC_TELEPHONE="C"LC_MEASUREMENT="C"LC_IDENTIFICATION="C"LC_ALL=[talen@tp-arch-tianfei ~]$ LANG= source /etc/profile.d/locale.sh[talen@tp-arch-tianfei ~]$ localeLANG=CLC_CTYPE=en_US.UTF-8LC_NUMERIC=en_US.UTF-8LC_TIME=en_US.UTF-8LC_COLLATE=en_US.UTF-8LC_MONETARY=en_US.UTF-8LC_MESSAGES=en_US.UTF-8LC_PAPER=en_US.UTF-8LC_NAME=en_US.UTF-8LC_ADDRESS=en_US.UTF-8LC_TELEPHONE=en_US.UTF-8LC_MEASUREMENT=en_US.UTF-8LC_IDENTIFICATION=en_US.UTF-8LC_ALL=[talen@tp-arch-tianfei t.web]$ ls apache http401认证请求.png 'http method1.png' http常见状态码.png http状态码.png tomcat apache整合tomcat多实例多网站.png httpbase64.png 'http method.png' http报文.png http盲中继keep-alive挂起问题 代理与网关区别 http401认证请求 httpbase65.png http常用方法.png http报文内容 nginx 基本web服务器请求步骤]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>terminal</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[react study]]></title>
    <url>%2F2019%2F08%2F01%2Freact-study%2F</url>
    <content type="text"><![CDATA[React学习笔记graph TB JavaScript-->JavaScript_runtime JavaScript_runtime-->Node.js JavaScript-->v8 v8(Google Chrome V8 引擎)-->Node.js Node.js-->webpack(npm package 管理器) webpack(webpack 打包器)-->npm JSX-->babel(babel编译器) npm-->create-react-app(create-react-app官方脚手架) create-react-app-->React(React framework) React_component(React 组件化三大基本要素) babel-->React_component(React) render-->React_component React_component-->React React-->vdom(虚拟DOM) React-->diff(DIFF算法) out_data(外部数据)-->this.props this.props-->render(render方法) bindin(内部数据)-->this.state this.state-->render add-dom(步骤 1 添加一个 DOM 容器到 HTML)-->script-tag(步骤 2 添加 Script 标签) script-tag-->create_react(步骤 3创建一个 React 组件) 面向数据编程 语法 … 展开运算符 组件 父组件通过属性向子组件传递参数 子组件通过this.props接收父组件传递过来的参数值 子组件如想和父组件通信,需要调用父组件传递过来的方法 123456789class HelloMessage extends Reacts.Component&#123; render()&#123; return( &lt;div&gt; hello, &#123;this.props.name&#125; &lt;/div&gt; ); &#125;&#125;]]></content>
      <categories>
        <category>react</category>
        <category>front-end</category>
      </categories>
      <tags>
        <tag>react</tag>
        <tag>front-end</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python errors]]></title>
    <url>%2F2019%2F07%2F31%2FPython-errors%2F</url>
    <content type="text"><![CDATA[python Errors 原因Q112345672019-07-31 17:23:44,663 - jms_perm.py - INFO - perm_key: ([&apos;名字(zhi.ming)&apos;], [&apos;v-hostname.hx(10.10.100.100)&apos;])Traceback (most recent call last): File &quot;jms_perm.py&quot;, line 338, in &lt;module&gt; perm_args_list = perm_process() File &quot;jms_perm.py&quot;, line 318, in perm_process long_time_perms[perm_key] = permTypeError: unhashable type: &apos;list&apos; A1Python dict的key必须为hashable 问题中key中包含list或dict类型,所以报错. 可哈希的元素有：int, float, str, tuple 不可哈希的元素有：list, set, dict 简单说在元素生命周期中,元素值会发布变动的为unhashable]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[git change user name in history commits]]></title>
    <url>%2F2019%2F07%2F26%2Fgit-change-user-name-in-history-commits%2F</url>
    <content type="text"><![CDATA[Git 修改历史提交记录中的用户名背景之间git提交时的用户名不对,但已经提交了4个commit了,所以需要修改历史记录中的用户名. 方案使用git rebase git rebase会把基于 rebase的版本后的commit取消掉,并临时保存为path到.git/reabase目录中,然后把当前分支更新到rebase的分支,最后把你修改的成为path的版本以补丁的形式应用到rebase的版本上. 操作这里把要rebase到4个commit之前的一个版本 12345678910111213141516171819202122232425262728293031[Fri Jul 26 talen@tp-arch-tianfei capacity]$ git rebase -i HEAD~5pick 7e1b101 X0pick 983d257 X1pick 17c4a0e X2pick 41e90ef X3pick 822104d X4# Rebase 5131eea..822104d onto 41e90ef (5 commands)## Commands:# p, pick &lt;commit&gt; = use commit# r, reword &lt;commit&gt; = use commit, but edit the commit message# e, edit &lt;commit&gt; = use commit, but stop for amending# s, squash &lt;commit&gt; = use commit, but meld into previous commit# f, fixup &lt;commit&gt; = like "squash", but discard this commit's log message# x, exec &lt;command&gt; = run command (the rest of the line) using shell# b, break = stop here (continue rebase later with 'git rebase --continue')# d, drop &lt;commit&gt; = remove commit# l, label &lt;label&gt; = label current HEAD with a name# t, reset &lt;label&gt; = reset HEAD to a label# m, merge [-C &lt;commit&gt; | -c &lt;commit&gt;] &lt;label&gt; [# &lt;oneline&gt;]# . create a merge commit using the original merge commit's# . message (or the oneline, if no original merge commit was# . specified). Use -c &lt;commit&gt; to reword the commit message.## These lines can be re-ordered; they are executed from top to bottom.## If you remove a line here THAT COMMIT WILL BE LOST.## However, if you remove everything, the rebase will be aborted.## Note that empty commits are commented out 12345Stopped at 4ac3916... X0You can amend the commit now, withgit commit --amend Once you are satisfied with your changes, rungit rebase --continue vi修改X1-X4的pick为edit,X0是rebase的版本,wq:退出 1[Fri Jul 26 talen@tp-arch-tianfei capacity]$ git commit --amend --author="tianfei.hao &lt;tianfei.hao@example.com&gt;" --no-edit 修改正确的用户名及邮箱 12[Fri Jul 26 talen@tp-arch-tianfei capacity]$ git rebase --continue[Fri Jul 26 talen@tp-arch-tianfei capacity]$ git push origin new_journey --force 强制提交操作]]></content>
      <categories>
        <category>git</category>
      </categories>
      <tags>
        <tag>git</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python学习笔记]]></title>
    <url>%2F2019%2F07%2F25%2Fpython%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[python 笔记设计模型1. 装饰器(decorator)模式(俄罗斯套娃封装) 123@装饰器二 @装饰器一 核心对象 创建一个装饰函数,内部定义一个wrapper新函数执行一些操作,将被装饰函数作为参数传入装饰函数,返回新函数 行为类似多重继承. 当在装饰器与继承之间选择时,只需要根据一些条件对对象进行动态修改时使用装饰器. 日志装饰器,传递一些参数动态记录日志 作用: 增强核心对象的能力 让核心对象支持多种可选行为 编写判断执行不同的装饰器 2. 观察者模式状态监测,事件处理 1核心对象-&gt;update()-&gt;观察者们-&gt;各自处理自已的任务 3. 策略模式每个策略类都包含同名方法,接收相同参数. 12核心对象-&gt;策略1核心对象-&gt;策略2 4.状态模式状态类的目的是实现状态转换,需要一个上下文类提供转换接口和指针指向状态类,状态类对前面的调用者是隐藏的. 123456Context -&gt; state -&gt; [state1, state2, state3] -&gt; Parser OpenTag ||FirstTag -&gt; ChildNode &lt;=&gt; Text || CloseTag 策略模式用于运行时选择一种算法,如一张图片根据不同的情况处理成不同的状态 状态模式用于允许在不同状态之间进行动态切换,如解析XML文件,context上下文切换 5.单件模式只有一个实例的对象类. 模块级实例变量能够模仿单件实例 6.模板模式7.适配模式(adapter)接口适配转换 8.外观模式(facade)为复杂的组件提供典型用途的简单接口,如requests为urllib,编写发送邮件的类为smtplib,samplib等 9.享元模式专为节省内存而设计的,如果有成百上千的相同对象,将相同特性整合进一个享元可极大减少内存消耗. 10.命令模式11.抽象工厂模式12.组合模式简单的组件构成复杂的树状结构 迭代器iterator&amp;递归器 迭代器 字符串(有时需要将字符串视为原子的.否则有时有可能导致无穷递归.) 每次只取一个对象,不会对内存造成巨大开销. 递归器 表达式 &amp; 语句 表达式有返回值 yield是表达式,所以调用生成器需要next()来执行表达式 send是传递值给yield表达式 python 运算符Python逻辑运算符Python语言支持逻辑运算符，以下假设变量 a 为 10, b为 20: 运算符 逻辑表达式 描述 实例 and x and y 布尔”与” - 如果 x 为 False，x and y 返回 False，否则它返回 y 的计算值。 (a and b) 返回 20。 or x or y 布尔”或” - 如果 x 是非 0，它返回 x 的值，否则它返回 y 的计算值。 (a or b) 返回 10。 not not x 布尔”非” - 如果 x 为 True，返回 False 。如果 x 为 False，它返回 True。 not(a and b) 返回 False 数学运算123456789+ plus- minus/ slash* asterisk% percent&lt; less-than&gt; greater-than&lt;= less-than-equal&gt;= greater-than-equal print1print "If I add %d, %r, and %d I get %d." % (my_age, my_height, my_weight, my_age + my_height + my_weight) 标识符 %s, %r, %d byte &amp; stringUnicode字符串和二进制数据流 123456789101112131415161718# bytes objectb = b"example"# str objects = "example"# str to bytesbytes(s, encoding = "utf8")# bytes to strstr(b, encoding = "utf-8")# an alternative method# str to bytesstr.encode(s)# bytes to strbytes.decode(b) 编码就是把一个字符用一个二进制来表示。字符串类str里有一个encode()方法，它是从字符串向比特流的编码过程。而bytes类型恰好有个decode()方法，它是从比特流向字符串解码的过程。ASCII码，一种8位即1个字节的编码规范，它可以涵盖整个英语系的编码需要。python 中编码print后会以ascii编码方式显示,所以中文会显示16进制,英文会直接显示ascii后的原文. 世界标准: ASCII(en:1byte,8bits) =&gt; unicode(en:2bytes,16bits; cn:3bytes,24bits) =&gt; utf-8(en:1byte,8bits; cn:3bytes,24bits) 中国标准 GBK 2bytes, 16bits 输入raw_input() Parametersargument 命令行参数Parameters 文件读写close – Closes the file. Like File-&gt;Save.. in your editor.read – Reads the contents of the file. You can assign the result to a variable.readline – Reads just one line of a text file.truncate – Empties the file. Watch out if you care about the file.write(‘stuff’) – Writes “stuff” to the file. 函数 匿名函数 lambda x: x * 8 回调函数 作为参数传入中间函数的函数 回调实际上有两种：阻塞式回调和延迟式回调。两者的区别在于：阻塞式回调里，回调函数的调用一定发生在起始函数返回之前；而延迟式回调里，回调函数的调用有可能是在起始函数返回之后。 中间函数 需要传入回调函数的函数 起始函数 调用中间函数的函数 装饰函数 ​ 代码风格 123456789101112def logging_tool(func): def wrapper(*arg, **kwargs): logging.info('%s is running...' % func.__name__) # 把today当作参数传递进来，执行func()就相当于执行today() func() return wrapper @logging_tool def today(): print('2018-05-25') today() 多进程,多线程What is a process? A process is just an instance of an executing program.sbla(socket, bind, listen, accept)process -&gt; UNIX fork() 进程&gt;线程&gt;协程 Python对协程的支持是通过generator实现的。 子程序顺序栈式调用,不可乱序 协程(Coroutine)中断式调用,可乱序 子程序，或者称为函数，在所有语言中都是层级调用(栈式调用)，比如A调用B，B在执行过程中又调用了C，C执行完毕返回，B执行完毕返回，最后是A执行完毕。 子程序调用总是一个入口，一次返回，调用顺序是明确的。而协程的调用和子程序不同。 Python中的协程大概经历了如下三个阶段： 最初的生成器变形yield/send 引入@asyncio.coroutine和yield from 在最近的Python3.5版本中引入async/await关键字 生成器(generator)(协程)(yield,需要多次调用:执行先中断,返回变量,再执行.)函数是顺序执行,生成器也是顺序计算的. 协程看上去也是子程序，但执行过程中，在子程序内部可中断，然后转而执行别的子程序，在适当的时候再返回来接着执行。 注意，在一个子程序中中断，去执行其他子程序，不是函数调用，有点类似CPU的中断。 列表推导式 -&gt; [] 直接打印 生成器推导式 -&gt; () next(generator)激活,最后一个返回StopIteration error generator保存的是算法,调用才开始计算 可迭代对象 生成器并没有将所有值放入内存中，而是实时地生成这些值，并且不会保存上一次迭代生成的值，因而，在迭代一个比较大的数据的时候，使用迭代器更好 yield 的作用就是返回迭代器 python直到遇到关键字yield之后，中断代码执行，返回yield变量值 send 函数就是给yield语句赋值 先调用,返回原值(send并不会改变yield的返回值) 发送send,修改变量,并返回next值 因为当send方法的参数为None时，它与next方法完全等价(不规范,慎用) close可以关闭生成器 生成器使用场景 项目中如何使用yield，使用的思路就是，中断代码执行，在yield之前打开一个资源，然后在yield之后关闭这个资源，这样可以很好地保证每次只有一个资源被打开，同时执行完成之后资源会被关闭 第二个思路，就是节约内存，不要一下子加载所有的资源 条件判断if 语句的判断条件可以用&gt;（大于）、&lt;(小于)、==（等于）、&gt;=（大于等于）、&lt;=（小于等于）来表示其关系。 True &amp; False针对Python中的True和False的定义，在不同版本的Python中是这样定义的： Python 2：None, 0, 和空字符串都被算作 False，其他的均为 True Python 3：None，0，空字符串，空列表，空字典都算是False，所有其他值都是True 面向对象 编写代码首要考虑它的可读性(DRY不要让自己重复) 继承(超类里也可定义子类才有的方法,使得自己成为通用类) 组合(大部分继承关系都可以建模替代为组合关系,反之大部分组合都不能建模为继承) 关联 如果只对数据操作-&gt;使用python数据结构 如果只关注行为不存储数据-&gt;使用函数 如果同时包含数据和行为 -&gt;使用对象-&gt;代码更易读而不关心长短,对象之间的继承,关联,组合. 随着程序的进一步扩展,需要把一组相关的变量传递到不同的函数中,这是一个将变量函数组合成类的好场景.(数据与行为的分离) 存储数据(名词) 数据对象CRUD操作行为使用property 参数也是另一种对象类型(自身就是文档) 数据行为操作(动词) 为了看起来像函数一样更易用,可以在init构造函数中接收参数而不是在方法中. 管理对象(有点类似之前自己使用main实现的函数,保证步骤顺序) python不像java语言,类私有变量可以直接访问,所以变量可以直接访问,无需访问方法. 使用property优雅的处理对象属性:可以直接访问name-&gt;property构造函数-&gt;调用方法,看起来跟直接访问属性一样. 123456789101112131415161718class Color: def __init__(self, rgb_value, name): self.rgb_value = rgb_value self._name = name def _set_name(self, name): if not name: raise Exception("Invalid Name") def _get_name(self): return self._name name = property(_get_name, _set_name)# or 另一种风格 @property # foo.getter 对于长消耗的操作,可以只取一次然后缓存起来. def foo(self): return self._foo @foo.setter def foo(self, value): self._foo = value 其它123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256from __future__ import absolute_import*** 忽略当前包下的模块,导入系统模块.相对导入：在不指明 package 名的情况下导入自己这个 package 的模块，比如一个 package 下有 a.py 和 b.py 两个文件，在 a.py 里 from . import b 即是相对导入 b.py。绝对导入：指明顶层 package 名。比如 import a，Python 会在 sys.path 里寻找所有名为 a 的顶层模块。from __future__ import absolute_import: 在 3.0 以前的旧版本中启用相对导入等特性所必须的 future 语句。如果你在main.py中写import string,那么在Python 2.4或之前, Python会先查找当前目录下有没有string.py, 若找到了，则引入该模块，然后你在main.py中可以直接用string了。如果你是真的想用同目录下的string.py那就好，但是如果你是想用系统自带的标准string.py呢？那其实没有什么好的简洁的方式可以忽略掉同目录的string.py而引入系统自带的标准string.py。这时候你就需要from __future__ import absolute_import了。---------------------相同缩进：开始缩进，短语句可以直接跟在：后面;可以连接多个操作语句＃注释'''大段注释'''"""大段注释"""基本输入：raw_input()基本输出：print()#-*- coding:utf-8 -*- 解决中文乱码print(var.decode('utf-8').encode('cp936'))交互命令下可以当计算器使用。import math基本的数学模块数据类型是程序的基础。程序设计的本质就是对数据进行处理。使用python数据结构基本不用考虑自己重新定义数据结构。数字,python中可以使用任意大的数字。 基本类型：（整数，长整数，浮点数，复数），使用前无需声明其类型。 运算符：**,*,/,%,+,-,|,^,&amp;,&lt;&lt;,&gt;&gt;按优先级下降&gt;&gt;&gt; 2.30-1.300.9999999999999998由于浮点数精度问题。&gt;&gt;&gt; 5^3 101^011=1106&gt;&gt;&gt; 11|5 1011|0101=111115&gt;&gt;&gt; 4&lt;&lt;2 100&lt;&lt;2=10000 等同于4*2**216字符串：'',"",""" """,''' ''' 转义符：\n,\t,\r,\\,\',\" 原始字符串：R或r开头 str操作方法：https://docs.python.org/3.5/library/stdtypes.html#string-methods 字符串索引，分片 [] 字符串格式化：%c单字符,%d十进制数,%o八进制数,%s字符串,%x十六进制数，字母小写,%X十六进制数，字母大写 %c%s%d % ('a','talen',5)&gt;&gt;&gt; print( "%c%s%d" % ('a','talen',5))atalen5字符串与数字的相互转换 int(str),str(int)&gt;&gt;&gt; int("10") +414列表list[]字典dict&#123;key:value&#125;fileif,elseforwhile函数：def name(args): returnpython 对象 元素 数据结构 自定义类 容器 序列 （迭代，索引，分片，加，乘，成员资格，最大，最小，长度） 列表 元组 字符串 Ｕnicode对象 buffer对象 xrange对象 映射 字典（python惟一内置映射类型） 集合 语句包import 模块 函数（参数），函数可嵌套函数 内置函数 外置导入，from 模块名 import 函数，可以使用变量引用函数，效果等同函数操作。 类型对象模块名.函数多态：操作的意义取决于操作对象的类型第4章：python的核心对象类型 数字、列表、字典、元组、第5章：数字 对象是python中最基本的概念，python编程的基础是对象。 python完整数字类型工具： 整数与浮点数 复数 固定精度的十进制数 有理分数 集合 布尔类型 无穷的整数精度 各种数字内置函数和模块 内置表达式操作符： + - * / &gt;&gt; ** &amp;等。 表达式是处理数字的最基本工具。 混合操作符表达式的优先级P120表5.2.越向后优先级越高。 使用（）分组子表达式改变优先级。 混合数字类型操作会将简单类型升级为复杂类型再计算。复杂度：整型&lt;浮点&lt;复数 内置数学函数： pow, abs, round, int, hex, bin等 公用模块： random, math等 变量： 变量在它第一次赋值时创建。 变量在表达式中使用将被替换为它们的值。 变量在表达式中使用前必须赋值。 变量像对象一样不需要一开始进行声明。 数字的显示格式： repr代码交互式 str用户友好式 比较：一般比较与连续的长比较 对数字启作用，比较结果是一个布尔类型 python基础教程 第１章 基础知识 列表，字符串，字典是python中最重要的三种数据类型。 第２章 列表(可变)与元组（不可变） 数据结构：是通过方式对元素的集合 容器数据结构：包含其它对象的任意对象。主要有序列（列表，元组等）与映射（字典等），集合。 序列中的每个元素都有一个编号，映射每个元素都有一个键。 python中最基本的数据结构是序列（内置６种，重点包括元组与列表，其它有字符串，Unicode字符串，buffer对象，xrange对象），元素序号是索引。 操作一组数值时，使用序列。 序列中可以包含序列。 序列操作： 索引 &gt;&gt;&gt; getting = 'hello' &gt;&gt;&gt; getting[1] 'e' &gt;&gt;&gt; getting[-1] 'o' &gt;&gt;&gt; 'hello'[1] 'e' 分片 冒号分割，２个索引作为边界，每１个索引在分片内，第２个在分片外。 使用捷径 更大的步长，使用负数做为步长时，必须让开始点大于结束点。 加 相同类型的序列才可以连接。 乘 None内置代表空 * 成员资格 in 返回True False 长度，最大元素，最小元素。 迭代(interation)： 依次对序列中的元素重复执行操作。 列表 [a,b,n...] list() 元素赋值，元素删除，分片赋值，列表方法。 列表方法： 方法是函数,但只对特定对象进行操作，如序列，字典等。 对象.方法（参数） append 入𣏾 count extend index insert pop 惟一一个修改列表并返回值的方法。出𣏾 remove 移出但不返回值，跟pop不同。 reverse 反序 sort 高级排序 cmp,key,reverse 元组：不可变序列 (a,n...) tuple 第３章 使用字符串 基本字符串操作 适用所有标准序列操作，如上一章 字符串如元组一样不可修改 字符串操作符% format % values values一般是元组，字典可格式多个值。如果使用列表，只能格式为一个值。 %.3f %s 模板字符串 from string import Template 变量.substitute() 字段宽度和精度 转换说明符可以包括字段宽度与精度。 可以使用＊号作为字体宽度或精度，这个值可以从后面的元组中读取。 标表 0,-,+,' '，放置在宽度或精度字段。 对齐，０填充。 字符串方法： find 返回最左端的索引 字符串.find('内容',起点，终点) split join相反的操作。分割，合并字符串 join添加的队列必须是字符串。 lower replace strip 去除两侧空格。 translate 只替换单个字符。 第４章 字典：当索引不好用时 ４.１字典的使用 &#123;k键:v值&#125; 4.2 创建与使用字典 4.2.1 dict函数 4.2.2 基本字典操作 键类型：更多类型 自动添加：列表不能不使用append的方法外自动建立。 成员资格：字典比列表检查成员资格更高效。 第５章 条件、循环、其它语句 5.1 print,import print 逗号输出多个表达式 +链接字符没有空格输出，逗号有空格输出。 from module import function as name 5.2 赋值魔法 序列解包 链式赋值 增量赋值 +=,*=,/=,%= 5.3 语句块：缩排的乐趣 布尔变量：假：false None 0 "" () [] &#123;&#125; 布尔函数：bool 5.4 条件 if : elif: else: 使用==判断两个对象是否相等，使用is判断两者是否等同。 多重if可以用布尔判断代替。 命名空间：作用域：in scope ,调用使用scope()函数 第６章 抽象abstraction 抽象结构：组织可读性程序，细节在其它地方定义。 函数： 调用（）中的参数或值，执行一系列操作，返回一个值。 创建函数是组织程序的关键。 def 函数名（参数） 操作 return result 记录函数：文档字符串,在函数开头写，使用函数.__doc__访问。 形参,实参 def 形参 调用 实参 函数内的局部作用域 使用关键字参数忘记顺序 使用多个参数 *是生成元组，**生成字典 python 命令空间，作用域，变量是不可见的字典 vars() local variable globals 变量名可以在函数作用域内定义全局变量。 递归：引用自身，调用自身的意思。＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝ 二元搜索 第７章 更加抽象，创建自己的数据类型自定义类。 面向对象的编程。 核心概念。 object.method()对象.方法() 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152baseexcept(SystemExit , KeyboardInterrupt , and GeneratorExit (these three derive directly from BaseException instead). exception arithmeticerror(the superclass of Over flowError , ZeroDivisionError , and FloatingPointError ,and a subclass of Exception .) buffererror类: 动: 方法 静: 数据 带访问控制的数据属性(property)(getter,setter,deleter,text)(自动调用一些自定义动作) 第三节:没有self的类变量会被所有类实例共享,作用域是类;self变量作用域是类实例,只有类实例可以使用.新式父类调用super().__init__(name, email)旧式父类调用super(subclass_name).__init__(name, email)多态:调用不同的子类实现不同的行为.different behaviors happen depending on which subclass is being used, without having to explicitly know what the subclass actually is.python的动态特性让其它编程中的多态变得不太重要.class AudioFile: def __init__(self, filename): if not filename.endswith(self.ext): # 父类并没有定义ext变量,但可以访问子类中的变量 raise Exception(&quot;Invalid file format&quot;) self.filename = filename class MP3File(AudioFile): ext = &quot;mp3&quot; def play(self): print(&quot;playing &#123;&#125; as mp3&quot;.format(self.filename))类静态方法(staticmethod)与类关联,被所有类实例共享异常: BaseException SystemExist KeyboardInterrupt Exception Most other Exceptionsexcept:或except BaseException:将捕捉所有异常except Exception:只捕捉Exception类对于一些使用if else的语句,也可以使用异常来做程序流控,会更简洁.property声明]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[使用nvm管理node版本]]></title>
    <url>%2F2019%2F07%2F25%2F%E4%BD%BF%E7%94%A8nvm%E7%AE%A1%E7%90%86node%E7%89%88%E6%9C%AC%2F</url>
    <content type="text"><![CDATA[nvm管理node版本安装curl -o- https://raw.githubusercontent.com/creationix/nvm/v0.33.8/install.sh|bash 配置环境1234567[Wed Jul 24 talen@tp-arch-tianfei ~]$ vim ~/.bashrc# nvmexport NVM_NODEJS_ORG_MIRROR=https://npm.taobao.org/mirrors/node#source /usr/share/nvm/init-nvm.shexport NVM_DIR="$HOME/.nvm"[ -s "$NVM_DIR/nvm.sh" ] &amp;&amp; \. "$NVM_DIR/nvm.sh" # This loads nvm[ -s "$NVM_DIR/bash_completion" ] &amp;&amp; \. "$NVM_DIR/bash_completion" # This loads nvm bash_completion 查看lts版本123456[Wed Jul 24 talen@tp-arch-tianfei ~]$ nvm ls-remote --lts v4.2.0 (LTS: Argon)... v10.15.2 (LTS: Dubnium)-&gt; v10.15.3 (LTS: Dubnium) v10.16.0 (Latest LTS: Dubnium) 安装指定版本1234567891011121314151617181920212223[Wed Jul 24 talen@tp-arch-tianfei ~]$ nvm install v10.16.0Downloading and installing node v10.16.0...Downloading https://npm.taobao.org/mirrors/node/v10.16.0/node-v10.16.0-linux-x64.tar.xz...################################################################################################## 100.0%Computing checksum with sha256sumChecksums matched!Now using node v10.16.0 (npm v6.9.0)[Wed Jul 24 talen@tp-arch-tianfei ~]$ node -vv10.16.0[Wed Jul 24 talen@tp-arch-tianfei ~]$ nvm lsv10.15.3-&gt; v10.16.0v12.2.0systemdefault -&gt; lts/* (-&gt; v10.16.0)node -&gt; stable (-&gt; v12.2.0) (default)stable -&gt; 12.2 (-&gt; v12.2.0) (default)iojs -&gt; N/A (default)lts/* -&gt; lts/dubnium (-&gt; v10.16.0)lts/argon -&gt; v4.9.1 (-&gt; N/A)lts/boron -&gt; v6.17.1 (-&gt; N/A)lts/carbon -&gt; v8.16.0 (-&gt; N/A)lts/dubnium -&gt; v10.16.0 切换版本1234567891011[Wed Jul 24 talen@tp-arch-tianfei ~]$ nvm use v10.16.0Now using node v10.16.0 (npm v6.9.0)[Wed Jul 24 talen@tp-arch-tianfei ~]$ nvm currentv10.16.0[Wed Jul 24 talen@tp-arch-tianfei ~]$ which npm/home/talen/.nvm/versions/node/v10.16.0/bin/npm[Wed Jul 24 talen@tp-arch-tianfei ~]$ which node/home/talen/.nvm/versions/node/v10.16.0/bin/node[Thu Jul 25 talen@tp-arch-tianfei github]$ nvm use lts/*Now using node v10.16.0 (npm v6.9.0)]]></content>
      <categories>
        <category>front-end</category>
      </categories>
      <tags>
        <tag>nodejs</tag>
        <tag>npm</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Django2.2 url path error]]></title>
    <url>%2F2019%2F04%2F30%2FDjango2-2-url-path-error%2F</url>
    <content type="text"><![CDATA[123WARNINGS:?: (2_0.W001) Your URL pattern &apos;nagios/alert/(?P&lt;pk&gt;\d+)/delete/&apos; [name=&apos;nagios-alert-delete&apos;] has a route that contains &apos;(?P&lt;&apos;, begins with a &apos;^&apos;, or ends with a &apos;$&apos;. This was likely an oversight when migrating to django.urls.path().?: (2_0.W001) Your URL pattern &apos;nagios/alert/(?P&lt;pk&gt;\d+)/update/&apos; [name=&apos;nagios-alert-edit&apos;] has a route that contains &apos;(?P&lt;&apos;, begins with a &apos;^&apos;, or ends with a &apos;$&apos;. This was likely an oversight when migrating to django.urls.path(). 搜索了一下,URL中有正则表达式的需要使用re_path代替path,修改后修复 12re_path(&apos;nagios/alert/(?P&lt;pk&gt;\d+)/update/&apos;, views.AlertEditView.as_view(), name=&apos;nagios-alert-edit&apos;),re_path(&apos;nagios/alert/(?P&lt;pk&gt;\d+)/delete/&apos;, views.AlertDeleteView.as_view(), name=&apos;nagios-alert-delete&apos;), 123456789(study-xiaofanzhuo) [tianfei@tianfei-pc xiaofanzhuo]$ python manage.py runserverWatching for file changes with StatReloaderPerforming system checks...System check identified no issues (0 silenced).April 30, 2019 - 16:40:40Django version 2.2, using settings &apos;xiaofanzhuo.settings&apos;Starting development server at http://127.0.0.1:8000/Quit the server with CONTROL-C.]]></content>
      <categories>
        <category>django</category>
      </categories>
      <tags>
        <tag>django</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[运维常用术语]]></title>
    <url>%2F2019%2F04%2F12%2F%E8%BF%90%E7%BB%B4%E5%B8%B8%E7%94%A8%E6%9C%AF%E8%AF%AD%2F</url>
    <content type="text"><![CDATA[12TCO（总体拥有成本）黑石物理服务器2.0: 基于腾讯云最新虚拟化技术研发的一款拥有极致性能裸金属云服务器 1234云盾Web应用防火墙（Web Application Firewall，简称 WAF）基于云安全大数据能力，用于防御SQL注入、XSS跨站脚本、常见Web服务器插件漏洞、木马上传、非授权核心资源访问等OWASP常见攻击，并过滤海量恶意CC攻击，避免您的网站资产数据泄露，保障网站的安全与可用性。如何使用WAF您购买Web应用防火墙后，把域名解析到Web应用防火墙提供的CNAME地址上，并配置源站服务器IP，即可启用Web应用防火墙。启用之后，您网站所有的公网流量都会先经过Web应用防火墙，恶意攻击流量在Web应用防火墙上被检测过滤，而正常流量返回给源站IP，从而确保源站IP安全、稳定、可用。]]></content>
      <categories>
        <category>uncategorized</category>
      </categories>
      <tags>
        <tag>untags</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[use /sbin/netconfig 命令更新/etc/resolv.conf文件]]></title>
    <url>%2F2019%2F04%2F01%2Fuse-sbin-netconfig-%E5%91%BD%E4%BB%A4%E6%9B%B4%E6%96%B0-etc-resolv-conf%E6%96%87%E4%BB%B6%2F</url>
    <content type="text"><![CDATA[netconfig是用于设置网络环境的命令 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647haotianfei@tianfei-opensuse:/etc/sysconfig&gt; sudo netconfig --helpUsage: netconfig &lt;global options&gt; netconfig &lt;action&gt; &lt;action options&gt; actions: modify Requires an interface and service specific settings via STDIN or as file using the --input-file or --lease-file option. Already existing settings for this interface and service will be replaced with the new one, otherwise netconfig creates a new state file. Finaly, netconfig updates the managed files. remove Removes the interface and service specific settings and updates the managed files. update Updates the managed files with the current set of settings. batch Executes a batch file with modify,remove,update action lines. Unlike in regular actions, modify and remove do not call update. modify options: &lt; -s|--service &lt;service name&gt; &gt; service providing settings [ -i|--interface &lt;interface name&gt; ] interface providing settings [ -F|--input-format &lt;input format&gt; ] currently &apos;dhcpcd&apos; supported only [ -I|--input-file &lt;file name&gt; ] file name to read, stdin by default [ -l|--lease-file &lt;file name&gt; ] alias for --input-file [ -m|--module-only &lt;name | prefix&gt; ] module or module group updates only [ -f|--force-replace ] generate files, even user modified [ -v|--verbose ] enable debug and be verbose remove options: &lt; -s|--service &lt;service name&gt; &gt; service providing settings [ -i|--interface &lt;interface name&gt; ] interface providing settings [ -m|--module-only &lt;name | prefix&gt; ] module or module group updates only [ -f|--force-replace ] generate files, even user modified [ -v|--verbose ] enable debug and be verbose update options: [ -m|--module-only &lt;name | prefix&gt; ] module or module group updates only [ -f|--force-replace ] generate files, even user modified [ -v|--verbose ] enable debug and be verbose batch options: [ -B|--batch-file &lt;file name&gt; ] file name to read, stdin by default [ -v|--verbose ] enable debug and be verbose global options: &lt;-h|--help&gt; show this help textActive modules: dns-resolver dns-bind dns-dnsmasq nis ntp-runtimeModule groups : dns nis ntp 注意help中的update,如果网络配置不正常,可以使用netconfig update -f强制修复 1234567haotianfei@tianfei-opensuse:/etc/sysconfig&gt; sudo netconfig update&lt;13&gt;Apr 1 09:53:46 dns-resolver: ATTENTION: You have modified /etc/resolv.conf. Leaving it untouched...&lt;13&gt;Apr 1 09:53:46 dns-resolver: You can find my version in /etc/resolv.conf.netconfigATTENTION: You have modified /etc/resolv.conf. Leaving it untouched...You can find my version in /etc/resolv.conf.netconfig ...haotianfei@tianfei-opensuse:/etc/sysconfig&gt; sudo netconfig update -f&lt;13&gt;Apr 1 09:54:03 dns-resolver: force replace set: backup created as /etc/resolv.conf.20190401-095403]]></content>
      <categories>
        <category>opensuse</category>
      </categories>
      <tags>
        <tag>opensuse</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[use imagemagick convert命令批量resize图片]]></title>
    <url>%2F2019%2F03%2F30%2Fuse%20imagemagick%20convert%20%E5%91%BD%E4%BB%A4%E6%89%B9%E9%87%8Fresize%E5%9B%BE%E7%89%87%2F</url>
    <content type="text"><![CDATA[1for img in $(ls);do convert -resize 40%x40% -quality 80 $img convert_$img;done 图片质量还是可以的,对于3M左右的图片,压缩到40%,质量80差不多300多K的样子,只需要1/10的存储空间]]></content>
      <categories>
        <category>uncategorized</category>
      </categories>
      <tags>
        <tag>untags</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[zabbix always in progress problem]]></title>
    <url>%2F2019%2F02%2F28%2Fzabbix-always-in-progress-problem%2F</url>
    <content type="text"><![CDATA[zabbix告警触发时一直显示in progress状态,查询了许多资料都没有解决.后来发现media脚本是pyc,更换成py后解决.这个有点太无语了.]]></content>
      <categories>
        <category>zabbix</category>
      </categories>
      <tags>
        <tag>zabbix</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[15 zabbix 自动发现discover]]></title>
    <url>%2F2019%2F02%2F19%2F15-zabbix-%E8%87%AA%E5%8A%A8%E5%8F%91%E7%8E%B0discover%2F</url>
    <content type="text"><![CDATA[网络发现zabbix提供自动网络发现功能是非常高效灵活的.使用网络发现 提高部署效率 简化管理 自动管理 自动发现基于以下信息: IP段 可用的外部服务访问(FTP,SSH,WEB,POP3,IMAP,TCP,etc) 非加密的zabbix agent信息 snmp agent信息 目前还不具有的功能: 网络拓扑 网络发现主要有两个部分:discovery-&gt; action discover周期性的扫描在network discovery rules 中定义的IP段.频率在每个规则下分别设置.每个rule只会被一个process处理.一个网段不会被分配到多个process.discovery checks 分别独立处理,一个check失败并不影响其它check的执行.每个check生成一个discovery event. 1zabbix 24712 0.0 0.1 300100 5908 ? S Feb05 1:02 \_ /usr/sbin/zabbix_server: discoverer #1 [processed 0 rules in 0.001094 sec, idle 60 sec] actiondiscovery event是actions的基础.action可以执行以下操作: 发送信息 Adding/removing hosts Enabling/disabling hosts Adding/removing hosts to/from a group Linking hosts to/unlinking from a template Executing remote scripts]]></content>
      <categories>
        <category>zabbix</category>
      </categories>
      <tags>
        <tag>zabbix</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Prometheus 架构分析]]></title>
    <url>%2F2019%2F02%2F18%2FPrometheus-%E6%9E%B6%E6%9E%84%E5%88%86%E6%9E%90%2F</url>
    <content type="text"><![CDATA[]]></content>
      <categories>
        <category>kubernetes</category>
      </categories>
      <tags>
        <tag>prometheus</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[salt配置]]></title>
    <url>%2F2019%2F02%2F12%2Fconfiguring-salt%2F</url>
    <content type="text"><![CDATA[配置salt这一部分将展示如何配置用户访问,查看和存储job结果,安全性,排错和其它管理任务. Configuring the Salt Master Configuring the Salt Minion Configuring the Salt Proxy Minion Configuration file examples Minion Blackout Configuration Access Control System Job Management Managing the Job Cache Storing Job Results in an External System Logging External Logging Handlers salt.log.handlers.fluent_mod salt.log.handlers.log4mongo_mod salt.log.handlers.logstash_mod salt.log.handlers.sentry_mod Salt File Server Git Fileserver Backend Walkthrough MinionFS Backend Walkthrough Salt Package Manager Storing Data in Other Databases Running the Salt Master/Minion as an Unprivileged User Using cron with Salt Use cron to initiate a highstate Hardening Salt Security disclosure policy Salt Transport Master Tops System Returners Renderers配置salt mastersalt系统配置另人惊讶的简单和轻松,两个组件各自有单独的配置文件.salt-master,salt-minion两个文件分别对应两个组件.默认的salt-master组件的配置文件在/etc/salt/master,FREEBSD显著的不同,位置/usr/local/etc/salt. 主master配置/etc/salt/master配置文件用来管理salt-master的行为.约定:被注释的值后面有一个空白行的,表示不需要配置使用默认值.如果没有空白行的表示这个是一个示例,并没有默认值. 12默认的,master会自动包含在master.d/*.conf下的所有配置文件,master.d是一个目录,在master相同的目录级别下.#default_include: master.d/*.conf minions配置配置salt-minion非常简单.一般的,惟一需要设置的值是master,这样minion就知道如何定位master.默认配置文件在/etc/salt/minion,FREEBSE显著不同的,位于/usr/local/etc/salt/minion.]]></content>
      <categories>
        <category>salt</category>
      </categories>
      <tags>
        <tag>salt</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[salt ssh,agentless模式]]></title>
    <url>%2F2019%2F02%2F11%2Fuse-salt-though-ssh-agentless%2F</url>
    <content type="text"><![CDATA[salt ssh执行salt commands及states通过ssh,不需要安装salt-minion. 开始salt ssh方式使用非常简单,通过配置/etc/salt/roster文件定义系统需要连接的主机,salt-ssh命令使用方式跟salt相同. salt ssh在2014.7.0版本产品化 远端需要有至少python2.6(也可以使用-r选项发送原子的ssh命令) 大多数系统中都是使用salt-ssh命令执行 salt ssh并不是用来替代标准的salt通信系统,它提供了不需要zeromq和远程agent的一个选择.由于所有通信都是通过ssh会在速度上慢于salt+zeromq 目前fileserver选项必须会封装,确保关联的文件会使用salt-ssh交付.state模块是例外,在master端编译,进程会找到所有salt://路径指向然后复制打tar包,fileserver封装还在开发中. salt ssh rostersalt roster系统轻松定义远程minions.https://docs.saltstack.com/en/latest/topics/ssh/roster.html#ssh-roster 默认roster文件是在/etc/salt/roster: 1234567web1: host: 192.168.42.1 # The IP addr or DNS hostname user: fred # Remote executions will be executed as user fred passwd: foobarbaz # The password to use for login, if omitted, keys are used sudo: True # Whether to sudo to root, not enabled by defaultweb2: host: 192.168.42.2 123Notesudo works only if NOPASSWD is set for user in /etc/sudoers: fred ALL=(ALL) NOPASSWD: ALL salt-ssh部署ssh key默认salt-ssh将为ssh生成密钥对,默认路径是/etc/salt/pki/master/ssh/salt-ssh.rsa.密钥对将在第一次运行salt-ssh命令时生成. 之后使用ssh-copy-id命令部署公钥到minions. 1ssh-copy-id -i /etc/salt/pki/master/ssh/salt-ssh.rsa.pub user@server.demo.com 可以创建一个简单的脚本: 123456#!/bin/bashif [ -z $1 ]; then echo $0 user@host.com exit 0fissh-copy-id -i /etc/salt/pki/master/ssh/salt-ssh.rsa.pub $1 12./salt-ssh-copy-id.sh user@server1.host.com./salt-ssh-copy-id.sh user@server2.host.com 当公钥部署完成后,salt-ssh就可以控制这些minions了. 调用salt-sshRHEL/centos 5 python2.6 1salt-ssh centos-5-minion -r &apos;yum -y install epel-release ; yum -y install python26&apos; python3.x在2017.7.0版本之前,salt是不支持python3.x,最好使用-r参数.salt-ssh的使用方法跟salt基本相同,有着相似的语法默认salt-ssh使用在远程minions上使用salt执行模块,使用-r会使用raw shell命令 1salt-ssh &apos;*&apos; test.ping salt ssh 使用statesalt ssh 使用state系统与salt一样抽象了相同的接口. salt ssh 使用target只支持glog与regex targets 配置salt ssh还是在/etc/salt/master中.Minion 配置选项可以在master配置中的ssh_minion_opts中配置,也可以在roster中的minion_opts中配置. salt-ssh使用非root用户默认salt读取/etc/salt配置.如果你使用普通用户必须修改pki_dir和cachedir路径,否则会报权限错误.推荐为普通用户创建单独的配置文件并使用-c加载. 使用saltfile定义命令行参数使用saltfile定义命令行参数,可以在一台服务器上管理多个不同的salt项目.可以cd到saltfile的目录执行 1234salt-ssh: config_dir: path/to/config/dir ssh_max_procs: 30 ssh_wipe: True salt-ssh –config-dir=path/to/config/dir –max-procs=30 –wipe * test.ping使用saltfile可简化成salt-ssh * test.ping. saltssh debugsalt-ssh 加 -ltrace 参数或定义SALT_ARGV变量.]]></content>
      <categories>
        <category>salt</category>
      </categories>
      <tags>
        <tag>salt</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[man 手册中的下划线]]></title>
    <url>%2F2019%2F02%2F07%2Fman-%E6%89%8B%E5%86%8C%E4%B8%AD%E7%9A%84%E4%B8%8B%E5%88%92%E7%BA%BF%2F</url>
    <content type="text"><![CDATA[一直印象里觉得man手册中的下划线是个链接,可以跳转到另一个文档.查看了man的help都没有提到这一块知识,后面才发现原来记忆的都是info命令功能;info命令是可以使用tab跳转到另一个文档的.man手册中的下划线单纯就是个下划线标识而已. 1haotianfei@tianfei-opensuse:~&gt; man man 1haotianfei@tianfei-opensuse:~&gt; info zypper]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ssh透传]]></title>
    <url>%2F2019%2F02%2F05%2Fssh%E9%80%8F%E4%BC%A0%2F</url>
    <content type="text"><![CDATA[nodeC节点上有一个HTTP服务器,监听在80端口nodeA节点可以访问nodeB,nodeB可以访问节点nodeC,但nodeA无法直接访问nodeC. [root@nodeB ~]# ssh -N -f -o GatewayPorts=yes -L *:8808:192.168.0.3:80 root@192.168.0.3[root@nodeB ~]# curl http://localhost:8808/zabbix 301 Moved Permanently Moved Permanently The document has moved here.]]></content>
      <categories>
        <category>uncategorized</category>
      </categories>
      <tags>
        <tag>untags</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[postgresql 11 install]]></title>
    <url>%2F2019%2F02%2F05%2Fpostgresql-11-install%2F</url>
    <content type="text"><![CDATA[https://yum.postgresql.org/repopackages.php [root@postgresql ~]# yum install https://download.postgresql.org/pub/repos/yum/11/redhat/rhel-7-x86_64/pgdg-centos11-11-2.noarch.rpm [root@postgresql ~]# yum install postgresql11-server postgresql11-contrib [root@postgresql ~]# /usr/pgsql-11/bin/postgresql-11-setup initdbInitializing database … OK[root@postgresql ~]# ll /usr/lib/systemd/system/ |grep postgre [root@postgresql ~]# systemctl enable postgresql-11 –nowCreated symlink from /etc/systemd/system/multi-user.target.wants/postgresql-11.service to /usr/lib/systemd/system/postgresql-11.service.[root@postgresql ~]# systemctl status postgresql-11● postgresql-11.service - PostgreSQL 11 database server Loaded: loaded (/usr/lib/systemd/system/postgresql-11.service; enabled; vendor preset: disabled) Active: active (running) since Tue 2019-02-05 21:37:11 CST; 43s ago Docs: https://www.postgresql.org/docs/11/static/ Process: 14569 ExecStartPre=/usr/pgsql-11/bin/postgresql-11-check-db-dir ${PGDATA} (code=exited, status=0/SUCCESS) Main PID: 14575 (postmaster) CGroup: /system.slice/postgresql-11.service ├─14575 /usr/pgsql-11/bin/postmaster -D /var/lib/pgsql/11/data/ ├─14577 postgres: logger ├─14579 postgres: checkpointer ├─14580 postgres: background writer ├─14581 postgres: walwriter ├─14582 postgres: autovacuum launcher ├─14583 postgres: stats collector └─14584 postgres: logical replication launcher Feb 05 21:37:11 postgresql.wasu.iot systemd[1]: Starting PostgreSQL 11 database server…Feb 05 21:37:11 postgresql.wasu.iot postmaster[14575]: 2019-02-05 21:37:11.150 CST [14575] LOG: listening on IPv6 address “::1”, port 5432Feb 05 21:37:11 postgresql.wasu.iot postmaster[14575]: 2019-02-05 21:37:11.150 CST [14575] LOG: listening on IPv4 address “127.0.0.1”, port 5432Feb 05 21:37:11 postgresql.wasu.iot postmaster[14575]: 2019-02-05 21:37:11.154 CST [14575] LOG: listening on Unix socket “/var/run/postgresql/.s.PGSQL.5432”Feb 05 21:37:11 postgresql.wasu.iot postmaster[14575]: 2019-02-05 21:37:11.161 CST [14575] LOG: listening on Unix socket “/tmp/.s.PGSQL.5432”Feb 05 21:37:11 postgresql.wasu.iot postmaster[14575]: 2019-02-05 21:37:11.174 CST [14575] LOG: redirecting log output to logging collector processFeb 05 21:37:11 postgresql.wasu.iot postmaster[14575]: 2019-02-05 21:37:11.174 CST [14575] HINT: Future log output will appear in directory “log”.Feb 05 21:37:11 postgresql.wasu.iot systemd[1]: Started PostgreSQL 11 database server. 修改/var/lib/pgsql/11/data/postgresql.conf 1listen_addresses = &apos;*&apos; 修改/var/lib/pgsql/11/data/pg_hba.conf,添加 1host zabbix zabbix 10.0.0.0/25 md5 [root@postgresql ~]# systemctl restart postgresql-11[root@postgresql data]# firewall-cmd –add-service postgresql –permanent[root@postgresql data]# firewall-cmd –add-service postgresql [root@postgresql data]# ss -lnptState Recv-Q Send-Q Local Address:Port Peer Address:PortLISTEN 0 128 :22 *: users:((“sshd”,pid=3737,fd=3))LISTEN 0 128 :5432 *: users:((“postmaster”,pid=15874,fd=3))LISTEN 0 100 127.0.0.1:25 : users:((“master”,pid=4105,fd=13))LISTEN 0 128 :::22 :::* users:((“sshd”,pid=3737,fd=4))LISTEN 0 128 :::5432 :::* users:((“postmaster”,pid=15874,fd=4))LISTEN 0 100 ::1:25 :::* users:((“master”,pid=4105,fd=14))]]></content>
      <categories>
        <category>Databasees</category>
      </categories>
      <tags>
        <tag>postgresql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ovirt spice 代理服务]]></title>
    <url>%2F2019%2F02%2F03%2Fovirt-spice-proxy%2F</url>
    <content type="text"><![CDATA[由于engine管理平台是做SNAT映射出去的,所以]]></content>
      <categories>
        <category>Ovirt</category>
      </categories>
      <tags>
        <tag>ovirt</tag>
        <tag>kvm</tag>
        <tag>RHV</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ovirt虚拟机管理手册]]></title>
    <url>%2F2019%2F02%2F01%2Fovirt-virtual-machine-management-guide%2F</url>
    <content type="text"><![CDATA[chapter 7. 模板templates模板是虚拟机的复本,在接下来操作中轻松重复创建相似的虚拟机.模板封装了软件,配置和硬件,还有模板基于的源虚拟机的所有安装软件.使用模板启动的虚拟机基于源虚拟机. 当基于一个虚拟机创建一个模板,虚拟机的一个只读复本硬盘被创建.这个只读硬盘成为新模板和由此模板创建的虚拟机的基本磁盘,因此,如果ovirt中存在基于这个模板创建的虚拟机,这个硬盘不能被删除. 基于模板创建的虚拟机使用跟源虚拟机相同的网卡类型和驱动,便被分配特别的不重复的MAC地址. 7.1 封装虚拟机并部署为模板封装是基于虚拟机创建模板之前从虚拟机中移除所有特殊的系统细节的处理过程.封装是保证基于相同模板创建的多个虚拟机防止使用显明相同的细节的需要.同时也是确保其它特性的功能如预期的网卡定制的需要. 7.1.1 封装linux做为模板linux封装通过新创建模板窗口勾选Seal Template勾选框创建处理. 7.1.2 封装windows做为模板部署windows虚拟机创建的模板必需是无特殊性的.这保证机器特殊配置不会复制到模板.使用sysprep用来封装windows模板.sysprep创建一个完整的没有附加的安装回答文件. /usr/share/ovirt-engine/conf/sysprep/目录下有多个windows操作系统的默认设置值文件. 这些文件是sysprep的模板.文件中的字段可以根据需求复制,粘贴,修改.这些定义将覆盖”修改虚拟机”-&gt;”初始运行”中设置.被修改的sysprep文件会多方面影响附加了sysprep文件的模板所创建的windows虚拟机.包含域成员,主机名,安全策略等. 7.1.2.1 封装windows虚拟机的先决条件略,详细查看https://access.redhat.com/documentation/en-us/red_hat_virtualization/4.2/html/virtual_machine_management_guide/chap-templates 7.1.2.2 封装windows 7,2008,2012为模板略,详细查看https://access.redhat.com/documentation/en-us/red_hat_virtualization/4.2/html/virtual_machine_management_guide/chap-templates 7.2 创建模板从一个已经存在的虚拟机创建模板作为蓝本创建其它虚拟机. 当创建模板,需要指定硬盘模式,raw或QCOW2: QCOW2 是瘦提供,即动态分配. RAW 硬盘在文件存储上是动态分配. RAW 硬盘在块存储上是预分配的. 创建模拟步骤: Compute → Virtual Machines,选择源虚拟机 确保虚拟机是关机的 More Actions → Make Template. 输入模板名称,说明,评语 选择分配给的集群,默认同源虚拟机相同 可选的,选择CPU配置集 可选的,创建为另一个模板的子模板 硬盘分配,别名,格式,存储域,硬盘配置集;默认与源虚拟机相同. 选择允许所有用户访问模板,是否公开模板. 选择是否复制源虚拟机的权限设置 如果是linux主机勾选封装模板 OK 模板创建过程中显示虚拟机image lock.处理过程有可能花费几个小时,决定于硬件能力及源虚拟机硬盘大小.完成后模板添加到Tamplates选项中,至此你可以基于模板创建虚拟机了. 创建模板会复制虚拟机,模板与源虚拟会同时存在. 7.3 编辑模板7.4 删除模板7.5 导出模板7.6 导入模板7.7 模板权限7.8 使用cloud-init自动配置虚拟机7.9 使用sysprep自动配置虚拟机7.10 基于模板创建虚拟机 从模板创建一个预配置了操作系统,网络,应用和其它资源的虚拟机. 如果基于模板创建了虚拟机,模板将不能被删除;如果要删除模板,可以选择clone方式. 模板创建虚拟机步骤: Compute → Virtual Machines. 创建 选择集群 选择模板 输入名称,说明,评论 资源分配标签 选择存储是thin(QCOW2)或clone(QCOW2/RAW)方式 选择存储域 OK. 7.11 基于模板创建cloned虚拟机]]></content>
      <categories>
        <category>Ovirt</category>
      </categories>
      <tags>
        <tag>ovirt</tag>
        <tag>kvm</tag>
        <tag>RHV</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ovirt 4.2 为Centos linux虚拟机安装 guest agent]]></title>
    <url>%2F2019%2F01%2F31%2Fovirt-4-2-install-guest-agent%2F</url>
    <content type="text"><![CDATA[2.4.1. Red Hat Virtualization Guest Agents and Drivers Oivrt guest agents 为Linux和Windows虚拟机提供了附加信息和功能,其中最核心的包括监控虚拟机资源使用和使用管理界面优雅的关闭或重启虚拟机 没有安装前虚拟机的IP地址无法获取 生产主要使用CentOS7.6的系统(其它CentOS系列基本相同),安装如下: 12[root@dns01 ~]# yum install centos-release-ovirt42[root@dns01 ~]# yum install -y ovirt-guest-agent-common 启动服务 12345678910111213141516171819202122232425262728293031[root@dns01 ~]# systemctl start ovirt-guest-agent.service [root@dns01 ~]# systemctl enable ovirt-guest-agent.service [root@dns01 ~]# systemctl status ovirt-guest-agent.service● ovirt-guest-agent.service - oVirt Guest Agent Loaded: loaded (/usr/lib/systemd/system/ovirt-guest-agent.service; disabled; vendor preset: disabled) Active: active (running) since Sat 2019-02-02 22:38:38 CST; 2s ago Process: 12089 ExecStartPre=/bin/chown ovirtagent:ovirtagent /run/ovirt-guest-agent.pid (code=exited, status=0/SUCCESS) Process: 12086 ExecStartPre=/bin/touch /run/ovirt-guest-agent.pid (code=exited, status=0/SUCCESS) Process: 12083 ExecStartPre=/sbin/modprobe virtio_console (code=exited, status=0/SUCCESS) Main PID: 12093 (python) CGroup: /system.slice/ovirt-guest-agent.service └─12093 /usr/bin/python /usr/share/ovirt-guest-agent/ovirt-guest-agent.pyFeb 02 22:38:38 dns01.talen.iot systemd[1]: Starting oVirt Guest Agent...Feb 02 22:38:38 dns01.talen.iot systemd[1]: Started oVirt Guest Agent.Feb 02 22:38:38 dns01.talen.iot userhelper[12101]: pam_succeed_if(ovirt-container-list:auth): requirement &quot;user = ovirtagent&quot; was met by user &quot;ovirtagent&quot;Feb 02 22:38:38 dns01.talen.iot userhelper[12101]: running &apos;/usr/share/ovirt-guest-agent/container-list&apos; with root privileges on behalf of &apos;ovirtagent&apos;Feb 02 22:38:39 dns01.talen.iot userhelper[12103]: pam_succeed_if(ovirt-container-list:auth): requirement &quot;user = ovirtagent&quot; was met by user &quot;ovirtagent&quot;Feb 02 22:38:39 dns01.talen.iot userhelper[12103]: running &apos;/usr/share/ovirt-guest-agent/container-list&apos; with root privileges on behalf of &apos;ovirtagent&apos;[root@dns01 ~]# systemctl start qemu-guest-agent.service[root@dns01 ~]# systemctl enable qemu-guest-agent.service[root@dns01 ~]# systemctl status qemu-guest-agent.service ● qemu-guest-agent.service - QEMU Guest Agent Loaded: loaded (/usr/lib/systemd/system/qemu-guest-agent.service; enabled; vendor preset: enabled) Active: active (running) since Sat 2019-02-02 22:38:38 CST; 20min ago Main PID: 12082 (qemu-ga) CGroup: /system.slice/qemu-guest-agent.service └─12082 /usr/bin/qemu-ga --method=virtio-serial --path=/dev/virtio-ports/org.qemu.guest_agent.0 --blacklist=guest-file-open,guest-file-close,guest-file-read,guest-file-write,guest-file-seek,gue...Feb 02 22:38:38 dns01.talen.iot systemd[1]: Started QEMU Guest Agent. 服务启动后提示消失,并能获取到虚拟机IP等信息.]]></content>
      <categories>
        <category>Ovirt</category>
      </categories>
      <tags>
        <tag>ovirt</tag>
        <tag>kvm</tag>
        <tag>RHV</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Install SecureCRT 8.3.4 on openSUSE 15.1]]></title>
    <url>%2F2019%2F01%2F27%2FInstall-SecureCRT-8-3-4-on-openSUSE-15-1%2F</url>
    <content type="text"><![CDATA[官方下载scrt-sfx-8.3.4.1699.rhel7-64.tar.gz并解压,我这里是/home/haotianfei/bin/scrt8.3.4/scrt-sfx-8.3.4/ 12cd /home/haotianfei/bin/scrt8.3.4/tar zxvf scrt-sfx-8.3.4.1699.rhel7-64.tar.gz 解压后进入bin目录运行提示找不到openssl的库文件 123haotianfei@tianfei-opensuse:~/bin/scrt8.3.4/scrt-sfx-8.3.4&gt; ./SecureCRT./SecureCRT: error while loading shared libraries: libssl.so.10: cannot open shared object file: No such file or directory./SecureCRT: error while loading shared libraries: libcrypto.so.10: cannot open shared object file: No such file or directory 这里使用www.openssl.org官方网站下载编译,然后链接到/usr/lib64/的方式 https://www.openssl.org/source/old/1.0.2/ 1.0.2版本的最后一个版本1.0.2phttps://www.openssl.org/source/old/1.0.2/openssl-1.0.2p.tar.gz 解压并编译 12haotianfei@tianfei-opensuse:~/bin/scrt8.3.4/openssl-devel/openssl-1.0.2p&gt; ./config shared zlib-dynamichaotianfei@tianfei-opensuse:~/bin/scrt8.3.4/openssl-devel/openssl-1.0.2p&gt; make 将编译好的so文件链接到系统库目录 12haotianfei@tianfei-opensuse:~/bin/scrt8.3.4/openssl-devel/openssl-1.0.2p&gt; sudo ln -sf `pwd`/libssl.so.1.0.0 /usr/lib64/libssl.so.10haotianfei@tianfei-opensuse:~/bin/scrt8.3.4/openssl-devel/openssl-1.0.2p&gt; sudo ln -sf `pwd`/libcrypto.so.1.0.0 /usr/lib64/libcrypto.so.10 虽然还是会提示版本信息不可用,但已经可以正常运行使用了.]]></content>
      <categories>
        <category>openSUSE</category>
      </categories>
      <tags>
        <tag>opensuse</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[配置DNS服务器]]></title>
    <url>%2F2019%2F01%2F27%2Fdns-can-t-resolv-out-domain%2F</url>
    <content type="text"><![CDATA[Ovirt虚拟化平台对DNS的可靠要求比较高,DNS服务如果无法正常提供解析,将造成整个虚拟化平台的宕机; Ovirt官方不推荐只在虚拟化平台上运行DNS服务,防止虚拟机宕机造成整个平台宕机,所以这里采用的是一台实体物理机运行主DNS服务(10.0.0.40),其它两台从服务器运行在虚拟化平台上低成本解决单点问题. 服务器: 主服务器: 10.0.0.40 从服务器1: 10.0.0.41 从服务器2: 10.0.0.42 其中主服务器部署在一台实体物理机上,其它服务器在Ovirt平台上启动的虚拟机. 在所有服务器上执行安装: 123[root@dns00 ~]# yum install -y bind bind-utils[root@dns01 ~]# yum install -y bind bind-utils[root@dns02 ~]# yum install -y bind bind-utils 配置如下: 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586[root@dns00 ~]# cat /etc/named.conf //// named.conf//// Provided by Red Hat bind package to configure the ISC BIND named(8) DNS// server as a caching only nameserver (as a localhost DNS resolver only).//// See /usr/share/doc/bind*/sample/ for example named configuration files.//// See the BIND Administrator&apos;s Reference Manual (ARM) for details about the// configuration located in /usr/share/doc/bind-&#123;version&#125;/Bv9ARM.htmlacl iot-slaves &#123; 10.0.0.41; 10.0.0.42;&#125;;acl localnet253 &#123; 10.0.0.0/25;&#125;;options &#123; listen-on port 53 &#123; any;&#125;; listen-on-v6 port 53 &#123; any; &#125;; directory &quot;/var/named&quot;; dump-file &quot;/var/named/data/cache_dump.db&quot;; statistics-file &quot;/var/named/data/named_stats.txt&quot;; memstatistics-file &quot;/var/named/data/named_mem_stats.txt&quot;; recursing-file &quot;/var/named/data/named.recursing&quot;; secroots-file &quot;/var/named/data/named.secroots&quot;; allow-query &#123; localnets;10.0.0.20; &#125;; recursion yes; allow-recursion &#123; localnets; &#125;; /* - If you are building an AUTHORITATIVE DNS server, do NOT enable recursion. - If you are building a RECURSIVE (caching) DNS server, you need to enable recursion. - If your recursive DNS server has a public IP address, you MUST enable access control to limit queries to your legitimate users. Failing to do so will cause your server to become part of large scale DNS amplification attacks. Implementing BCP38 within your network would greatly reduce such attack surface */ forward only; forwarders &#123; 119.29.29.29; 223.5.5.5; 223.6.6.6; 8.8.8.8; &#125;; allow-transfer &#123; iot-slaves; &#125;; dnssec-enable no; dnssec-validation no; /* Path to ISC DLV key */ bindkeys-file &quot;/etc/named.iscdlv.key&quot;; managed-keys-directory &quot;/var/named/dynamic&quot;; pid-file &quot;/run/named/named.pid&quot;; session-keyfile &quot;/run/named/session.key&quot;;&#125;;logging &#123; channel default_debug &#123; file &quot;data/named.run&quot; versions 30 size 10240k; severity debug; print-time yes; print-severity yes; print-category yes; &#125;;&#125;;zone &quot;.&quot; IN &#123; type hint; file &quot;named.ca&quot;;&#125;;include &quot;/etc/named.rfc1912.zones&quot;;include &quot;/etc/named.root.key&quot;; 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556[root@dns00 ~]# cat /etc/named.rfc1912.zones // named.rfc1912.zones://// Provided by Red Hat caching-nameserver package //// ISC BIND named zone configuration for zones recommended by// RFC 1912 section 4.1 : localhost TLDs and address zones// and http://www.ietf.org/internet-drafts/draft-ietf-dnsop-default-local-zones-02.txt// (c)2007 R W Franks//// See /usr/share/doc/bind*/sample/ for example named configuration files.//zone &quot;localhost.localdomain&quot; IN &#123; type master; file &quot;named.localhost&quot;; allow-update &#123; none; &#125;;&#125;;zone &quot;localhost&quot; IN &#123; type master; file &quot;named.localhost&quot;; allow-update &#123; none; &#125;;&#125;;zone &quot;1.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.ip6.arpa&quot; IN &#123; type master; file &quot;named.loopback&quot;; allow-update &#123; none; &#125;;&#125;;zone &quot;1.0.0.127.in-addr.arpa&quot; IN &#123; type master; file &quot;named.loopback&quot;; allow-update &#123; none; &#125;;&#125;;zone &quot;0.in-addr.arpa&quot; IN &#123; type master; file &quot;named.empty&quot;; allow-update &#123; none; &#125;;&#125;;zone &quot;talen.iot&quot; IN &#123; type master; file &quot;named.talen.iot&quot;; allow-update &#123; none; &#125;; allow-transfer &#123; iot-slaves; &#125;;&#125;;zone &quot;253.34.10.in-addr.arpa&quot; IN &#123; type master; file &quot;named.10.0.0&quot;; allow-update &#123; none; &#125;; allow-transfer &#123; iot-slaves; &#125;;&#125;; 注意zone文件中一定要将所有NS服务器列举出来,否则从服务器无法收到主服务的notify 123456789101112131415161718192021[root@dns00 ~]# cat /var/named/named.talen.iot$TTL 3H@ IN SOA @ haotianfei.talen.com. ( 2019020300 ; serial 1D ; refresh 1H ; retry 1W ; expire 3H ) ; minimum NS ns.talen.iot. NS ns1.talen.iot. NS ns2.talen.iot.storage NS ns.talen.iot.server IN A 10.0.0.40ns IN A 10.0.0.40ns1 IN A 10.0.0.41ns2 IN A 10.0.0.42engine IN A 10.0.0.20vnode00 IN A 10.0.0.30vnode01 IN A 10.0.0.31vnode02 IN A 10.0.0.32storage IN A 10.0.0.20 123456789101112131415161718[root@dns00 ~]# cat /var/named/named.10.0.0$TTL 3H@ IN SOA ns.talen.iot haotianfei.talen.com. ( 2019012700 ; serial 1D ; refresh 1H ; retry 1W ; expire 3H ) ; minimum NS ns.talen.iot. NS ns1.talen.iot. NS ns2.talen.iot.40 IN PTR ns.talen.iot.40 IN PTR server.talen.iot.20 IN PTR engine.talen.iot.30 IN PTR vnode00.talen.iot.31 IN PTR vnode01.talen.iot.32 IN PTR vnode02.talen.iot.20 IN PTR engine.talen.iot. 配置两个从节点,配置基本一致,zone数据是从主节点同步过来的,所以无需管理.: 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142[root@dns01 ~]# cat /etc/named.conf//// named.conf//// Provided by Red Hat bind package to configure the ISC BIND named(8) DNS// server as a caching only nameserver (as a localhost DNS resolver only).//// See /usr/share/doc/bind*/sample/ for example named configuration files.//// See the BIND Administrator&apos;s Reference Manual (ARM) for details about the// configuration located in /usr/share/doc/bind-&#123;version&#125;/Bv9ARM.htmlacl &quot;trusted&quot; &#123; 10.0.0.20;&#125;;options &#123; listen-on port 53 &#123; any; &#125;; listen-on-v6 port 53 &#123; any; &#125;; directory &quot;/var/named&quot;; dump-file &quot;/var/named/data/cache_dump.db&quot;; statistics-file &quot;/var/named/data/named_stats.txt&quot;; memstatistics-file &quot;/var/named/data/named_mem_stats.txt&quot;; recursing-file &quot;/var/named/data/named.recursing&quot;; secroots-file &quot;/var/named/data/named.secroots&quot;; allow-query &#123; localnets;10.0.0.20; &#125;; recursion yes; allow-recursion &#123; localnets; &#125;; forward only; forwarders &#123; 119.29.29.29; 223.5.5.5; 223.6.6.6; 8.8.8.8; &#125;; allow-transfer &#123; none; &#125;; /* - If you are building an AUTHORITATIVE DNS server, do NOT enable recursion. - If you are building a RECURSIVE (caching) DNS server, you need to enable recursion. - If your recursive DNS server has a public IP address, you MUST enable access control to limit queries to your legitimate users. Failing to do so will cause your server to become part of large scale DNS amplification attacks. Implementing BCP38 within your network would greatly reduce such attack surface */ dnssec-enable no; dnssec-validation no; /* Path to ISC DLV key */ bindkeys-file &quot;/etc/named.iscdlv.key&quot;; managed-keys-directory &quot;/var/named/dynamic&quot;; pid-file &quot;/run/named/named.pid&quot;; session-keyfile &quot;/run/named/session.key&quot;;&#125;;logging &#123; channel default_debug &#123; file &quot;data/named.run&quot; versions 30 size 10240k; severity debug; print-time yes; print-severity yes; print-category yes; &#125;;&#125;;zone &quot;.&quot; IN &#123; type hint; file &quot;named.ca&quot;;&#125;;include &quot;/etc/named.rfc1912.zones&quot;;include &quot;/etc/named.root.key&quot;;[root@dns01 ~]# cat /etc/named.rfc1912.zones // named.rfc1912.zones://// Provided by Red Hat caching-nameserver package //// ISC BIND named zone configuration for zones recommended by// RFC 1912 section 4.1 : localhost TLDs and address zones// and http://www.ietf.org/internet-drafts/draft-ietf-dnsop-default-local-zones-02.txt// (c)2007 R W Franks// // See /usr/share/doc/bind*/sample/ for example named configuration files.//zone &quot;localhost.localdomain&quot; IN &#123; type master; file &quot;named.localhost&quot;; allow-update &#123; none; &#125;;&#125;;zone &quot;localhost&quot; IN &#123; type master; file &quot;named.localhost&quot;; allow-update &#123; none; &#125;;&#125;;zone &quot;1.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.ip6.arpa&quot; IN &#123; type master; file &quot;named.loopback&quot;; allow-update &#123; none; &#125;;&#125;;zone &quot;1.0.0.127.in-addr.arpa&quot; IN &#123; type master; file &quot;named.loopback&quot;; allow-update &#123; none; &#125;;&#125;;zone &quot;0.in-addr.arpa&quot; IN &#123; type master; file &quot;named.empty&quot;; allow-update &#123; none; &#125;;&#125;;zone &quot;talen.iot&quot; IN &#123; type slave; file &quot;named.talen.iot&quot;; masters &#123;10.0.0.40;&#125;; allow-query &#123; localnets; &#125;; zone-statistics yes;&#125;;zone &quot;253.34.10.in-addr.arpa&quot; IN &#123; type slave; file &quot;named.10.0.0&quot;; masters &#123;10.0.0.40;&#125;; allow-query &#123; localnets; &#125;; zone-statistics yes;&#125;; 验证: 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950[root@dns00 ~]# dig www.sina.com; &lt;&lt;&gt;&gt; DiG 9.9.4-RedHat-9.9.4-72.el7 &lt;&lt;&gt;&gt; www.sina.com;; global options: +cmd;; Got answer:;; -&gt;&gt;HEADER&lt;&lt;- opcode: QUERY, status: NOERROR, id: 20729;; flags: qr rd ra; QUERY: 1, ANSWER: 3, AUTHORITY: 0, ADDITIONAL: 1;; OPT PSEUDOSECTION:; EDNS: version: 0, flags:; udp: 4096;; QUESTION SECTION:;www.sina.com. IN A;; ANSWER SECTION:www.sina.com. 24 IN CNAME us.sina.com.cn.us.sina.com.cn. 15 IN CNAME spool.grid.sinaedge.com.spool.grid.sinaedge.com. 28 IN A 202.102.94.124;; Query time: 8 msec;; SERVER: 10.0.0.40#53(10.0.0.40);; WHEN: Sun Jan 27 17:38:06 CST 2019;; MSG SIZE rcvd: 119[root@dns00 ~]# dig engine.talen.iot; &lt;&lt;&gt;&gt; DiG 9.9.4-RedHat-9.9.4-72.el7 &lt;&lt;&gt;&gt; engine.talen.iot;; global options: +cmd;; Got answer:;; -&gt;&gt;HEADER&lt;&lt;- opcode: QUERY, status: NOERROR, id: 63533;; flags: qr aa rd ra; QUERY: 1, ANSWER: 1, AUTHORITY: 1, ADDITIONAL: 2;; OPT PSEUDOSECTION:; EDNS: version: 0, flags:; udp: 4096;; QUESTION SECTION:;engine.talen.iot. IN A;; ANSWER SECTION:engine.talen.iot. 10800 IN A 10.0.0.20;; AUTHORITY SECTION:talen.iot. 10800 IN NS ns.talen.iot.;; ADDITIONAL SECTION:ns.talen.iot. 10800 IN A 10.0.0.40;; Query time: 1 msec;; SERVER: 10.0.0.40#53(10.0.0.40);; WHEN: Sun Jan 27 17:39:03 CST 2019;; MSG SIZE rcvd: 93 故障现象一 bind可以解析自管理的域名,但无法解析外部域名. 日志中报错: 1234Jan 27 17:22:31 server.talen.iot named[7460]: no valid RRSIG resolving &apos;net/DS/IN&apos;: 223.6.6.6#53Jan 27 17:22:31 server.talen.iot named[7460]: no valid RRSIG resolving &apos;net/DS/IN&apos;: 223.5.5.5#53Jan 27 17:22:41 server.talen.iot named[7460]: no valid DS resolving &apos;l.root-servers.net/AAAA/IN&apos;: 223.6.6.6#53Jan 27 17:22:41 server.talen.iot named[7460]: no valid DS resolving &apos;l.root-servers.net/A/IN&apos;: 223.6.6.6#53 解决方法: 关闭DNSSEC 故障现象二 主服务器域名zone文件是text,从服务器zone文件是data 1234[root@dns00 ~]# file /var/named/named.talen.iot /var/named/named.talen.iot: ASCII text[root@dns01 ~]# file /var/named/named.talen.iot /var/named/named.talen.iot: data 解决方法:从服务器/etc/named.conf的option中添加masterfile-format text; 12[root@dns01 ~]# file /var/named/named.talen.iot /var/named/named.talen.iot: ASCII text 故障现象三123456789[root@saltstack bind]# nslookup salt Server: 10.34.253.40Address: 10.34.253.40#53** server can&apos;t find salt: NXDOMAIN[root@saltstack bind]# vi /etc/resolv.conf[root@saltstack bind]# hostnamesaltstack.talne.iot 解决方法:hostname中的域名配置错误,只使用主机名解析找不到域. 1[root@saltstack bind]# hostnamectl set-hostname saltstack.talen.iot]]></content>
      <categories>
        <category>Redhat Server</category>
      </categories>
      <tags>
        <tag>dns</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[firefox allways display close button]]></title>
    <url>%2F2019%2F01%2F27%2Ffirefox-allways-display-close%2F</url>
    <content type="text"><![CDATA[firefox相比chrome不同的一点是标签只有活动的才显示关闭按钮;当你想关闭一个后台标签时,不得不切换到标签然后再关闭,效率比较低.通过在userChrome.css中添加自定义配置,允许标签全部显示关闭按钮. 123haotianfei@tianfei-opensuse:~&gt; vi .mozilla/firefox/nnghxxxx.default/chrome/userChrome.css@namespace url(&quot;http://www.mozilla.org/keymaster/gatekeeper/there.is.only.xul&quot;);.tab-close-button:not([pinned=&quot;true&quot;]) &#123; display: -moz-box !important; &#125; 效果如下]]></content>
      <tags>
        <tag>firefox</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[yum常用操作汇总]]></title>
    <url>%2F2019%2F01%2F26%2Fyum%E5%B8%B8%E7%94%A8%E6%93%8D%E4%BD%9C%E6%B1%87%E6%80%BB%2F</url>
    <content type="text"><![CDATA[使用DVD或本地源修改/etc/yum.repo.d/CentOS-Media.repo 1baseurl=file///root/cdrom # 镜像目录 然后执行 1yum --disablerepo=\* --enablerepo=c7-media install bind]]></content>
      <categories>
        <category>Redhat</category>
      </categories>
      <tags>
        <tag>yum</tag>
        <tag>redhat</tag>
        <tag>centos</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Enhancing Your Blog with Advanced Features翻译加实践]]></title>
    <url>%2F2019%2F01%2F20%2FEnhancing-Your-Blog-with-Advanced-Features%2F</url>
    <content type="text"><![CDATA[在上一章节,创建了一个基本的blog应用.现在,将应用转入具有高级特性的全功能blog,例如email分享post,添加评论,文章标签,接收相似文章.在这一章节,将会学习到如下内容: 使用Django发送邮件 视图中创建并处理表单 使用models创建表单 整合第三方应用 创建混合querysets 使用Email分享posts首先,我们将允许用户使用Email分享posts.花一点点时间想一下如何使用上一章节学习的视图,URLS,模板创建这个功能.现在,检查允许用户发送邮件需要哪些东西.你将做如下的操作: 创建一个from允许用户填写用户名,email,email接收者,评论. 创建一个view处理数据和发送邮件 为上面的view添加一个url匹配 创建一个template显示from表单 在Django中创建froms表单让我们来创建分享表单.Django内置表单框架允许你轻松创建表单.表单框架允许你定义表单字段,指定如何显示,标识如何验证数据.Django表单框架灵活的渲染表单和处理数据.Django使用两个类来创建表单: from: 创建基本表单 ModelForm: 创建数据绑定表单 首先,我们在blog应用目录创建from.py文件: 123456789from django import formsclass EmailPostForm(forms.Form): name = forms.CharField(max_length=25) email = forms.EmailField() to = forms.EmailField() comments = forms.CharField(required=False, widget=forms.Textarea) 这是我们第一个表单.分析一下代码内容.我们继承Form类创建一个表单.使用了不同的字段类型,Django将相应的验证这些字段. 表单可以存在于Django工程的任何地方,最好在每个应用的目录下存放在form.py文件中 name字段是字符串字段.这个字段渲染为一个HTML元素 1&lt;input type=&quot;text&quot;&gt; 每个字段都有一个默认的微件决定字段在HTML中如何渲染.comments字段我们使用了一个Textarea的微件在HTML显示为 1&lt;textarea&gt; 元素.字段验证同样信赖字段类型.例如,email和to字段使用EmailField类型.两个字段都需要验证email地址,否则将提示forms.ValidationError错误.其它参数也将被带入验证:我们为name定义了最大长度25字符,comments字段使用required=False表示不是必须的.所有这些都存在字段验证.这里只使用了Django表单字段的一部分,所有表单字段可查阅:https://docs.djangoproject.com/en/2.0/ref/forms/fields/ 在视图中处理表单你需要创建一个新的视图处理当提交成功时表单发送email.编辑应用下的views.py文件: 12345678910111213141516171819202122# 导入表单from .forms import EmailPostForm# 处理表单def post_share(request, post_id): # 根据post_id取得post对象 post = get_object_or_404(Post, id=post_id, status=&apos;published&apos;) # 如果提交操作且经过验证 if request.method == &quot;POST&quot;: # 表单是提交操作 form = EmailPostForm(request.POST) if form.is_valid(): cd = form.changed_data # 发送邮件 else: # 表单是显示操作 form = EmailPostForm return render(request, &apos;blog/post/share.html&apos;, &#123;&apos;form&apos;: form, &apos;post&apos;: post&#125;) 视图处理流程如下:1 创建post_share视图,带入request和post_id参数2 使用get_object_or_404()快捷方法接收post对象,根据后面的参数post_id及status=published.3 使用同一视图显示初始表单及处理表单提交数据.区别是提交还是显示基于request的方法,提交是POST.如果是GET方法,显示表单;如果是POST方法,表单是提交,然后需要view做处理.request.method == ‘POST’是区分两种方式的关键. 下面是处理显示及处理表单数据:1 当表单是初始状态或接收GET请求,我们创建一个新表单实例在模板中来显示空白表单.2 当用户输入数据点击提交后接收为POST,然后我们使用提交的数据创建包含request.POST的表单实例:3 在这个过程中,我们验证提交的数据使用form.is_vaild()方法.这个方法验证表单数据正确返回True.错误返回False.可以使用form.errors查看验证错误列表.4 如果表单不正确,再次渲染表单模板并显示验证错误.5 如果表单正确,我们通过form.cleaned_data接收验证过的数据.这个属性是一个表单字段和表单字段值的一个字典. 如果表单数据不正确,cleaned_data将只包含通过验证的数据. 现在,让我学习如何在Django中发送邮件来把事情融合. 使用django发送邮件Django发送邮件是相当直接的.首先,你需要有一个本地SMTP服务器或在settings.py中定义一个外界的SMTP服务器: EMAIL_HOST: smtp服务器地址,默认是localhost EMAIL_PORT: smtp端口,默认25 EMAIL_HOST_USER: 用户名 EMAIL_HOST_PASSWORD: 密码 EMAIL_USE_TLS: 是否使用TLS安全连接 EMAIL_USE_SSL: 是否使用SSL安全连接 如果你不能使用SMTP服务器,你可以告诉Django输出email到终端,添加如下配置: 12# For EmailEMAIL_BACKEND = &apos;django.core.mail.backends.console.EmailBackend&apos; 这样配置后,Django将输入email到终端.这在没有SMTP服务器的情况下测试非常有用.如果你想发送邮件,但没有本地SMTP服务器,你可以使用SMTP服务商.下面是使用GMAIL的配置: 12345EMAIL_HOST = &apos;smtp.gmail.com&apos;EMAIL_HOST_USER = &apos;your_account@gmail.com&apos;EMAIL_HOST_PASSWORD = &apos;your_password&apos;EMAIL_PORT = 587EMAIL_USE_TLS = True 运行python manage.py shell打开终端,然后发送email: 1234567891011121314&gt;&gt;&gt; from django.core.mail import send_mail&gt;&gt;&gt; send_mail(&apos;Django mail&apos;, &apos;This e-mail was sent with Django.&apos;, &apos;talenhao@gmail.com&apos;, [&apos;talenhao@gmail.com&apos;], fail_silently=False)Content-Type: text/plain; charset=&quot;utf-8&quot;MIME-Version: 1.0Content-Transfer-Encoding: 7bitSubject: Django mailFrom: talenhao@gmail.comTo: talenhao@gmail.comDate: Sun, 20 Jan 2019 14:11:55 -0000Message-ID: &lt;154799351565.16947.13299734647581468097@tianfei-opensuse&gt;This e-mail was sent with Django.-------------------------------------------------------------------------------1 send_mail()功能带入标题,信息,发送者,一个接收者列表作为必选参数.可选参数fail_silently=False,我们告知它如果不能正确发送触发一个错误.如果发送email由GMAIL提供,必需允许低安全应用访问https://myaccount.google.com/lesssecureapps.现在,我们添加发邮件功能到视图中.修改post_share视图: 1234567891011121314151617181920212223242526272829303132333435# 发送邮件from django.core.mail import send_mail# 处理表单def post_share(request, post_id): # 根据post_id取得post对象 post = get_object_or_404(Post, id=post_id, status=&apos;published&apos;) sent = False # 如果提交操作且经过验证 if request.method == &quot;POST&quot;: # 表单是提交操作 form = EmailPostForm(request.POST) if form.is_valid(): cd = form.changed_data # 发送邮件 # 创建文章 post_url = request.build_absolute_uri(post.get_absolute_url()) subject = &apos;&#123;&#125; (&#123;&#125;) recommends you reading &quot;&#123;&#125;&quot;&apos;.format(cd[&apos;name&apos;], cd[&apos;email&apos;], post.title) message = &apos;Read &quot;&#123;&#125;&quot; at &#123;&#125;\n\n&#123;&#125;\&apos;s comments: &#123;&#125;&apos;.format(post.title, post_url, cd[&apos;name&apos;], cd[&apos;comments&apos;]) send_mail(subject, message, &apos;talenhao@test.domain&apos;, [cd[&apos;to&apos;]]) sent = True else: # 表单是显示操作 form = EmailPostForm return render(request, &apos;blog/post/share.html&apos;, &#123;&apos;form&apos;: form, &apos;post&apos;: post, &apos;sent&apos;: sent&#125;) 我们宣告一个sent变量,邮件发送成功后设置为True.如果发送成功,我们将稍后在模板中使用这个变量来显示成功消息.因为必需在邮件正文中包含post的链接,我们使用Post模型中定义的get_absolute_url()方法.我们使用这个地址带入request.build_absolute_url()方法来创建包含HTTP结构及主机名的完整的url.然后我们使用cleaned_data创建邮件标题,信息;最后发送这个邮件到to字段的地址.现在视图已经完整,但还是需要添加url匹配规则.打开urls.py修改: 1path(&apos;&lt;int:post_id&gt;/share/&apos;, views.post_share, name=&apos;post_share&apos;), 在模板中渲染表单创建表单,编写视图,添加URL匹配后,我们还缺少模板.创建一个新文件blog/templates/blog/post/share.html,添加下面的代码: 1234567891011121314151617181920&#123;% extends &apos;blog/base.html&apos; %&#125;&#123;% block title %&#125; Share &#123;&#123; post.title &#125;&#125;&#123;% endblock %&#125;&#123;% block content %&#125; &#123;% if sent %&#125; &lt;p&gt; &quot;&#123;&#123; post.title &#125;&#125;&quot; was successfully sent to &#123;&#123; form.cleaned_data.to &#125;&#125; &lt;/p&gt; &#123;% else %&#125; &lt;h1&gt;Share &quot;&#123;&#123; post.title &#125;&#125;&quot; by email&lt;/h1&gt; &lt;form action=&quot;.&quot; method=&quot;post&quot;&gt; &#123;% csrf_token %&#125; &#123;&#123; form.as_p &#125;&#125; &lt;input type=&quot;submit&quot; value=&quot;Send Email&quot;&gt; &lt;/form&gt;&#123;% endblock %&#125; 如果已经发送,这个模板将显示一个成功消息.我们创建了一个html元素,POST方法提交.我们使用as_p()方法告诉Django渲染表单字段在HTML元素.我们也可以使用as_ul或as_table.如果我们希望渲染每个字段,我们可以迭代每个字段: 123456&#123;% for field in form %&#125;&lt;div&gt;&#123;&#123; field.errors &#125;&#125;&#123;&#123; field.label_tag &#125;&#125; &#123;&#123; field &#125;&#125;&lt;/div&gt;&#123;% endfor %&#125; 1&#123;% csrf_token %&#125; 模板标记隐含字段包含一个自动生成的token防止 cross-site request forgery(CSRF)攻击.那些包含恶意网站或不希望的执行程序在你的站点上.在这里可以找到更多说明https://www.owasp.org/index.php/Cross-Site_Request_Forgery_(CSRF)处理标记生成一个隐含字段如下: 12&lt;input type=&apos;hidden&apos; name=&apos;csrfmiddlewaretoken&apos;value=&apos;26JjKo2lcEtYkGoV9z4XmJIEHLXN5LDR&apos; /&gt; 修改blog/post/detail.html模板添加分享链接: 123456&#123;&#123; post.body|linebreaks &#125;&#125;&lt;p&gt; &lt;a href=&quot;&#123;% url &quot;blog:post_share&quot; post.id %&#125;&quot;&gt; Share this post &lt;/a&gt;&lt;/p&gt; 在这里我们使用Django提供的url动态创建链接.使用命令空间blog和url名称post_share,然后传递post ID作为参数来创建绝对路径的URL.现在可以启动开发服务器,查看页面运行情况了.如果输入字段类型不对,会提示错误. 创建一个评论系统现在,我们将创建一个评论系统,读者能够评论文章.为了实现这个功能,我们将做如下事情: 1 创建一个model存储comments2 创建一个form验证并提交comments3 创建一个view处理from并存储commnets到model数据库4 编辑post detail模板显示comments列表和添加新comment表单 首先,创建一个model存储评论.打开models.py文件: 12345678910111213141516class Comment(models.Model): post = models.ForeignKey(Post, on_delete=models.CASCADE, related_name=&apos;comments&apos;) name = models.CharField(max_length=80) email = models.EmailField() body = models.TextField() created = models.DateTimeField(auto_now_add=True) updated = models.DateTimeField(auto_now=True) active = models.BooleanField(default=True) class Meta: ordering = (&apos;created&apos;,) def __str__(self): return &apos;Comment by &#123;&#125; on &#123;&#125;&apos;.format(self.name, self.post) 我们的Comment model,包含外键ForeignKey辅助访问一个post的comment.这里定义了一个多对一关系,因为每个comment只能评论在一个post上,每个post可以有多个comments.related_name属性允许我们为从关联对象回到关系所使用的属性命名.定义后,我们可以使用comment.post接收comment对象的post,接收post的所有comments使用post.comments.all().如果你不定义related_name属性.,Django将使用model的小写加_set作为关联对象post回指的管理器.查看更多多对一关系https://docs.djangoproject.com/en/2.0/topics/db/examples/many_to_one/ 我们创建了一个active布尔字段为了手工关闭不适合的评论.我们使用created创建时间做为排默认排序.创建完Commnet model后并没有同步到数据库.使用Django迁移命令. 1234567891011(django2byExample) haotianfei@tianfei-opensuse:~/PycharmProjects/Django2byExample&gt; python manage.py makemigrations blogMigrations for &apos;blog&apos;: blog/migrations/0002_auto_20190121_1444.py - Create model Comment - Alter field slug on post - Add field post to comment(django2byExample) haotianfei@tianfei-opensuse:~/PycharmProjects/Django2byExample&gt; python manage.py migrate blogOperations to perform: Apply all migrations: blogRunning migrations: Applying blog.0002_auto_20190121_1444... OK 现在,为了通过一个简单的接口管理comments我们添加新model到管理站点.修改admin.py 12345678from blog.models import Comment@admin.register(Comment)class CommentAdmin(admin.ModelAdmin): list_display = (&apos;name&apos;, &apos;email&apos;, &apos;post&apos;, &apos;created&apos;, &apos;updated&apos;, &apos;active&apos;) list_filter = (&apos;active&apos;, &apos;created&apos;, &apos;upcated&apos;) search_fields = (&apos;name&apos;, &apos;email&apos;, &apos;body&apos;) 运行开发服务器,执行python manage.py runserver命令,使用浏览器打开http://127.0.0.1:8000/admin,你将会看到新的model已经在Blog中了.现在model已经注册到管理站点,我们可以使用一个简单的接口管理Comment实例了 从models创建froms我们需要创建一个能让用户评论文章的表单.Django有两个基础类可以创建表单,Form和ModelForm.我们使用Form在上面创建用户email分享.在这一部分,因为要从Comment模型创建一个动态表单使用ModelForm.编辑forms.py,添加下面的代码: 1234567from .models import Commentclass CommentForm(forms.ModelForm): class Meta: model = Comment fields = (&apos;name&apos;, &apos;email&apos;, &apos;body&apos;) 从model创建form,只需要在Meta类中指出从哪个model创建.Django自己会跟model交互然后动态的创建.每个model字段类型都对应有默认的表单字段.定义model类型是为了解释表单验证.Django为model中每一个字段创建表单字段.但可以使用fields列表明确的告知框架你想包含在表单中的字段,或使用exclude定义哪些字段你想要排除.在这个CommentForm表单,我们将使用name,email,body字段,因为我们用户只需要填入这些. 在视图中处理ModelForm我们将在post的详细页面视图中初始化一个表单并处理,这样可以保持简洁.编辑views.py文件: 123456789101112131415161718192021222324252627282930# ModelFormfrom .forms import CommentFormfrom .models import Commentdef post_detail(request, year, month, day, post): post = get_object_or_404(Post, slug=post, status=&apos;published&apos;, publish__year=year, publish__month=month, publish__day=day) # 接收所有当前post评论 comments = post.comments.filter(active=True) comment_form = CommentForm() new_comment = None if request.method == &quot;POST&quot;: comment_form = CommentForm(data=request.POST) if comment_form.is_valid(): new_comment = comment_form.save(commit=False) new_comment.post = post new_comment.save() else: comment_form = CommentForm() return render(request, &apos;blog/post/detail.html&apos;, &#123;&apos;post&apos;: post, &apos;comments&apos;: comments, &apos;new_comment&apos;: new_comment, &apos;comment_form&apos;: comment_form&#125;) 我们使用post的详细页显示评论.首先使用一个QuerySet接收所有post评论,命名为comments,使用Commnet关系模型关联属性对象的管理器接收对象.我们同时使用相同的视图来主我们的用户添加新的评论.初始化new_comment变量为None.我们将在创建新的comment时使用这个变量.如果是request.GET请求使用comment_form创建一个初始表单.如果请求是POST,我们将使用提交数据和变量初始表单并使用is_vaild()验证方法.如果表单正确,将产生以下动作:1 使用表单save()方法创建新Comment对象,附给new_commnet变量.save()方法创建一个表单链接新的模型实例,并存储到数据库.如果调用时使用commit=False,创建实例但不保存到数据库.这可以在保存之间修改对象,我们需要修改数据.save只在ModelForm中有用,Form无效.因为Form没有关联model2 关联post到刚刚创建的commnet.这样就指定了新的评论到post.3 最后,调用save()保存新的comment到数据库 现在视图已经可以显示并处理新的评论. 添加评论到文章详细页模板我们已经创建post管理comment的功能.现在,需要对post/detail.html模板做下面的事情: 显示一篇post的总commnet数量 显示commnets列表 显示一个新commnet表单 首先,添加评论总数. 1234567&lt;span&gt; &#123;% with comments.count as total_comments %&#125; &lt;h2&gt; &#123;&#123; total_comments &#125;&#125; comment&#123;&#123; total_comments|pluralize &#125;&#125; &lt;/h2&gt; &#123;% endwith %&#125;&lt;/span&gt; 在模板中使用Django ORM,执行QuerySet comments.count.Django模板语言调用方法不会使用复数.with标签允许附加值到一个新的变量.pluralize模板过滤器根据commnets的值来显示复数后辍.模板过滤器带入变量值做为输入,然后返回一个混合后的值.第三章节将详细介绍过滤器.如果结果不为1,pluralize过滤器将返回字母s.Django包含完美的模板标记和过滤器帮助显示你想要的信息.现在,列出评论.代码如下: 1234567891011&#123;% for comment in comments %&#125; &lt;div class=&quot;comment&quot;&gt; &lt;p class=&quot;info&quot;&gt; Comment &#123;&#123; forloop.counter &#125;&#125; by &#123;&#123; comment.name &#125;&#125; Created &#123;&#123; comment.created &#125;&#125; &lt;/p&gt; &#123;&#123; comment.body|linebreaks &#125;&#125; &lt;/div&gt;&#123;% empty %&#125; &lt;p&gt;No Comments.&lt;/p&gt;&#123;% endfor %&#125; 我们使用for模板标签循环commnets.如果评论为空,显示一条消息,提示用户现在还没有评论.列举评论使用forloop.counter变量,包含整数循环计数.然后我们显示评论用户名,日期,评论内容. 最后,需要渲染一个表单或显示成功提交消息. 12345678910111213141516&lt;span&gt; &#123;% if new_comment %&#125; &lt;h2&gt; Your comment has been added. &lt;/h2&gt; &#123;% else %&#125; &lt;h2&gt;Add a new commnet&lt;/h2&gt; &lt;form action=&quot;.&quot; method=&quot;post&quot;&gt; &#123;&#123; comment_form.as_p &#125;&#125; &#123;% csrf_token %&#125; &lt;p&gt; &lt;input type=&quot;submit&quot; value=&quot;Add comment&quot;&gt; &lt;/p&gt; &lt;/form&gt; &#123;% endif %&#125;&lt;/span&gt; 代码相当简洁直接.如果new_comment对象存在,显示一条成功消息.否则,显示post表单并包含csrf token.可以通过编辑http://127.0.0.1/admin/blog/comment active字段不显示不合适的评论,从文章评论中屏蔽它们. 添加标签功能完成实施comment系统后，接下来创建post tag.工程将整合一个第三方Django tag应用。django－tag模块是的利用程序，一个主要提供一个Tag model和轻松标签到任何model一个管理器.可以到https://github.com/alex/django-taggit查看源码。 首先，执行以下命令使用pip安装django-taggit。 1pip install django-taggit 打开settings.py文件添加taggit到INSTALLED_APPS: 12345678910INSTALLED_APPS = [ &apos;django.contrib.admin&apos;, &apos;django.contrib.auth&apos;, &apos;django.contrib.contenttypes&apos;, &apos;django.contrib.sessions&apos;, &apos;django.contrib.messages&apos;, &apos;django.contrib.staticfiles&apos;, &apos;blog.apps.BlogConfig&apos;, &apos;taggit&apos;,] 打开models.py文件添加django-taggit提供的TaggableManager管理器到Post model： 1234567from taggit.managers import TaggableManagerclass Post(models.Model): tags = TaggableManager() objects = models.Manager() ... tags管理器将允许从Post对象中添加，接收，移除tag。运行下面的命令创建migration。 1234567891011(django2byExample) haotianfei@tianfei-opensuse:~/PycharmProjects/Django2byExample&gt; python manage.py makemigrations blogMigrations for &apos;blog&apos;: blog/migrations/0003_post_tags.py - Add field tags to post(django2byExample) haotianfei@tianfei-opensuse:~/PycharmProjects/Django2byExample&gt; python manage.py migrateOperations to perform: Apply all migrations: admin, auth, blog, contenttypes, sessions, taggitRunning migrations: Applying taggit.0001_initial... OK Applying taggit.0002_auto_20150616_2121... OK Applying blog.0003_post_tags... OK 现在数据库已经准备好使用django-taggit models。让我们学习如何来使用tags管理器。打开终端python manage.py shell.首先，接收一个post；然后添加tags到这个post；检查是否已经成功添加。最后，移除一个tag然后再次检查。 1234567891011&gt;&gt;&gt; from blog.models import Post&gt;&gt;&gt; post = Post.objects.get(id=2)&gt;&gt;&gt; post&lt;Post: This is the second post&gt;&gt;&gt;&gt; post.tags.add(&apos;music&apos;, &apos;jazz&apos;, &apos;django&apos;)&gt;&gt;&gt; post.tags.all()&lt;QuerySet [&lt;Tag: music&gt;, &lt;Tag: jazz&gt;, &lt;Tag: django&gt;]&gt;&gt;&gt;&gt; post.tags.remove(&apos;django&apos;)&gt;&gt;&gt; post.tags.all()&lt;QuerySet [&lt;Tag: music&gt;, &lt;Tag: jazz&gt;]&gt;&gt;&gt;&gt; 是不是很容易？运行runserver命令，打开admin网站查看看tag对象。然后到post对象上查看tag字段，还可以编辑它。下面将在编辑post页面显示tags。打开blog/post/list.html template添加下面的html代码： 1&lt;p class=&quot;tags&quot;&gt;Tags: &#123;&#123; post.tags.all|join:&quot;, &quot; &#125;&#125;&lt;/p&gt; 接下来，我们将编辑post_list view让用户可以列出所有打了指定tag的posts。编辑view.py，从django-taggit import Tag model,通过修改post_list view使用可选的tag_slug过滤一个tag的所有posts: 123456789# tag,tag标签复用了post_list模板from taggit.models import Tagdef post_list(request, tag_slug=None): # 获取所有的post对象 object_list = Post.published.all() tag = None if tag_slug: tag = get_object_or_404(Tag, slug=tag_slug) object_list = Post.published.filter(tags__in=[tag]) post_list veiw作用流程如下:1 带入一个可选的参数tag_slug(默认为None).这个参数来自url.2 在view内部,创建一个初始QuerySet,接收所有发布的posts,但如果有一个tag slug参数,我们将使用get_object_or_404快捷方式带入slug取得Tag对象.3 然后,我们过滤包含tag的posts列表.这个一个多对多关联,所有使用包含过滤,在这里,只包含一个元素. QuerySet只在我们解析模板时才循环post列表.最后,修改view底部的render()函数将tag变量传递到模板. 12345return render(request, &apos;blog/post/listold.html&apos;, &#123;&apos;posts&apos;: posts, &apos;page&apos;: page, &apos;tag&apos;: tag&#125;) 编辑urls.py,注释掉PostListView,去掉post_list view的注释,添加tag 1path(&apos;tag/&lt;slug:tag_slug&gt;/&apos;, views.post_list, name=&apos;post_list_by_tag&apos;), 修改post_list.html加入tag判断 123456&#123;% for post in posts %&#125; &lt;p&gt; &#123;% if tag %&#125; &lt;h3&gt;Posts tagged with &#123;&#123; tag.name &#125;&#125;&lt;/h3&gt; &#123;% endif %&#125; &lt;/p&gt; 为每个tag标签添加超链接 1234567&lt;p class=&quot;tags&quot;&gt;Tags: &#123;% for p_tag in post.tags.all %&#125; &lt;a href=&quot;&#123;% url &quot;blog:post_list_by_tag&quot; p_tag.slug %&#125;&quot;&gt;&#123;&#123; p_tag.name &#125;&#125;&lt;/a&gt; &#123;% endfor %&#125; &#123;% if not forloop.last %&#125;&#123;% endif %&#125;&lt;/p&gt; 接收相似文章在post_detail view中计算相关性,在detail.html中列举: 123456789101112post_tags_ids = post.tags.values_list(&apos;id&apos;, flat=True)similar_posts = Post.published.filter(tags__in=post_tags_ids)\ .exclude(id=post.id)similar_posts = similar_posts.annotate(same_tags=Count(&apos;tags&apos;))\ .order_by(&apos;-same_tags&apos;, &apos;-publish&apos;)[:4]return render(request, &apos;blog/post/detail.html&apos;, &#123;&apos;post&apos;: post, &apos;comments&apos;: comments, &apos;new_comment&apos;: new_comment, &apos;comment_form&apos;: comment_form, &apos;similar_posts&apos;: similar_posts&#125;) 123456789101112&lt;span&gt; &lt;h2&gt;Similar Posts&lt;/h2&gt; &#123;% for similar_post in similar_posts %&#125; &lt;p&gt; &lt;a href=&quot;&#123;&#123; similar_post.get_absolute_url &#125;&#125;&quot;&gt;&#123;&#123; similar_post.title &#125;&#125;&lt;/a&gt; &lt;/p&gt; &#123;% empty %&#125; &lt;p&gt;There are no similar posts yet.&lt;/p&gt; &#123;% endfor %&#125;&lt;/span&gt; 总结]]></content>
      <categories>
        <category>django 2 by example</category>
      </categories>
      <tags>
        <tag>django</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Building a Blog Application 翻译加实践]]></title>
    <url>%2F2019%2F01%2F14%2FBuilding-a-Blog-Application%2F</url>
    <content type="text"><![CDATA[创建第一个工程第一个django工程是创建一个完整的blog.Django提供了一个命令创建和初始化工程文件结构. 1(django2byExample) haotianfei@tianfei-opensuse:~/PycharmProjects&gt; django-admin startproject django_2_by_example 这会创建一个名为django_2django_2_by_example的工程,工程名应该避免使用与python或django内置模块相同的名字,以免引起冲突.我们来看一下生成的工程结构: 12345678910(django2byExample) haotianfei@tianfei-opensuse:~/PycharmProjects&gt; tree django_2_by_example/django_2_by_example/├── django_2_by_example│ ├── __init__.py│ ├── settings.py│ ├── urls.py│ └── wsgi.py└── manage.py1 directory, 5 files manage.py: 这是一个与工程交互的命令行管理工具.这是一个对django-admin.py的简单封装,一般不需要修改这个文件. django_2_by_example: 工程目录,包括4个文件: init.py: 一个空文件,python将包含此文件的目录视为一个模块. settings.py: 工程配置文件,默认包含一些配置都在此文件中. urls.py: URL配置文件,每个条URL都映射到一个view. uwsgi.py: 工程通过此文件配置部署成web server gateway interface(WSGI)应用.生成的settings.py文件包含工程配置,其中默认配置了SQLite3的数据库及包含默认在INSTALLED_APPS列表中的通用应用.我们稍后将在工程设置部分研究这些应用.为了完成工程安装,需要在数据库中创建INSTALLED_APPS列表中的应用相应的表.运行下面的命令:12345678910111213141516171819(django2byExample) haotianfei@tianfei-opensuse:~/PycharmProjects&gt; cd django_2_by_example/(django2byExample) haotianfei@tianfei-opensuse:~/PycharmProjects/django_2_by_example&gt; python manage.py migrateOperations to perform: Apply all migrations: admin, auth, contenttypes, sessionsRunning migrations: Applying contenttypes.0001_initial... OK Applying auth.0001_initial... OK Applying admin.0001_initial... OK Applying admin.0002_logentry_remove_auto_add... OK Applying contenttypes.0002_remove_content_type_name... OK Applying auth.0002_alter_permission_name_max_length... OK Applying auth.0003_alter_user_email_max_length... OK Applying auth.0004_alter_user_username_opts... OK Applying auth.0005_alter_user_last_login_null... OK Applying auth.0006_require_contenttypes_0002... OK Applying auth.0007_alter_validators_add_error_messages... OK Applying auth.0008_alter_user_username_max_length... OK Applying auth.0009_alter_user_last_name_max_length... OK Applying sessions.0001_initial... OK 上面是Django数据库迁移输出信息.通过migrations,初始应用的表将在数据库中创建.在接下来的”创建及应用迁移”这一章节将会学习migrate管理命令. 在开发环境运行服务django提供了一个轻量web服务器以便快速测试代码,不需要花大量时间配置一个生产服务器.当运行django开发服务器,它将持续检测代码修改.重载是自动的,不需要代码修改后手工重载服务器.但有些行为可能不会被提示,例如添加新文件到工程,这里必需手动重载服务器.使用下面的命令在工程根目录运行开发服务器: 12345678(django2byExample) haotianfei@tianfei-opensuse:~/PycharmProjects/django_2_by_example&gt; python manage.py runserverPerforming system checks...System check identified no issues (0 silenced).January 11, 2019 - 06:39:35Django version 2.0.5, using settings &apos;django_2_by_example.settings&apos;Starting development server at http://127.0.0.1:8000/Quit the server with CONTROL-C. 打开浏览器,输入http://127.0.0.1:8000/将会显示成功运行界面.标志着Django开发服务器已经在运行中.返回命令行终端,会有GET请求记录打印: 1[11/Jan/2019 06:50:04] &quot;GET / HTTP/1.1&quot; 200 16348 每个HTTP请求都会被开发服务器记录并打印在终端.任何的错误信息同样会输出到终端.还可以订制django开发服务器使用指定IP与port,加载指定配置文件(当你拥有多个环境需要多个配置文件时可以为每个环境创建一个配置文件)的方式运行工程,如下: 1(django2byExample) haotianfei@tianfei-opensuse:~/PycharmProjects/django_2_by_example&gt; python manage.py runserver 127.0.0.1:8001 --settings=django_2_by_example.settings 当然开发服务器只能在开发时使用不能用于生产环境.生产部署django需要使用WSGI应用部署在真实的web服务器上,如apache,gunicorn或uWSGI.关于部署wsgi可以参阅https://docs.djangoproject.com/en/2.0/howto/deployment/wsgi/. 工程设置让我们打开settings.py文件看看我们工程的配置.这个文件包含许多配置,但这只是settings的一部分.全部参数参考https://docs.djangoproject.com/en/2.0/ref/settings/比较重要的设置如下: DEBUG: 布尔值,打开或关闭工程调试模式.默认是true,如果应用有非预期的错误,django会显示详细的错误信息.迁移到生产环境时记得设置为false.永远不要在生产环境打开DEBUG部署一个站点,因为有可能泄漏与工程相关的敏感信息. ALLOWED_HOSTS: DEBUG开启及tests时不生效.一旦迁移到生产环境,你可以添加域名允许解析站点. INSTALLED_APPS: 配置在django站点中启用的应用.Django默认包含以下应用: django.contrib.admin: 一个admin管理框架. django.contrib.auth: 一个认证框架. django.contrib.contenttypes: 内容类型处理框架. django.contrib.sessions: 会话框架. django.contrib.messages: 消息系统框架. django.contrib.staticfiles: 静态文件管理框架. MIDDLEWARE: 将要执行的中间件列表. ROOT_URLCONF: 应用定义url匹配位置. DATABASES: 工程中所有数据库信息.必须设置一个默认数据库.默认是SQLite3. LANGUAGE_CODE: 站点默认语言编码. USE_TZ: 打开或关闭时区支持. 工程和应用在django中,工程被视为带有一些设置的django安装.一个应用站点是模型,视图,模板和URLS的组合.应用与django框架交互提供一些特殊的功能,然后可以在其它工程中重用.可以把工程视作你的网站,包含了许多应用,如blog,wiki和forum.然后这些应用也可以在其它网站重用. 创建一个应用现在,让我创建每一个django应用.我们将一步步创建一个blog应用.进入工程根目录,运行下面的命令: 1(django2byExample) haotianfei@tianfei-opensuse:~/PycharmProjects/django_2_by_example&gt; python manage.py startapp blog 这将创建一个基本的应用结构,如下所示: 1234567891011(django2byExample) haotianfei@tianfei-opensuse:~/PycharmProjects/django_2_by_example&gt; tree.├── blog│ ├── admin.py│ ├── apps.py│ ├── __init__.py│ ├── migrations│ │ └── __init__.py│ ├── models.py│ ├── tests.py│ └── views.py 包括如下文件: admin.py: 注册到django admin管理框架模型,可选项. apps.py: blog应用的主配置文件. migrations: 应用数据库迁移文件目录.迁移允许django追踪model修改,然后相应的同步到数据库. models.py: 应用数据模型,所有的django文件都需要有一个数据模型文件,但可以内容为空. tests.py: 添加测试到应用. views.py: 定义应用逻辑; 每个视图接收http请求,处理请求,然后返回响应. 设置blog应用的数据库结构通过定义数据模型来设计blog的数据结构.一个模型是django.db.models.Model子类,每个属性对应数据库字段.django会为每个模型创建一个数据库表.通过创建模型,django提供了一个易于查询数据库的事实上的API接口.首先,我们将定义一个post模型.添加如下内容到models.py: 12345678910111213141516171819202122232425262728293031from django.db import models# create your models here.from django.utils import timezonefrom django.contrib.auth.models import Userclass Post(models.Model): STATUS_CHOICES = ( (&apos;draft&apos;, &apos;Draft&apos;), (&apos;published&apos;, &apos;Published&apos;), ) title = models.CharField(max_length=250) slug = models.SlugField(max_length=250, unique_for_date=&apos;published&apos;) author = models.ForeignKey(User, on_delete=models.CASCADE, related_name=&quot;blog_posts&quot;) body = models.TextField() publish = models.DateTimeField(default=timezone.now) created = models.DateTimeField(auto_now_add=True) updated = models.DateTimeField(auto_now=True) status = models.CharField(max_length=10, choices=STATUS_CHOICES, default=&apos;draft&apos;) class Meta: ordering = (&apos;-published&apos;,) def __str__(self): return self.title 模型属性: title: 文章标题,对应数据库中的varchar字段. slug: 这个字段被打算用于URLs.slug是一个只包含字母,数字,下划线,连字号的一个简短的标记.使用slug可以构建漂亮的,SEO友好的urls.我们为其添加了unique_for_data参数,以便创建使用发布日期与slub结合的文章urls.Django会阻止同一日期使用相同slug的文章. author: 这是一个外键.默认是多对一的关系.我们可以告诉Django文章由一个用户书写,一个用户可以书写一定数量的文章.使用外键,Django将会使用关联模型的主键在数据库中创建一个外键.我们可以信赖Django认证系统的User数据模型.on_delete参数指明当指向的对象删除时采纳的相应动作.这是SQL的基本动作.使用models.CASCADE,我们设定当指定的用户删除时,数据库将删除用户关联的所有文章.关于CASCADE可参考我们同时指定了一个反向关联名称related_name,表示从User到posts.这将轻松访问关联对象. body: 文章的主体内容,一个文本字段,对应SQL数据库的TEXT字段. publish: 当文章发布时的时间.使用Django的timezone的now方法生成,返回值是timezone可识别格式的当前时间.可以看作是python datatime.now方法. created: 文章创建时间.auto_now_add参数表示时间会自动保存到创建对象. updated: 文章更新时间.auto_now表示当更新时日期时间会自动保存. status: 发布状态.使用choice参数,只能在所预设的值中选择.Django在不同的模型中使用不同的类型,查阅参考Meta类包含模型的元数据.这里使用发布日期的倒序排序查询结果.最近发布的文章将排在第一位.str方法返回一个对人友好的描述.Django大量使用此方法,如管理站点. 激活应用为了让Django可以持续追踪应用,通过模型创建数据库表,首先要激活应用.修改settings.py在INSTALLED_APPS变量中添加blog.apps.BlogConfig. 1234567891011# Application definitionINSTALLED_APPS = [ &apos;django.contrib.admin&apos;, &apos;django.contrib.auth&apos;, &apos;django.contrib.contenttypes&apos;, &apos;django.contrib.sessions&apos;, &apos;django.contrib.messages&apos;, &apos;django.contrib.staticfiles&apos;, &apos;blog.apps.BlogConfig&apos;,] BlogConfig是blog应用主配置文件apps.py中定义的一个类.现在已经激活应用,可以加载应用模型了. 创建及应用migrations下面来创建数据库表.Django使用一个迁移系统追踪模型修改然后相应的应用到数据库.migrate命令为INSTALLED_APPS表中所有的应用实施与数据库的同步.首先,创建一个初始migration.执行下面的指令: 1234(django2byExample) haotianfei@tianfei-opensuse:~/PycharmProjects/django_2_by_example&gt; python manage.py makemigrations blogMigrations for &apos;blog&apos;: blog/migrations/0001_initial.py - Create model Post 初始化操作仅是创建了blog/migrations/0001_initial.py文件,一个迁移操作依赖其它迁移,当模型修改时执行数据库同步操作.我们来看一下将要对模型进行操作的SQL代码.附带了迁移名称的sqlmigrate命令可以返回SQL语句但不真正执行. 123456789(django2byExample) haotianfei@tianfei-opensuse:~/PycharmProjects/django_2_by_example&gt; python manage.py sqlmigrate blog 0001BEGIN;---- Create model Post--CREATE TABLE &quot;blog_post&quot; (&quot;id&quot; integer NOT NULL PRIMARY KEY AUTOINCREMENT, &quot;title&quot; varchar(250) NOT NULL, &quot;slug&quot; varchar(250) NOT NULL, &quot;body&quot; text NOT NULL, &quot;publish&quot; datetime NOT NULL, &quot;created&quot; datetime NOT NULL, &quot;updated&quot; datetime NOT NULL, &quot;status&quot; varchar(10) NOT NULL, &quot;author_id&quot; integer NOT NULL REFERENCES &quot;auth_user&quot; (&quot;id&quot;) DEFERRABLE INITIALLY DEFERRED);CREATE INDEX &quot;blog_post_slug_b95473f2&quot; ON &quot;blog_post&quot; (&quot;slug&quot;);CREATE INDEX &quot;blog_post_author_id_dd7a8485&quot; ON &quot;blog_post&quot; (&quot;author_id&quot;);COMMIT; Django默认使用应用+类名作为数据库表明,可以在meta类中使用db_table属性指定数据库表名.Django同时为每个模型创建一个主键,也可以便利属性primary_key=True手工指定一个字段为主键.默认主键字段是id,一个自增长整数字段.下面来实施数据库同步: 12345(django2byExample) haotianfei@tianfei-opensuse:~/PycharmProjects/django_2_by_example&gt; python manage.py migrateOperations to perform: Apply all migrations: admin, auth, blog, contenttypes, sessionsRunning migrations: Applying blog.0001_initial... OK 如果修改了model模型,需要makemigrates,然后使用migrate同步到数据库. 创建一个管理数据库站点已经创建好post模型,接下来创建一个简单的管理站点来管理blog文章.Django自带一个非常有用的管理接口编辑内容.Django管理站点通过读取模型元数据动态创建,提供了一个编辑内容的产品级接口.你可以开箱即用,在上面显示你想模型.django.contrib.admin默认已经在INSTALLED_APPS中,不需要自己添加. 创建超级用户首先,需要一个用户来管理站点. 12345678910(django2byExample) haotianfei@tianfei-opensuse:~/PycharmProjects/django_2_by_example&gt; python manage.py createsuperuserUsername (leave blank to use &apos;haotianfei&apos;): adminEmail address: talenhao@gmail.comPassword:Password (again):This password is too short. It must contain at least 8 characters.This password is too common.Password:Password (again):Superuser created successfully. 管理站点现在打开开发服务器,使用浏览器打开http://127.0.0.1:8000/admin. 1python manage.py runserver 使用刚才创建的超级用户及密码登陆.Group和User模型是由Django认证框架django.contrib.auth提供的.之前的Post模型使用auther字段就是关联到这里的User. 添加模型到管理站点现在添加blog post模型到管理站点.修改admin.py文件: 123456from django.contrib import admin# Register your models here.from blog.models import Postadmin.site.register(Post) 打开http://127.0.0.1:8000/admin将会看到新添加的Post.是不是很简单?当你的模型注册到管理站点,你会得到由内置框架生成的一个友好的界面,你可以轻松查看,编辑,创建和删除对象.点击右边的添加链接添加一篇新文章.Django针对不同的字段类型使用不同的插件,甚至混合字段如DateTimeField使用javascript 日期插件,也很好的显示出来.填入内容,然后点击保存按钮,会重定向到文章列表及显示一个成功的消息. 定制模型显示方式下面来定制管理站点.编辑admin.py: 123456789101112from django.contrib import admin# Register your models here.from blog.models import Post@admin.register(Post)class PostAdmin(admin.ModelAdmin): list_display = (&apos;title&apos;, &apos;slug&apos;, &apos;author&apos;, &apos;publish&apos;, &apos;status&apos;) 注册模型Post继承admin.ModelAdmin,使用自定制类.在这个自定类中,可以包括显示,及如何交互.list_display属性允许要显示在管理站对象列表的模型字段.@admin.register()装饰器代替admin.site.register(),注册我们的自定类PostAdmin如何ModelAdmin注册Post.下面来扩展更多参数: 1234567891011121314from django.contrib import admin# Register your models here.from blog.models import Post@admin.register(Post)class PostAdmin(admin.ModelAdmin): list_display = (&apos;title&apos;, &apos;slug&apos;, &apos;author&apos;, &apos;publish&apos;, &apos;status&apos;) list_filter = (&apos;author&apos;, &apos;publish&apos;, &apos;status&apos;, &apos;created&apos;, &apos;updated&apos;) search_fields = (&apos;title&apos;, &apos;body&apos;) prepopulated_fields = &#123;&apos;slug&apos;: (&apos;title&apos;,)&#125; raw_id_fields = (&apos;author&apos;,) date_hierarchy = &apos;publish&apos; ordering = (&apos;status&apos;, &apos;publish&apos;) 使用QuerySet和managers现在你拥有了全功能的管理站点来管理blog的内容,现在来从数据库接收信息及与之交互.Django自带了一个非常强大的抽象接口,可以轻松创建,接收,更新,删除对象.Django ORM(object-relateional mapper)可以兼容MySQL,PostgreSQL,SQLite,Oracle.不要忘记你可以在settings.py的DATABASES部分定义工程数据库.Django可以同时配置多个数据库,可以编辑数据库路由来自定义路由结构.一旦创建数据模型,可以自由的在Django中与之交互.数据模型参考官方文档 创建对象打开终端,然后运行下面的命令来打开python shell: 123456789101112(django2byExample) haotianfei@tianfei-opensuse:~/PycharmProjects/django_2_by_example&gt; python manage.py shellPython 3.6.5 (default, Mar 31 2018, 19:45:04) [GCC] on linuxType &quot;help&quot;, &quot;copyright&quot;, &quot;credits&quot; or &quot;license&quot; for more information.(InteractiveConsole)&gt;&gt;&gt; from django.contrib.auth.models import User&gt;&gt;&gt; from blog.models import Post&gt;&gt;&gt; user = User.objects.get(username=&quot;admin&quot;)&gt;&gt;&gt; post = Post(title=&quot;Auther admin post&quot;,... slug=&quot;Auther_admin_post&quot;,... body=&quot;Post body&quot;,... author=user)&gt;&gt;&gt; post.save() 首先使用用户名’admin’接收user对象.get()方法允许你从数据库中接收单个对象.这个方法预期会有一个匹配结果.如果没有结果匹配到,会返回DoesNotExist错误;如果返回多个结果,将会抛出MultipleObjectsReturned错误.接下来创建了一个post实例,填入title,slug,body,author使用上一步接收到的user,最后使用实例方法save()保存到数据库.save()会执行一个INSERT SQL语句,我们可以看到如何在内存中首先创建一个对象,然后持久化到数据库中.但我们还可以只需要一个create()操作创建对象然后持久化到数据库: 12&gt;&gt;&gt; Post.objects.create(title=&apos;One more post&apos;, slug=&apos;one-more-post&apos;, body=&apos;Post body&apos;, author=user)&lt;Post: One more post&gt; 更新对象现在修改一个post然后保存对象 12&gt;&gt;&gt; post.title = &apos;New title&apos;&gt;&gt;&gt; post.save() 这里的save()方法执行的UPDATE SQL语句 接收对象Django的 ORM基于QuerySets.一个QuerySets是从数据库中收集对象,然后设置多个过滤去限制结果.上面已经知道使用get()接收单个对象.每个Django模型都至少有一个管理器,这个默认的管理器叫做objects.你得到一个QuerySet对象使用模型管理器.为了从一个表中接收所有的对象,使用objects.all()方法 1&gt;&gt;&gt; all_posts = Post.objects.all() 使用filter()方法过滤QuerySets使用objects的filter()方法.举个例子,我们需要接收所有发布时间为2019年的文章使用如下的QuerySet: 12&gt;&gt;&gt; Post.objects.filter(publish__year=2019)&lt;QuerySet [&lt;Post: One more post&gt;, &lt;Post: New title&gt;, &lt;Post: This is the second post&gt;, &lt;Post: This is the first post.&gt;]&gt; 使用多个过滤条件: 12&gt;&gt;&gt; Post.objects.filter(publish__year=2019, author__username=&apos;admin&apos;)&lt;QuerySet [&lt;Post: One more post&gt;, &lt;Post: New title&gt;, &lt;Post: This is the second post&gt;, &lt;Post: This is the first post.&gt;]&gt; 上面的命令等效: 123&gt;&gt;&gt; Post.objects.filter(publish__year=2019)\... .filter(author__username=&apos;admin&apos;)&lt;QuerySet [&lt;Post: One more post&gt;, &lt;Post: New title&gt;, &lt;Post: This is the second post&gt;, &lt;Post: This is the first post.&gt;]&gt; 使用exclude()可以使用objects.exclude()从结果中排除适当的内容. 123&gt;&gt;&gt; Post.objects.filter(publish__year=2019)\... .exclude(title__startswith=&quot;New&quot;)&lt;QuerySet [&lt;Post: One more post&gt;, &lt;Post: This is the second post&gt;, &lt;Post: This is the first post.&gt;]&gt; 使用order_by()可以使用objects.order_by()方法按不同的字段排序结果.-号表示反序. 1234&gt;&gt;&gt; Post.objects.order_by(&apos;-title&apos;)&lt;QuerySet [&lt;Post: This is the second post&gt;, &lt;Post: This is the first post.&gt;, &lt;Post: One more post&gt;, &lt;Post: New title&gt;]&gt;&gt;&gt;&gt; Post.objects.order_by(&apos;title&apos;)&lt;QuerySet [&lt;Post: New title&gt;, &lt;Post: One more post&gt;, &lt;Post: This is the first post.&gt;, &lt;Post: This is the second post&gt;]&gt; 删除对象如果想删除一个对象,可以使用对象实例方法delete() 12345&gt;&gt;&gt; post_new = Post.objects.get(id=1)&gt;&gt;&gt; post_new&lt;Post: This is the first post.&gt;&gt;&gt;&gt; post_new.delete()(1, &#123;&apos;blog.Post&apos;: 1&#125;) QuerySet评估操作你可以串连尽可能多的过滤到QuerySet,在没有评估之间是不会去数据库的.QuerySet只会在下面的情况下被评估: 第一次迭代 当有切片操作,对于实例,Post.objectes.all()[:3] 当数据有pickle或缓存操作 使用repr()或len() 明确的调用list() 使用测试语句,如bool(),or,and,if 创建模型管理器objects是每个模型在数据库中的默认管理器.但我们还可以为模型定制管理器.我们将创建一个定制管理器接收所有published状态的文章.有2种方式添加管理器:扩展默认管理器方法或修改初始QuerySets.前者提供一个QuerySets接口如Post.objects.my_manager(),后者提供如Post.my_manager.all().管理器允许我们使用Post.published.all()接收文章.编辑model.py文件添加自定管理器: 12345678class PublishedManager(models.Manager): def get_queryset(self): return super(PublishedManager, self).get_queryset().filter(status=&apos;published&apos;)class Post(models.Model): objects = models.Manager() published = PublishedManager() get_queryset方法用于管理器返回QuerySet.上面采取了覆盖方法,包含了自定过滤条件. 12&gt;&gt;&gt; Post.published.all()&lt;QuerySet [&lt;Post: This is the second post&gt;]&gt; 构建列表及详细视图现在已经具有了ORM的知识,现在可以为blog应用创建视图了.Django视图是能够接收web请求然后返回一个web响应的python函数.所有预期的响应逻辑都是包含在视图中.首先,我们将创建应用视图,然后为每一个视图定义一个URL匹配,最后创建HTML模板渲染视图生成的数据.每个视图都会传递变量到渲染的模板,然后伴随渲染输出返回一个HTTP响应. 创建列表及详细视图现在开始创建一个显示文章列表的视图.编辑blog应用的views.py文件如下: 123456789101112from django.shortcuts import render# Create your views here.from django.shortcuts import get_object_or_404from .models import Postdef post_list(request): posts = Post.objects.all() return render(request, &apos;blog/post/list.html&apos;, &#123;&apos;posts&apos;: posts&#125;) 这是每个django视图.post_list视图只需要带入request对象作为惟一参数.request也被所有视图作为参数.在这个视图中,我们使用自建管理器published接收了所有published状态的文章.最后我们使用django提供的render()快捷函数使用模板渲染文章列表.这个函数带入request对象,模板路径,内容变量渲染指定模板.最终返回一个包含渲染文本(通常是HTML代码)的HttpResponse对象.render快捷函数request上下文考虑在内,因此模板上下文处理器设置的任何变量都可以被给定的模板访问.模板上下文处理器是可调用的,用于将变量设置到上下文中.你将会在第三章扩展blog应用中学习如何使用他们.让我们创建第二个视图以显示单个post.添加下面的函数到view.py文件 12345678910def post_detail(request, year, month, day, post): post = get_object_or_404(Post, slug=post, status=&apos;published&apos;, publish__year=year, publish__month=month, publish__day=day) return render(request, &apos;blog/post/detail.html&apos;, &#123;&apos;post&apos;: post&#125;) 这是文章详细视图.这个视图带入year,month,day和post参数来接收给定slug和日期的发布状态文章.在这里,我们确认使用slug与日期只匹配一篇文章.在详细视图,我们使用get_object_or_404()快捷函数接收预期的文章.这个函数接收给定参数所匹配到的对象或在没有对象找到时明确的弹出HTTP404.最后,我们使用render快捷函数使用一个模板渲染接收到的文章. 为视图添加URL匹配URL匹配允许你映射URLs到视图.一个URL匹配由一个字符串匹配,一个视图和一个工程域可用指向这个URL的名称的可选项.Django顺序执行每个URL匹配然后停止在第一个匹配到的请求URL.然后Django导入匹配URL规则的视图然后执行它,传递一个HttpRequest类和关键字或位置参数.创建一个urls.py文件在blog应用目录然后添加如下的代码: 12345678910111213from django.urls import pathfrom . import viewsapp_name = &apos;blog&apos;urlpatterns = [ # post views path(&apos;&apos;, views.post_list, name=&apos;post_list&apos;), path(&apos;&lt;int:year&gt;/&lt;int:month&gt;/&lt;int:day&gt;/&lt;slug:post&gt;/&apos;, views.post_detail, name=&apos;post_detail&apos;),] 在上面的代码中,我们定义了一个使用app_name变量的应用空间.这允许我们通过指定它们的名字的应用组织URLs.我们使用path()定义了两个不同的匹配.第一个URL匹配不带入任何参数,指向post_list视图.第二个带入下面四个参数然后映射到post_detail视图. year: 整数 month: 整数 day: 整数 post: 提交的文章slug我们使用单个&lt;&gt;捕捉URL的值.任何使用&lt;参数&gt;匹配的URL指定匹配都被捕捉为字符串.我们使用类似int:year的路径转换,指定匹配规则,返回一个整数和使用类似slug:post指定匹配一个slug(一个包含asscii字符或数字,连接符-,下划线_的字符串).你可以查看所有路径转换符参考 https://docs.djangoproject.com/en/2.0/topics/http/urls/#path-converters如果使用path()和转换不满足你的要求,你可以使用re_path()包含混合RUL匹配规则使用python正则表达式(https://docs.djangoproject.com/en/2.0/ref/urls/#django.urls.re_path).如果你没有学习过正则表达式,你可以先看一下正则表达式howto(https://docs.python.org/3/howto/regex.html).创建应用单独的urls.py文件是被其它工程重用的最好手段.现在你必须在工程主url匹配中包含blog应用的url匹配规则.编辑工程urls.py文件:123456789from django.contrib import adminfrom django.urls import pathfrom django.urls import includeurlpatterns = [ path(&apos;admin/&apos;, admin.site.urls), path(&apos;blog/&apos;, include(&apos;blog.urls&apos;, namespace=&apos;blog&apos;)),] 新的URL匹配规则使用blog/的路径,include指向blog中定义的urls匹配规则.我们在Namespace(命令空间)blog下使用那些匹配.NameSpace在整个工程环境下是非重复的,后面,我们在Namespace中轻松指定我们的blog应用,类似blog:post_list,blog:blog_detail.你可以学习到更多的namesapce通过下面的链接(https://docs.djangoproject.com/en/2.0/topics/http/urls/#url-namespaces) models正式的urls你可以使用上面定义的post_detail为post对象创建正式的URL.在django中习惯在model中添加一个get_absolute_url()方法.使用这个方法,我们将使用reverse()方法带入名称及转入可选参数创建urls.编辑models.py文件然后添加如下: 12345678910111213from django.urls import reverseclass Post(models.Model): ... def get_absolute_url(self): return reverse(&apos;blog:post_detail&apos;, args=[ self.published.year, self.published.month, self.published.day, self.slug ]) 我们将在templates中使用get_absolute_url()方法链接到指定posts 为views创建templates我们将为blog应用创建views和url patterns.现在,是时候使用用户友好的方式添加templates显示posts.在blog应用目录下创建下面的目录及文件: 12345678910haotianfei@tianfei-opensuse:~/PycharmProjects/django_2_by_example/blog&gt; pwd/home/haotianfei/PycharmProjects/django_2_by_example/bloghhaotianfei@tianfei-opensuse:~/PycharmProjects/django_2_by_example/blog&gt; tree templates/templates/└── blog ├── base.html └── post ├── detail.html └── list.html base.html包含网站的主HTML,分成主内容区及侧边栏区.list.html和detail.html文件继承base.html文件分别来渲染blog post列表和详细视图.Django拥有一个强大的template语言允许你指定数据如何显示.它基于模板标签,模板变量和模板过滤器: 模板标签控制渲染模板,如 1&#123;% tag %&#125; 模板变量在渲染时替换值, 如 1&#123;&#123; variable &#125;&#125; 模板过滤器允许修改变量显示, 如 1&#123;&#123; variable|filter &#125;&#125; 你能够看到所有内置的模板标签和过滤器在这个页面:https://docs.djangoproject.com/en/2.0/ref/templates/builtins/让我们来修改base.html文件添加如下的代码: 12345678910111213141516171819202122&#123;% load static %&#125;&lt;!DOCTYPE html&gt;&lt;html lang=&quot;en&quot;&gt;&lt;head&gt; &lt;meta charset=&quot;UTF-8&quot;&gt; &lt;title&gt;&#123;% block title %&#125; &#123;% endblock %&#125;&lt;/title&gt; &lt;link href=&quot;&#123;% static &quot;css/blog.css&quot; %&#125;&quot; rel=&quot;stylesheet&quot;&gt;&lt;/head&gt;&lt;body&gt; &lt;div id=&quot;content&quot;&gt; &#123;% block content %&#125; &#123;% endblock %&#125; &lt;/div&gt; &lt;div id=&quot;sidebar&quot;&gt; &lt;h2&gt;Tf&apos;s blog&lt;/h2&gt; &lt;p&gt;This is my blog.&lt;/p&gt; &lt;/div&gt;&lt;/body&gt;&lt;/html&gt; 1&#123;% load static %&#125; 告知Django加载在INSTALLED_APPS中设置的由dango.contrib.staticfiles应用提供的static静态模板标签.加载后就可以在模板的任何地方使用 1&#123;% static %&#125; 模板过滤器.通过这个过滤器,你可以过滤静态文件,比如位于static目录下的blog.css文件.在这里有2个 1&#123;% block %&#125; 标签.这些标签通告Django我们想要在那个区域定义一个代码块.继承于此模板的所有模板能够用内容填允在这个些块中.我们这里定义了title和content块.让我们来编辑post/list.html: 123456789101112131415161718192021&#123;% extends &quot;blog/base.html&quot; %&#125;&#123;% block title %&#125;Tianfei&apos;s Blog&#123;% endblock %&#125;&#123;% block content %&#125; &lt;h1&gt;我的Blog&lt;/h1&gt; &#123;% for post in posts %&#125; &lt;h2&gt; &lt;a href=&quot;&#123;&#123; post.get_absolute_url &#125;&#125;&quot;&gt; &#123;&#123; post.title &#125;&#125; &lt;/a&gt; &lt;/h2&gt; &lt;p class=&quot;date&quot;&gt; Published &#123;&#123; post.publish &#125;&#125; by &#123;&#123; post.author &#125;&#125; &lt;/p&gt; &#123;&#123; post.body|truncatechars:60|linebreaks &#125;&#125; &#123;% endfor %&#125;&#123;% endblock %&#125; 使用 1&#123;% extends %&#125; 模板标签,我们告知Django继承blog/base.html模板.然后,我们将内容填充到base.html的title和content块中.整合posts,显示post的title,data,author,body字段,为title配置规划的链接到post.post的body部分应用了2个过滤器,truncatechars截取了部分字符 ,linebreaks转换输出为html格式.你可以按照你的想法将过滤器可以多个串起;每一个过滤器都将作用于上一个过滤器的输出.此时运行python manage.py runserver开启开发服务器.打开http://127.0.0.1/blog.然后编辑post/detail.html: 123456789101112131415&#123;% extends &quot;blog/base.html&quot; %&#125;&#123;% block title %&#125; &#123;&#123; post.title &#125;&#125;&#123;% endblock %&#125;&#123;% block content %&#125; &lt;h1&gt; &#123;&#123; post.title &#125;&#125; &lt;/h1&gt; &lt;p class=&quot;date&quot;&gt; Published &#123;&#123; post.publish &#125;&#125; by &#123;&#123; post.author &#125;&#125; &lt;/p&gt; &#123;&#123; post.body|linebreaks &#125;&#125;&#123;% endblock %&#125; 返回浏览器,点击列表中的post标题,将会在新的页面查看post内容.url被设计成针对blog post SEO友好的. 添加分页当你已经开添加内容到blog,你很快就会领悟到需要分割post列表到多个页面上.Django拥有一个内置的分布类轻松管理分页数据.编辑blog的view.py文件然后导入分布类,修改post_list视图: 1234567891011121314151617181920212223from django.core.paginator import Paginator, EmptyPage, PageNotAnIntegerdef post_list(request): # 获取所有的post对象 object_list = Post.published.all() # 以每页3篇post初始化paginator对象实例 paginator = Paginator(object_list, 3) # 获取当前所处页数.从页面传递过来一个&quot;page&quot; page = request.GET.get(&apos;page&apos;) try: # 获取当前页的posts对象 posts = paginator.page(page) except PageNotAnInteger: # 如果返回page页数不足1,即非整数,只显示一页即第一页 posts = paginator.page(1) except EmptyPage: # if page is empty, disable the lastest page posts = paginator.page(paginator.num_pages) return render(request, &apos;blog/post/list.html&apos;, &#123;&apos;posts&apos;: posts, &apos;paginator&apos;: paginator&#125;) pagination工作流程是:1 把我们想每页显示的post数作为参数实例化Paginator类2 我们使用request.GET.get得到当前页数值3 我们继承使用Paginator实例对象的page()方法得到要显示的posts4 在执行上步过程中,如果当前页数值是非整数(有可能输入了非法字符),我们将接收第一个页面.如果当前请求面大于最大页面数,我们将显示最后一页(有可能是在URL直接输入了更大的值).5 传递页数及接收到的posts对象到模板.在这里我们单独创建一个pagination模板,以便其它有需要分布的模板可以直接套用.在blog应用的templates目录下创建pagination.html. 12345678910111213141516171819&lt;div class=&quot;pagination&quot;&gt; &lt;span class=&quot;step-links&quot;&gt; &#123;% if page.has_previous %&#125; &lt;a href=&quot;?page=&#123;&#123; page.previous_page_number &#125;&#125;&quot;&gt; Previous &lt;/a&gt; &#123;% endif %&#125; &lt;/span&gt; &lt;span&gt; Page &#123;&#123; page.number &#125;&#125; of &#123;&#123; page.paginator.num_pages &#125;&#125; &lt;/span&gt; &lt;span&gt; &#123;% if page.has_next %&#125; &lt;a href=&quot;?page=&#123;&#123; page.next_page_number &#125;&#125;&quot;&gt;Next&lt;/a&gt; &#123;% endif %&#125; &lt;/span&gt;&lt;/div&gt; 这个pagination模板需要一个page对象来渲染上一个与下一个链接,显示当前页在总页数中的位置.让我们返回blog/templates/list.html的内容块中插入pagination模板: 123&#123;% block content %&#125; &#123;% include &quot;pagination.html&quot; with page=posts%&#125;&#123;% endblock %&#125; 自此我们传递了一个page=posts的参数到list.html模板.pagination.html模板包含在list.html中会正确渲染.可以使用此方法在其它需要分页的模型中重用pagination模板. 使用基于类视图基于类视图是一种使用python对象代替函数实施视图的辅助方法.自从视图调用带入一个web请求然后返回一个web响应,你还可以调用你的视图用类方法.Django提供继承于view类的基于类视图,可以快速处理HTTP方法及公共的功能.基于类视图提供高于基于函数视图的使用.它们具有以下特性: 关联HTTP方法组织代码,如GET,POST,PUT,使用特殊的方法代替分歧. 使用多少继承创建可重用的视图类.我们将修改我们的post_list视图使用由Django提供的基于类的视图ListView.这个基本视图允许你列举任何对象.修改view.py:123456789# Use class-base viewfrom django.views.generic import ListViewclass PostListView(ListView): queryset = Post.published.all() context_object_name = &apos;posts&apos; paginate_by = 3 template_name = &apos;blog/post/list.html&apos; 基于类视图与之前的post_list视图非常相似.在上面的代码中,我们告诉ListView做如下的事情: 使用指定queryset代替接收所有对象.定义一个queryset属性,我们能够指定使用model=Post,Django会为我们创建Post.object.all() queryset对象. 使用上下文变量posts接收查询结果.如果没有指定context_object_name默认变量是object_list. 使用自定义模板渲染页面.如果未指定模板,ListView将使用blog/post_list.html关于基本类视图可查看https://docs.djangoproject.com/en/2.0/topics/class-based-views/intro/现在,修改urls.py注释掉post_list URL匹配规则,添加使用类URL匹配规则:123456urlpatterns = [ # post views path(&apos;list/&apos;, views.post_list, name=&apos;post_list_old&apos;), path(&apos;&apos;, views.PostListView.as_view(), name=&apos;post_list&apos;), ...] 同时为了保持pagination正常,我们需要修改接收的page对象.Django的ListView通用视图使用page_obj变量传递,所以我们修改post/list.html模板: 1&#123;% include &quot;pagination.html&quot; with page=page_obj%&#125; 总结在这一章节,我们学习了Django web 框架的基础.创建了视图,模板,URLS,包含了一个分页对象.]]></content>
      <categories>
        <category>django 2 by example</category>
      </categories>
      <tags>
        <tag>django</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[virtualenvwrapper使用]]></title>
    <url>%2F2019%2F01%2F11%2Fvirtualenvwrapper%E4%BD%BF%E7%94%A8%2F</url>
    <content type="text"><![CDATA[virtualenvwrapper简介virtualenvwrapper是virtualenv的一组扩展工具.它方便了创建,删除python虚拟开发环境,使得管理多个虚拟python环境变得更容易 Features在一个地方组织管理所有的虚拟开发环境.封装简化了管理虚拟环境(创建,删除,复制等).使用单一命令就可快在不同环境快速切换.命令行下支持环境名tab补全.支持操作配置.丰富的插件. 安装1haotianfei@tianfei-opensuse:~ &gt; sudo pip install virtualenvwrapper 将下面的初始变量添加天.bashrc中 123export WORKON_HOME=&apos;~/.virtualenvs&apos;export VIRTUALENVWRAPPER_PYTHON=/usr/bin/python3.6source /usr/bin/virtualenvwrapper.sh 创建一个虚拟环境 1234567891011haotianfei@tianfei-opensuse:~ &gt; mkvirtualenv d2beUsing base prefix &apos;/usr&apos;New python executable in /home/haotianfei/.virtualenvs/d2be/bin/python3Also creating executable in /home/haotianfei/.virtualenvs/d2be/bin/pythonInstalling setuptools, pip, wheel...done.virtualenvwrapper.user_scripts creating /home/haotianfei/.virtualenvs/d2be/bin/predeactivatevirtualenvwrapper.user_scripts creating /home/haotianfei/.virtualenvs/d2be/bin/postdeactivatevirtualenvwrapper.user_scripts creating /home/haotianfei/.virtualenvs/d2be/bin/preactivatevirtualenvwrapper.user_scripts creating /home/haotianfei/.virtualenvs/d2be/bin/postactivatevirtualenvwrapper.user_scripts creating /home/haotianfei/.virtualenvs/d2be/bin/get_env_details 显示当前已经创建的虚拟环境 1234(d2be) haotianfei@tianfei-opensuse:~ &gt; lsvirtualenvd2be====d2b3 切换虚拟环境 1(d2be) haotianfei@tianfei-opensuse:~ &gt; workon d2be 退出 1(d2b3) haotianfei@tianfei-opensuse:~&gt; deactivate 删除 12haotianfei@tianfei-opensuse:~&gt; rmvirtualenv d2b3Removing d2b3...]]></content>
      <categories>
        <category>django 2 by example</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>django</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[django 2 by example环境]]></title>
    <url>%2F2019%2F01%2F10%2Fdjango-2-by-example%E7%8E%AF%E5%A2%83%2F</url>
    <content type="text"><![CDATA[使用虚拟环境: 1haotianfei@tianfei-opensuse:~/pyproject&gt; sudo pip3 install virtualenv 指定python版本为3.6 1234567891011121314151617181920212223242526haotianfei@tianfei-opensuse:~/pyproject&gt; virtualenv --python=python3.6 django2byExampleRunning virtualenv with interpreter /usr/bin/python3.6Using base prefix &apos;/usr&apos;New python executable in /home/haotianfei/pyproject/django2byExample/bin/python3.6Also creating executable in /home/haotianfei/pyproject/django2byExample/bin/pythonInstalling setuptools, pip, wheel...done.haotianfei@tianfei-opensuse:~/pyproject/django2byExample/bin&gt; source ~/pyproject/django2byExample/bin/activate(django2byExample) haotianfei@tianfei-opensuse:~/pyproject/django2byExample/bin&gt;(django2byExample) haotianfei@tianfei-opensuse:~/pyproject/django2byExample/bin&gt; sudo pip3 install virtualenvwrapperhaotianfei@tianfei-opensuse:~/github/tianfei/talenhao.github.io.hexo&gt; export WORKON_HOME=~/.virtualenvs/haotianfei@tianfei-opensuse:~/github/tianfei/talenhao.github.io.hexo&gt; export VIRTUALENVWRAPPER_PYTHON=/usr/bin/python3.6haotianfei@tianfei-opensuse:~/github/tianfei/talenhao.github.io.hexo&gt; virtualenvwrapper.shvirtualenvwrapper.user_scripts creating /home/haotianfei/.virtualenvs/premkprojectvirtualenvwrapper.user_scripts creating /home/haotianfei/.virtualenvs/postmkprojectvirtualenvwrapper.user_scripts creating /home/haotianfei/.virtualenvs/initializevirtualenvwrapper.user_scripts creating /home/haotianfei/.virtualenvs/premkvirtualenvvirtualenvwrapper.user_scripts creating /home/haotianfei/.virtualenvs/postmkvirtualenvvirtualenvwrapper.user_scripts creating /home/haotianfei/.virtualenvs/prermvirtualenvvirtualenvwrapper.user_scripts creating /home/haotianfei/.virtualenvs/postrmvirtualenvvirtualenvwrapper.user_scripts creating /home/haotianfei/.virtualenvs/predeactivatevirtualenvwrapper.user_scripts creating /home/haotianfei/.virtualenvs/postdeactivatevirtualenvwrapper.user_scripts creating /home/haotianfei/.virtualenvs/preactivatevirtualenvwrapper.user_scripts creating /home/haotianfei/.virtualenvs/postactivatevirtualenvwrapper.user_scripts creating /home/haotianfei/.virtualenvs/get_env_details 或使用virtualenvwrapper 123456789101112haotianfei@tianfei-opensuse:~&gt; mkvirtualenv django2byExampleUsing base prefix &apos;/usr&apos;New python executable in /home/haotianfei/.virtualenvs/django2byExample/bin/python3Also creating executable in /home/haotianfei/.virtualenvs/django2byExample/bin/pythonInstalling setuptools, pip, wheel...done.virtualenvwrapper.user_scripts creating /home/haotianfei/.virtualenvs/django2byExample/bin/predeactivatevirtualenvwrapper.user_scripts creating /home/haotianfei/.virtualenvs/django2byExample/bin/postdeactivatevirtualenvwrapper.user_scripts creating /home/haotianfei/.virtualenvs/django2byExample/bin/preactivatevirtualenvwrapper.user_scripts creating /home/haotianfei/.virtualenvs/django2byExample/bin/postactivatevirtualenvwrapper.user_scripts creating /home/haotianfei/.virtualenvs/django2byExample/bin/get_env_details(django2byExample) haotianfei@tianfei-opensuse:~&gt; workon django2byExample 安装django 12345678910(django2byExample) haotianfei@tianfei-opensuse:~&gt; pip install django==2.0.5(django2byExample) haotianfei@tianfei-opensuse:~&gt; lssitepackagesdjango easy_install.py pip-18.1.dist-info __pycache__ pytz-2018.9.dist-info setuptools-40.6.3.dist-info wheel-0.32.3.dist-infoDjango-2.0.5.dist-info pip pkg_resources pytz setuptools wheel(django2byExample) haotianfei@tianfei-opensuse:~&gt; pythonPython 3.6.5 (default, Mar 31 2018, 19:45:04) [GCC] on linuxType &quot;help&quot;, &quot;copyright&quot;, &quot;credits&quot; or &quot;license&quot; for more information.&gt;&gt;&gt; import django&gt;&gt;&gt; django.__version__&apos;2.0.5&apos;]]></content>
      <categories>
        <category>django 2 by example</category>
      </categories>
      <tags>
        <tag>django</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[chapter1 Go简介 翻译实践]]></title>
    <url>%2F2019%2F01%2F08%2Fgo%E8%AF%AD%E8%A8%80%E7%AE%80%E4%BB%8B%2F</url>
    <content type="text"><![CDATA[1 Go简介计算机一直在演进,但编程语言却原地踏步.手机处理器已经比我们最初的电脑核心数还要多,高性能服务器已经有64,128个甚至更多的核心,但我们还在使用基于单个核心的编程技术.编程的艺术也已经进化.许多程序已经不再是单一开发者:它们被分布在不同时区与不同时间的团队编写.大型项目被分成小块分配给程序员,然后以软件库或包的形式递送回组成完整的应用.今天的程序员与计算越来越相信开源软件的力量.Go是一种轻松共享代码程序语言.Go工具集使得使用其它人的打包更轻松,也更容易共享自己的包.在这一章你会看到Go与其它编程语言的不同.Go重新思考了传统的面向对象的开发,并提供了一个有效的代码重用思想.Go使得有效的利用现存服务器的所有核心更容易,在大型项目中的不利因素一去不复返. 1.1 使用Go解决当今编程挑战Go团队长期致力于解决面向软件开发的问题.开发者经常为项目的快速开发与性能之间做痛苦的语言选择.C和C++运行快速,但例如ruby和python经常可以快速开发.Go架起了两者的桥梁,并为快速开发提供了高性能特性.作为一门编程语言,Go被定义为不限定它包含的,也包括它不包含的.Go提供了简明的语法及少量的关键字易于记忆.Go提供了超快的编译器,以至于你会感觉不到它运行过.作为GO开发者,明显花费更少的时间等待项目创建.由于GO内置并行特性,软件不需要被调度使用资源而强制使用特殊的进程库.GO使用简单有效的类系统封装面向对象开发,你可以专注于代码重用.GO提供了GC垃圾回收,不需要关注内存管理. 1.1.1 敏捷开发使用C或C++编译大型应用通常花费大量的时间.GO通过使用智能编译器与简便的信赖解决算法提供快速轻量的编译.当你创建一个GO程序,编译器只需要查看直接包含的库,而不是像jave,c,c++一样追踪全部包所包含的所有库的依赖.所以许多GO应用秒内编译.全部的GO资源树在当今的硬件条件下20秒内编译.使用动态语言编写应用使得产品快速开发因为它们在写代码与执行之间没有中间步骤.交换的代价是动态语言不能提供type安全,但静态语言可以.运行同时需要全面的测试套件去调用发现不正确的type bugs.想像一下使用动态语言如javascript编写大型应用,通过一个函数等待接收一个ID字段.这个字段是一个整数,字符串还是UUID?只能通过查看源代码找出来.你可以尝试执行这个函数传入一个数字,字符串然后查看将会发生什么.在GO中,你不需要花费时间惊异,因为编译器会为你捕捉不同. 1.1.2 并行作为程序员的一件困难的事是编写高效地利用硬件上运行的可用资源的应用.现在计算机会有多个核心,但多数程序语言没有高效的工具轻松调度那些附加的资源.它们通常需要大量的线程同步代码,容易带来错误.GO的concurryency是它强大的特性之一.goroutines类型线程,但使用非常少的内存,只需要非常少的代码实现.Channels可以与内部go例行程序同步发送typed信息.这简化了一个程序模型,你可以在goroutines之间发送数据,而不是让goroutines序使用相同的数据.下面来详细查看这些特性. 1.1.2.1 goroutinesgoroutines是与其它goroutines并行运行的功能,是程序的接入口.类似在其它编程语言中使用的线程,但go语言中一个线程上运行多个goroutines.举例说明,如果你想写一个web服务程序同时处理不同的web请求,在C或java中你必须写大量的额外代码处理线程.但在GO内置goroutines使用net/http库处理并行.每个请求自动绑定并只在自己的goroutine中运行.goroutines相比threads只需更少内存,go runtime会自动调度goroutines的执行,配置分配给一些的逻辑处理器.每个逻辑处理器绑定到单个OS thread.如此使得你的应用显著的减少开发工作量更有效率.如果你想并行的执行一些代码以便抽出时间完成其它事情,对此goroutine是完美的.如上所述,goruotines的开销很小,所以成千上万的大量运行是常见的. 1.1.2.2 ChannelsChannels是一种在goroutines之间安全的数据通信的数据构造.channels可以帮助减少编程语言共享内存访问中的常规错误.并行最大的挑战是确保数据不会被并行运行的程序,线程或goroutines非预期的修改.当多个线程在没有锁或同步机制的状态下修改相同的数据,悲剧总是发生.在其它编程语言中,当你拥有全局变量和共享内存,你需要使用复杂的锁练习避免对同一变量的非同步修改.Channels的解决方法是提供了一个pattern确保并行修改数据安全.Channels强制pattern同一时间只能有一个goroutine修改数据.想像一下应用有许多不同的进程需要顺序地调用或修改数据.使用goruntines和channels,你可以安全的建模.如上图,有3个goroutines,2个channels.goroutine 1 通过channel one发送数据到已经等待中的goroutines 2.两个goroutines的数据交换是同步的,一旦传送发生,两个goroutines都会知道交换地址.当goroutine 2 使用这些数据处理完它的任务,它会发送这些数据到已经等待中的goroutine3.交换同样是同步的,双方都可以保证交换成功.这种安全的交换数据方式不需要其它的锁或同步架构.重要的一点,channels不提供数据访问保护.如果多份数据通过channel交换,每个goroutine只能修改自己那份保证了数据安全.如果数据指向变动,每个goroutine要读写数据的话仍然需要同步. 1.1.3 GO的类型系统Go提供了一个灵活的无层次的类型系统,它可以最小重构开销重用代码.它仍然面向对象开发,但没有传统的困扰.如果你曾经在java或C++程序中花费大量时间规划抽象类和接口,你会意识到GO简单类型系统的优点.GO composition使开发者重用功能只要简单的封闭类型.其它编程语言使用composition会深感疲惫于继承,非常复杂及难用.go的类型由小型类组成,区别于传统的基于继承的模式.另外,GO有一个独特的接口实现,允许你建模行为,而不是建模类型.你不需要宣告你的行为接口,编译器的工作会确定类型值是否满足你正使用的接口.GO的基本库的接口通常非常小,只提供了少量的功能.在实践中这将花费一些时间适应,特别是你一直使用面向对象的语言,如java. 类型相当简单Go拥有内置类如int和string,同时还有用户定义类型.一个典型的用户自定类是存储数据的类字段.如果你了解C的数据结构,GO的用户定义类看起来熟悉,操作也相似.但类需要宣告方法操作那些数据.崦不是创建一长串的继承结构-客户端扩展-用户扩展-实体.GO开发者创建小型类,客户与管理员,然后嵌入一个更大一点类. 小行为接口模型接口表达了类行为.如果一个类值实现在接口,意味着这个类值拥有了一系列的行为.你不需要宣告你实现了一个接口,只要编写这个实现.在其它编程语言中称为鸭子类型–如果它叫起来像鸭子,它就可以是个鸭子.GO是这种说法的很好实现.在GO中,如果你的类实现一个接口方法,一个类值会被存储在接口上.不需要特别的声明.在严格的面向对象语言如JAVA,接口总是被围绕.你总是需要在写代码前思考一个大型的继承链. 1234interface User &#123;public void login();public void logout();&#125; 用java实现这个接口需要完整满足所有许诺的类,明确的宣告实现的接口.并为对比,GO接口类描述只需要一个操作.举例说明,GO使用中一个最通用的接口io.Reader.这个接口提供一个简单的方法宣告类可被其它标准库理解的方式读取数据. 123type Reader interface &#123;Read(p []byte) (n int, err error)&#125; 写一个类实现io.Reader接口,只需要实现一个read方法,接收一个byte数据片,返回一个整数或错误.这与其它面向对象的编程语言使用的接口系统有着根本的区别.GO接口更小更直接.在实践中,这对重用代码与组合大有好处.你可以实现一个io.Reader在近乎任何有数据可用的类上,然后发送到任何知道如何从io.Reader读取的go函数.GO中所有的网络库都使用io.Reader接口构建,因为它允许不同的网络操作需求与应用程序分离.使得接口有趣,优雅,灵活.同一个io.Reader能够对文件,缓存,套接字及其它数据源简单的操作.使用单一接口允许操作数据高效地,不分数据源. 1.1.4 内存管理不当的内存管理会使用应用崩溃和内存泄漏.GO拥有一个现代垃圾回收机制.在其它系统语言中,如C,C++,你需要使用前分配一片内存,使用完后释放它.如果正确的执行失败,程序会崩溃或内存泄漏.一片内存不再需要时总是很难追踪.线程或重并行架构使得难上加难.如果你脑中有垃圾回收的想法去写代码,GO的垃圾回收只增加了一点的程序执行时间消耗,但显著减少了开发工作量.go去掉了编程的单调,把bean留给了会计师. 1.2 你好,GO12345package mainimport &quot;fmt&quot;func main()&#123; fmt.Println(&quot;Hello Tianfei!)&#125;]]></content>
      <categories>
        <category>go in action</category>
      </categories>
      <tags>
        <tag>golang</tag>
        <tag>go</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[yum列出指定源的包含的所有包]]></title>
    <url>%2F2018%2F12%2F23%2Fyum%E5%88%97%E5%87%BA%E6%8C%87%E5%AE%9A%E6%BA%90%E7%9A%84%E5%8C%85%E5%90%AB%E7%9A%84%E6%89%80%E6%9C%89%E5%8C%85%2F</url>
    <content type="text"><![CDATA[列出指定源所包含的所有包列表 123456789101112131415[root@tianfeicentos ~]# yum repository-packages kubernetes listLoaded plugins: fastestmirrorLoading mirror speeds from cached hostfile * base: mirrors.cn99.com * epel: ftp.cuhk.edu.hk * extras: mirrors.163.com * updates: mirrors.163.comInstalled Packageskubectl.x86_64 1.13.1-0 @kuberneteskubelet.x86_64 1.13.1-0 @kuberneteskubernetes-cni.x86_64 0.6.0-0 @kubernetesAvailable Packagescri-tools.x86_64 1.12.0-0 kuberneteskubeadm.x86_64 1.13.1-0 kubernetesrkt.x86_64 1.27.0-1 kubernetes]]></content>
      <tags>
        <tag>yum</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[pts,tty的区别]]></title>
    <url>%2F2018%2F12%2F19%2Ftty%20pts%20%E5%8C%BA%E5%88%AB%2F</url>
    <content type="text"><![CDATA[12A tty is a regular terminal device (the console on your server, for example).A pts is a psuedo terminal slave (an xterm or an ssh connection). 转自:”https://unix.stackexchange.com/questions/21280/difference-between-pts-and-tty&quot;]]></content>
      <categories>
        <category>Redhat</category>
      </categories>
      <tags>
        <tag>redhat</tag>
        <tag>centos</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[FreeRADIUS Beginner's Guide]]></title>
    <url>%2F2018%2F12%2F14%2FFreeRADIUS%20Beginner's%20Guide%2F</url>
    <content type="text"><![CDATA[4. Authentication认证过程: data link layer -&gt; success -&gt; network layer 认证协议: userpassword: PAP (password Authentication protocal)密码认证协议(p2p) client -&gt; (密码明文) -&gt; NAS -&gt; (加密密码) -&gt; RADIUS SERVER CHAP (challenge-handshake authentication protocal)询问交互认证协议 NAS -&gt; 重复发送随机间隔的 challenge -&gt; user -&gt; hash identifiter &amp; 明文密码 -&gt; NAS -&gt; 加密密码 -&gt; radius server MS-CHAP 微软chap协议,增强了功能,如用户修改密码,错误消息等. chapv1 &amp; chapv2 user -&gt; 包含微软特殊字段NT-Response + 加密密码 -&gt; NAS EAP协议使用MS-CHAP 12345678910111213141516171819202122232425[root@localhost raddb]# vi /etc/raddb/users添加以下2行&quot;tianfei&quot; Cleartext-Password := &quot;passgo&quot; Reply-Message = &quot;Hello, %&#123;User-Name&#125;&quot;[root@localhost raddb]# radtest tianfei passgo 127.0.0.1 100 testing123Sent Access-Request Id 170 from 0.0.0.0:44098 to 127.0.0.1:1812 length 77 User-Name = &quot;tianfei&quot; User-Password = &quot;passgo&quot; NAS-IP-Address = 127.0.0.1 NAS-Port = 100 Message-Authenticator = 0x00 Cleartext-Password = &quot;passgo&quot;Received Access-Reject Id 170 from 127.0.0.1:1812 to 0.0.0.0:0 length 20(0) -: Expected Access-Accept got Access-Reject[root@localhost raddb]# radtest tianfei passgo 127.0.0.1 100 testing123Sent Access-Request Id 155 from 0.0.0.0:44387 to 127.0.0.1:1812 length 77 User-Name = &quot;tianfei&quot; User-Password = &quot;passgo&quot; NAS-IP-Address = 127.0.0.1 NAS-Port = 100 Message-Authenticator = 0x00 Cleartext-Password = &quot;passgo&quot;Received Access-Accept Id 155 from 127.0.0.1:1812 to 0.0.0.0:0 length 36 Reply-Message = &quot;Hello, tianfei&quot; 服务器日志输出 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374Ready to process requests(0) Received Access-Request Id 155 from 127.0.0.1:44387 to 127.0.0.1:1812 length 77(0) User-Name = &quot;tianfei&quot;(0) User-Password = &quot;passgo&quot;(0) NAS-IP-Address = 127.0.0.1(0) NAS-Port = 100(0) Message-Authenticator = 0x5328ee7e1eaa61d3555baa241acb7582(0) # Executing section authorize from file /etc/raddb/sites-enabled/default(0) authorize &#123;(0) policy filter_username &#123;(0) if (&amp;User-Name) &#123;(0) if (&amp;User-Name) -&gt; TRUE(0) if (&amp;User-Name) &#123;(0) if (&amp;User-Name =~ / /) &#123;(0) if (&amp;User-Name =~ / /) -&gt; FALSE(0) if (&amp;User-Name =~ /@[^@]*@/ ) &#123;(0) if (&amp;User-Name =~ /@[^@]*@/ ) -&gt; FALSE(0) if (&amp;User-Name =~ /\.\./ ) &#123;(0) if (&amp;User-Name =~ /\.\./ ) -&gt; FALSE(0) if ((&amp;User-Name =~ /@/) &amp;&amp; (&amp;User-Name !~ /@(.+)\.(.+)$/)) &#123;(0) if ((&amp;User-Name =~ /@/) &amp;&amp; (&amp;User-Name !~ /@(.+)\.(.+)$/)) -&gt; FALSE(0) if (&amp;User-Name =~ /\.$/) &#123;(0) if (&amp;User-Name =~ /\.$/) -&gt; FALSE(0) if (&amp;User-Name =~ /@\./) &#123;(0) if (&amp;User-Name =~ /@\./) -&gt; FALSE(0) &#125; # if (&amp;User-Name) = notfound(0) &#125; # policy filter_username = notfound(0) [preprocess] = ok(0) [chap] = noop(0) [mschap] = noop(0) [digest] = noop(0) suffix: Checking for suffix after &quot;@&quot;(0) suffix: No &apos;@&apos; in User-Name = &quot;tianfei&quot;, looking up realm NULL(0) suffix: No such realm &quot;NULL&quot;(0) [suffix] = noop(0) eap: No EAP-Message, not doing EAP(0) [eap] = noop(0) files: users: Matched entry tianfei at line 1(0) files: EXPAND Hello, %&#123;User-Name&#125;(0) files: --&gt; Hello, tianfei(0) [files] = ok(0) [expiration] = noop(0) [logintime] = noop(0) [pap] = updated(0) &#125; # authorize = updated(0) Found Auth-Type = PAP(0) # Executing group from file /etc/raddb/sites-enabled/default(0) Auth-Type PAP &#123;(0) pap: Login attempt with password(0) pap: Comparing with &quot;known good&quot; Cleartext-Password(0) pap: User authenticated successfully(0) [pap] = ok(0) &#125; # Auth-Type PAP = ok(0) # Executing section post-auth from file /etc/raddb/sites-enabled/default(0) post-auth &#123;(0) update &#123;(0) No attributes updated(0) &#125; # update = noop(0) [exec] = noop(0) policy remove_reply_message_if_eap &#123;(0) if (&amp;reply:EAP-Message &amp;&amp; &amp;reply:Reply-Message) &#123;(0) if (&amp;reply:EAP-Message &amp;&amp; &amp;reply:Reply-Message) -&gt; FALSE(0) else &#123;(0) [noop] = noop(0) &#125; # else = noop(0) &#125; # policy remove_reply_message_if_eap = noop(0) &#125; # post-auth = noop(0) Sent Access-Accept Id 155 from 127.0.0.1:1812 to 127.0.0.1:44387 length 0(0) Reply-Message = &quot;Hello, tianfei&quot;(0) Finished requestWaking up in 4.9 seconds.(0) Cleaning up request packet ID 155 with timestamp +6Ready to process requests]]></content>
      <tags>
        <tag>radius</tag>
        <tag>AAA</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ovirt 运维管理]]></title>
    <url>%2F2018%2F12%2F14%2Fovirt%E8%BF%90%E7%BB%B4%E7%AE%A1%E7%90%86%2F</url>
    <content type="text"><![CDATA[用户管理internal域用户管理设置及重置用户密码 –password-valid-to选项必须指定密码无期时间,否则过期时间设置为当前时间,时间格式为 yyyy-MM-dd HH:mm:ssX 默认密码长度不小于6位 用户之前3次使用的密码不能再次设置 12345[root@ovirt-engine ~]# /usr/bin/ovirt-aaa-jdbc-tool user password-reset vmuser --password-valid-to=&quot;2019-01-01 12:00:00+0800&quot;Password:Reenter password:updating user vmuser...user updated successfully]]></content>
      <categories>
        <category>Ovirt</category>
      </categories>
      <tags>
        <tag>ovirt</tag>
        <tag>kvm</tag>
        <tag>RHV</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ovirt 技术参考]]></title>
    <url>%2F2018%2F12%2F12%2Fovirt%E6%8A%80%E6%9C%AF%E5%8F%82%E8%80%83%2F</url>
    <content type="text"><![CDATA[chapter1.技术架构说明1.1 Virtualization Manager(Engine)集中化的虚拟环境管理平台 1.2 Hosts KVM(kernel-based virtual machine) 使用 Intel VT or AMD-V hardware extensions的全虚拟化内核模块 kvm运行在kernel space QEMU() 全平台模拟器 QEMU运行在user space VDSM(Host Agent) 初始化虚拟环境 host间通信 监控主机资源(CPU,MEM,NET) 虚拟机创建,统计,日志收集 接收来自ovirt engine的指令,监听端口:54321 VDSM-REG 负责向engine注册host 提供自身信息及host信息 libvirt 管理虚拟机 engine(start,stop,reboot指令) -&gt; vdsm -&gt; libvirt SPM(storage pool manager) 辅助维护存储metadata 创建,删除,维护虚拟磁盘,创建映像,模板. 数据中心的所有主机都必需能够访问存储,任何主机都有可能被指定为SPM,但一个数据中心只有一个SPM SPM host不可达时,engine重新指定spm Guest Operating System 虚拟机操作系统不受ovirt环境影响及修改 Guest Agent安装在Guest OS上可以更高效率的运行. 1.3 ovirt支撑组件 Red Hat JBoss Enterprise Application Platform java程序服务器 报表及历史数据 数据仓库收集监控数据(host,vms,storage) 两个PG数据库 engine ovirt_engine_history ovirt-engine-dwhd 历史收集服务 访问目录服务 内部账号: admin Active Directory Identity Management (IdM) OpenLDAP Red Hat Directory Server 9 1.4 存储逻辑存储池(域) 存储域是共享资源,数据中心的所有主机都必需能够访问存储 data(必备惟一,不能夸数据中心) vdisk image snapshots templates export(可选) 主要用来在不同data center之间迁移数据,同一时间只能附在一个data center ISO(可选) ISO域存储操作系统ISO文件,可以在多个data center之间共享,可附加多个data center. 1.5 网络网络架构不仅连接网络,还可以分隔网络. 网络基础要实现硬件与ovirt逻辑组件之间的连接 Networking Infrastructure Layer host NIC 连接物理网络 VNIC 使用基于 NIC 连接 vms bonds 多个NIC为1个接口 bridge 在网络中进行包转发与包交换,是虚拟网络的基础 Logical Networks 隔离网络流量 虚拟机网络 bridge转发交换,需要host上创建bridge虚拟设备 非虚拟机网络 直接作用于NIC,不在host上创建bridge 可选的网络 必选的网络 迁移网络是单独的,不影响(ovirtmgmt) 逻辑网络在不同的层次有不同的意义 Data Center Layer 逻辑网络是在数据中心层定义的. Cluster Layer 逻辑网络应用在集群上. 在默认的情况下，每个集群都会连接到管理网络中 “必需的”逻辑网络被添加到集群中时，它需要被添加到集群中的所有主机上 “可选的”逻辑网络可以根据需要被添加到所需的主机上。 Host Layer 虚拟机逻辑网络 host bridge -&gt; NIC 非虚拟机逻辑网络 -&gt; NIC 管理网络 ovirtmgmt bridge -&gt; NIC 添加到集群中的required逻辑网络必需关联到host上相当的网卡上才能使用. Virtual Machine Layer 同host,VNIC必需关联到逻辑网络才能使用上面的资源. 1.6 数据中心组件 存储 一个数据中心,一个独享data域 export在数据中心共享数据,但同时只能附到一个数据中心 ISO域是所有数据中心共享的. 网络(创建于data center,应用于cluster) ip address VLAN tags STP 集群 host pool 一致的硬件 VM在cluster内的host迁移 chapter2.存储chapter3.网络3.1 网络架构 基础网络 cluster 网络 host 网络3.2 介绍基础网络 连通vm,host,LAN A Network Interface Controller (NIC) A Bridge 逻辑网络通过bridge实现 IP分配在虚拟的bridge接口上，而不是实际的NIC 虚拟机的VNIC可以与bridge的接口地址不同子网;相同子网的话虚拟机可以访问host上的网络资。 A Virtual NIC 基于template或snapshot批量创建虚拟机,系统会自动按顺序配置vnic的MAC地址. 增强安全,高可用,性能 A Bond (fault tolerance) 多NIC聚合 bond mode bridge and bridgeless 1 Mode 1 (active-backup policy) 2 Mode 2 (XOR policy) 3 模式 3（broadcast policy） 4 模式 4（IEEE 802.3ad policy） bridgeless 0 Mode 0 (round-robin policy) 5 模式 5（adaptive transmit load balancing policy） 6 模式 6（adaptive load balancing policy） A Virtual LAN (VLAN)(数字) 作用在packets上 在switch层隔离网络流量3.3 网络标签 标签支持大小写字母、下划线和分号,没有长度限制 简化逻辑网络管理 网络标签与主机关联 自动将逻辑网络关联到具有相同标签的hosts硬件网卡上 自动装hosts NIC关联到具有相同标签的逻辑网络 移除或修改标签会作相应的关联删除或修改 网络标签与集群关联 自动将逻辑网络关联到具有相同标签的cluster中的hosts硬件网卡上 删除cluster中网络标签,自动从cluster中hosts硬件网卡上删除逻辑网络 网络标签和有用户角色的逻辑网络 当一个有网络标识的逻辑网络被设为“显示网络”或“迁移网络”时，它会在主机物理网络接口中被配置为通过 DHCP 获得一个 IP 地址。 当为一个角色网络（如“一个迁移网络”或“一个显示网络”）设置网络标签时，会在所有主机上产生大量部署这个网络的操作。这些大量的网络添加操作是通过使用 DHCP 实现的，而不是通过输入静态地址实现的。这是因为，和 DHCP 相比，输入大量静态地址不具有“可扩展性”. 3.5 集群网络 集群内的hosts访问相同的存储域,逻辑网络 VM逻辑网络必须在所有hosts上配置 其它逻辑网络只需在需要的hosts上配置 3.6 逻辑网络 只能在主机处于维护模式时才可以部署逻辑网络 逻辑网络的类型包括： (vm)用来处理虚拟机网络流量的逻辑网络 在host创建相应的bridge, 并添加绑定的物理网卡 VM网卡到bridge中,bridge中的网卡可互相通信 为虚拟机逻辑网络所创建的网桥设备需要和主机上的一个网络接口相关联。如果和网桥相关联的主机网络接口已经被其它网络所使用，则新加入的网络接口将同样可以共享那些已经连接到主机网络接口中的网络。当虚拟机被创建并被添加到一个特定的逻辑网中时，它们的虚拟网卡会被添加到那个逻辑网所在的网桥中。这样，虚拟机就可以和连接到相同网桥中的其它设备进行网络交流。 (other)不处理虚拟机网络流量的逻辑网络， 直接作用在host物理网卡上 (optional)可选的逻辑网络， (required)必需的逻辑网络 定义在数据中心,作用在主机 3.7 必需的网络,可选的网络,虚拟机网络 必需的网络在所有hosts上配置,host的必需网络不可用时会迁移所有虚拟机到其它host 非必需网络不可用不会迁移虚拟机 虚拟机网络（VM network）是那些只处理虚拟机网络流量的逻辑网络 3.8 端口镜像端口镜像（port mirroring）会把指定逻辑网络和主机上的第 3 层网络流量复制到一个虚拟机的虚拟网络接口上。这样，通过这个虚拟机就可以进行网络纠错、网络优化、网络入侵检测以及对在同一个主机和逻辑网络中运行的虚拟机进行监控。 3.9 主机网络配置主机上包括的常见网络配置类型： 网桥和网卡配置。 网桥、VLAN（虚拟局域网）和网卡配置。 网桥、网络绑定和 VLAN 配置。 多网桥、多 VLAN 和网卡配置。 chapter4.电源管理chapter5.负载均衡,调度,迁移chapter6.活动目录服务chapter7.模板与池chapter8.Virtual Machine快照chapter9.硬件设备与驱动]]></content>
      <categories>
        <category>Ovirt</category>
      </categories>
      <tags>
        <tag>ovirt</tag>
        <tag>kvm</tag>
        <tag>RHV</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ovirt 规划与需求]]></title>
    <url>%2F2018%2F12%2F11%2Fovirt%E8%A7%84%E5%88%92%E4%B8%8E%E9%9C%80%E6%B1%82%2F</url>
    <content type="text"><![CDATA[使用哪种架构Architecture1.虚拟化架构 standalone管理端部署 管理端部署在一台物理机上(也可部署在特殊的虚拟机) 管理机实现高可用要使用第三方实现 Self-Hosted Engine部署 管理端使用cokpit部署或cli的方式部署在虚拟机中 不需要扩展HA,实现自管理虚拟机engine高可用 2.需求2.1.Manager需求硬件需求资源|最小|推荐cpu|2|多核memory|4G|16GDisk|25G|50Gnet interface|1Gbps|1Gbps 浏览器需求 推荐firefox,linux系统全功能支持 IE,windows部分功能受限 客户端需求类型|客户端VM remote console|virt-viewer|SPICE protocol|QXL graphical drivervnc|vnc viewer 操作系统需求RHEL 7或CENTOS 7或ovirt官方node 2.2.hosts需求 类型|特性CPU|Intel® 64 or AMD64 CPU extensions,AMD-V™ or Intel VT®,No eXecute flag (NX)memory|2G-2Tdisk|Minimum Total - 45 GBnet interface|1Gbps*nvGPU|GPU 123456789101112131415161718192021支持的CPU类型AMD Opteron G1 (deprecated) Opteron G2 (deprecated) Opteron G3 (deprecated) Opteron G4 Opteron G5Intel Conroe (deprecated) Penryn (deprecated) Nehalem Westmere Sandybridge Haswell Haswell-noTSX Broadwell Broadwell-noTSX Skylake (client) Skylake (server)IBM POWER8 使用以下命令检测 1# grep -E &apos;svm|vmx&apos; /proc/cpuinfo | grep nx 2.3. 网络需求DNS系统DNS系统要在ovirt环境外独立安装,保障可用,否则对系统影响很大 逻辑网络 逻辑网络可以使用物理设备网卡或虚拟设备bond网卡 Bonding可以提升性能或可靠性,bond默认是4,Bonding modes 1, 2, 3, and 4 support both virtual machine and non-virtual machine network types. Modes 0, 5, and 6 only support non-virtual machine networks. 一块网卡可以承载多个逻辑网络,可以使用VLAN tag隔离网络流量,这需要交换机支持. 逻辑网络附加到HOST的数量受网卡数量及VLAN最大数量4096的限制 单次操作可以附加到一台主机的网络最大50个. 集群的网络数量受限主机,因为都是使用相同的网络. 数据中心的网络数量受限于集群数量及每个集群的网络数量 修改ovirtmgmt网络要非常小心,不当的操作有可能使用整个系统停止. 活动目录服务不要使用外部用户作为ovirt环境的管理用户. internal 默认创建admin用户初始化管理及排错. ovirt-aaa-jdbc-tool创建新的内部用户 openldap active directory Identity Management (IdM - based on IPA) Red Hat Directory Server 9 (RHDS 9 - based on 389DS) IBM Security (Tivoli) Directory Server Firewallengine-setup自动配置防火墙iptables装被覆盖,Firewalld不影响已经存在的规则 存储需求 Ovirt目前支持最大400台hosts规模 至少一个data存储域,推荐创建ISO域 存储域可以是块设备(只支持egacy (512b block) ),或文件系统 支持NFS,iSCSI,Fibre,gluster,POSIX-Compliant FS,Local Storage 基础设施需求在性能不是瓶颈的情况下,将组件与管理机安装在一起维护比较简单. standalone部署过程中会提示是否安装在管理机上. self-hosted engine下需要先进行安装后再部署engine. data warehouse manager database web socket proxy 下面的三个系统只能独立于ovirt环境安装 DNS系统 storage存储 identity Management 3.建议常规建议 定期备份环境 避免将ovirt环境要信赖的服务部署在自身环境中 查看系统entropy不要小于200,否则有可能造成系统cause 可以使用PXE, Kickstart, Satellite, CloudForms, Ansible或混合使用以上工具自动化安装宿主机和虚拟机,但hosted-engine不支持 https://access.redhat.com/documentation/en-us/red_hat_virtualization/4.2/html/planning_and_prerequisites_guide/recommendations 部署NTP服务同步所有服务器及虚拟机时间12[root@ovirt00 ~]# cat /proc/sys/kernel/random/entropy_avail3496 安全建议 不要禁用默认开启的安全特性(HTTPS, SELinux, and the firewall) 创建隔离的admin账号 限制访问主机,特别是root账号 不要创建不信任的用户 除了必须的包不要在系统上安装其它服务 主机建议 相同集群中使用相同规格的host 没有特殊需求不要混合部署RHEL,CENTOS,ovirt官方node系统 部署fencing设备,排除故障机器 交换机高可用 网络建议 bonding网卡 使用VLAN 如果可用,提升MTU,例如9000,提高吞吐,降低CPU负载 1G网络用于管理,10G,40G网络用于虚拟机或存储 为存储使用单独的网卡,去掉vm network,VLAN直接使用物理网卡. 如果部署了openstack,可以整合neutron添加Open vSwitch 能力. 配置网络的实施建议 手工配置主机网络然后添加到ovirt环境 推荐使用cockpit配置网络,也可以使用nmtui,nmcli 使用administration portol 删除或添加主机,删除网络 命名规范: VLAN devices: VLAN_NAME_TYPE_RAW_PLUS_VID_NO_PAD VLAN interfaces: physical_device.VLAN_ID (for example, eth0.23, eth1.128, enp3s0.50) Bond interfaces: bondnumber (for example, bond0, bond1) VLANs on bond interfaces: bondnumber.VLAN_ID (for example, bond0.50, bond1.128) 使用bonding 123456789101112Configure a VLAN on a physical NIC as in the following example (although nmcli is used, you can use any tool):# nmcli connection add type vlan con-name vlan50 ifname eth0.50 dev eth0 id 50# nmcli con mod vlan50 +ipv4.dns 8.8.8.8 +ipv4.addresses 123.123.0.1/24 +ivp4.gateway 123.123.0.254Configure a VLAN on a bond as in the following example (although nmcli is used, you can use any tool):# nmcli connection add type bond con-name bond0 ifname bond0 bond.options &quot;mode=active-backup,miimon=100&quot; ipv4.method disabled ipv6.method ignore# nmcli connection add type ethernet con-name eth0 ifname eth0 master bond0 slave-type bond# nmcli connection add type ethernet con-name eth1 ifname eth1 master bond0 slave-type bond# nmcli connection add type vlan con-name vlan50 ifname bond0.50 dev bond0 id 50# nmcli con mod vlan50 +ipv4.dns 8.8.8.8 +ipv4.addresses 123.123.0.1/24 +ivp4.gateway 123.123.0.254 不要禁用firewalld self-engine建议 为hosted-engine创建单独的data center,有助于安全,备份,性能,可用. 专为hosted-engine创建的engine巻不要用于其它虚拟机 分离management,storage,migration网络 建议每个集群中不超过7个host,带来更好的弹性 CPU使用相同的架构 有足够的内存空间启动或迁移engine]]></content>
      <categories>
        <category>Ovirt</category>
      </categories>
      <tags>
        <tag>ovirt</tag>
        <tag>kvm</tag>
        <tag>RHV</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ovirt 架构介绍]]></title>
    <url>%2F2018%2F12%2F10%2Fovirt%E6%9E%B6%E6%9E%84%2F</url>
    <content type="text"><![CDATA[关于Ovirt虚拟化1.虚拟化架构 standalone管理端部署 管理端部署在物理机上 管理机实现高可用要使用第三方实现 Self-Hosted Engine部署 管理端使用cokpit部署或cli的方式部署在虚拟机中 不需要扩展HA,实现自管理虚拟机engine高可用 2.组件及术语术语|解释data center|包含所有物理机,虚拟机上的逻辑资源的最高级别容器.包含cluster,vm,storage domain,network等cluster|物理机hosts的集合池,上面部署VMs,共享相同的网络及存储,虚拟机可以在host之间迁移.host|部署VM的物理宿主机self-hosted engine node|self-hosted Engine部署的物理宿主机storage domain|存储域,逻辑概念,存储虚拟磁盘或iso镜像virtual machines|运行操作系统的虚拟机.多个虚拟机可以组成pool.Template|预定义的虚拟机配置.方便快速创建大量相同配置的虚拟机.vm pool|多个相同标记的虚拟机组成的池.snapshot|保存虚拟机一个时间点的状态,可以恢复到那个点.logical networks| 物理网络的逻辑描述,逻辑网络分组不同的manager,hosts,storages,vms流量events and monitors|事件提醒,方便管理员管理vdsm|host agent服务,与管理端通信.storage pool manager(spm)|一个数据中心只有一个spm角色,负责存储metadata维护.Host Storage Manager(HSM)|Any non-SPM host in the data center that can be used for data operations, such as moving a disk between storage domains. This prevents a bottleneck at the SPM host, which should be used for shorter metadata operations.Remote viewer|连接虚拟机的可视化接口High availability|虚拟机中断时使用自动重启,维护2份资源,在失败时直接替换.HA service|包括ovirt-ha-agent,ovirt-ha-broker,管理hosted-engine vm的高可用. Ovirt虚拟化组件1. Virtual manager web 化的图形管理页面 restful api管理接口 2. hosts两种类型的机器: 装有REDHAT 7或CENTOS 7的物理机 ovirt官方提供的基于以上系统精减的node节点 3. storage至少种类型的基本存储域: ISO domain 存储系统安装镜像及驱动等 data domain 存储VM磁盘镜像 export domain 临时迁移数据用的,现在已经被import data domain 代替 4. data warehouseovirt_engine_history 历史信息数据库,为报表等服务. 5. networkOvirt通过逻辑网络切分隔离流量,默认只有一个虚拟网络,可以添加多个分配到不同的网卡及bond不同的网卡提升性能 ovirtmgmt|Managementvmnet|General virtual machine trafficstoragenet|Storage-related traffic (such as NFS or iSCSI)mvmt|Virtual machine migration trafficvmdt|Virtual machine display trafficglusternet|Gluster storage traffic 安装Ovirt 访问Ovirt 支持读写的接口 Administration Portal 浏览器图形界面,管理资源环境 VM Portal 浏览器图形界面,受限用户管理虚拟机资源 Cockpit 主机管理配置 self-hosted Engine部署 Rest api 任何支持HTTP action的语言,通过API的方式查询或修改虚拟环境 Software Development Kit (SDK) Python Java Ruby Ansible 自动化程序 Self-Hosted Engine Command Line Utility 执行管理任务 管理虚拟环境 VDSM Hooks 由 Administration Portal 触发修改虚拟机 Command Line Shell(ovirt-engine-cli)(未来将放弃) 支持只读的接口 ovirt_engine_history Libvirt on Hosts virsh -r 不被支持的接口 vdsm-client 直接修改(engine)数据库]]></content>
      <categories>
        <category>Ovirt</category>
      </categories>
      <tags>
        <tag>ovirt</tag>
        <tag>kvm</tag>
        <tag>RHV</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[安装telnet服务]]></title>
    <url>%2F2018%2F10%2F12%2Ftelnet%E6%9C%8D%E5%8A%A1%E5%AE%89%E8%A3%85%2F</url>
    <content type="text"><![CDATA[#环境 os: OpenSUSE Tumbleweed pc: Thinkpad T460s #描述 远程登陆方式主要有三种：1 明文文本模式:telnet,rsh等，不安全，现在很少使用，但在一些特殊场所还会有所使用。2 加密文本模式:ssh3 图形模式：xdmcp,vnc,rdp等 1.查询系统中是否已经安装了telnet服务1[root@ovirt ~]# rpm -qa |grep telnet 2.安装telnet-server服务端及telnet客户端包1[root@ovirt ~]# yum install telnet-server talnet 3.telnet服务是由xinetd守护进程维护的，需要启动xinetd服务1[root@ovirt ~]# yum install xinetd 4.rhel7版本使用systemd代替init.d维护启动进程，7版本以下使用init.d管理1[root@ovirt ~]# systemctl start xinetd 7版本以下修改/etc/xinetd.d/telnet 1234567891011121314[root@hostovirt ~]# vi /etc/xinetd.d/telnet # default: on# description: The telnet server serves telnet sessions; it uses \# unencrypted username/password pairs for authentication.service telnet&#123; flags = REUSE socket_type = stream wait = no user = root server = /usr/sbin/in.telnetd log_on_failure += USERID disable = no # 这个配置项由yes修改为no[root@ovirt ~]# service xinetd start 5.启动telnet-server,7版本使用systemd,7版本以下使用init.d启动xinetd后会自动启动telnet1[root@ovirt etc]# systemctl start telnet.socket 6.防火墙开放端口12[root@ovirt etc]# firewall-cmd --zone=public --add-port=23/tcpsuccess iptables操作方法： 123[root@hostovirt ~]# iptables -I INPUT -p tcp --dport 23 -j ACCEPT[root@ovirt etc]# firewall-cmd --zone=public --list-ports23/tcp 7.使用nmap查看端口状态,STATE为open状态123456789haotianfei@tianfei-opensuse:~&gt; nmap 192.168.56.101 -p 23Starting Nmap 7.70 ( https://nmap.org ) at 2018-10-11 14:41 CSTNmap scan report for ovirt.wasu (192.168.56.101)Host is up (0.00037s latency).PORT STATE SERVICE23/tcp filtered telnetNmap done: 1 IP address (1 host up) scanned in 0.05 seconds 123456789haotianfei@tianfei-opensuse:~&gt; nmap 192.168.56.101 -p 23Starting Nmap 7.70 ( https://nmap.org ) at 2018-10-11 14:43 CSTNmap scan report for ovirt.wasu (192.168.56.101)Host is up (0.00032s latency).PORT STATE SERVICE23/tcp open telnetNmap done: 1 IP address (1 host up) scanned in 0.05 seconds 8.出于安全原因，默认telnet终端是不能登陆的，暂时移除/etc/securetty123456789101112131415161718haotianfei@tianfei-opensuse:~&gt; telnet -l root 192.168.56.101Trying 192.168.56.101...Connected to 192.168.56.101.Escape character is &apos;^]&apos;.Password: Login incorrectovirt login: [root@ovirt etc]# mv /etc/securetty&#123;,.bak&#125;haotianfei@tianfei-opensuse:~&gt; telnet -l root 192.168.56.101 23Trying 192.168.56.101...Connected to 192.168.56.101.Escape character is &apos;^]&apos;.Password: Last failed login: Thu Oct 11 02:44:46 EDT 2018 from ::ffff:192.168.56.1 on pts/1There were 3 failed login attempts since the last successful login.Last login: Thu Oct 11 02:35:13 from ::ffff:192.168.56.1[root@ovirt ~]#]]></content>
      <tags>
        <tag>telnet</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Homebrew,MacOS下类yum,zypper,apt的包管理工具]]></title>
    <url>%2F2018%2F10%2F01%2FHomebrew%2CMacOS%E4%B8%8B%E7%B1%BByum%2Czypper%2Capt%E7%9A%84%E5%8C%85%E7%AE%A1%E7%90%86%E5%B7%A5%E5%85%B7%2F</url>
    <content type="text"><![CDATA[环境 os: macOS Mojave pc: Apple macbook 13’ pro 2015 描述Home-brew 是macos下类似rpm系的yum,zypper,dnf等的包管理系统。官方定义为：macOS 缺失的软件包的管理器。 安装安装方式很简单，直接一条脚本命令完成。其间会自动下载一些所需要的组件。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165192:~ tf$ /usr/bin/ruby -e &quot;$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/master/install)&quot;==&gt; This script will install:/usr/local/bin/brew/usr/local/share/doc/homebrew/usr/local/share/man/man1/brew.1/usr/local/share/zsh/site-functions/_brew/usr/local/etc/bash_completion.d/brew/usr/local/Homebrew==&gt; The Xcode Command Line Tools will be installed.Press RETURN to continue or any other key to abort==&gt; Searching online for the Command Line Tools==&gt; /usr/bin/sudo /usr/bin/touch /tmp/.com.apple.dt.CommandLineTools.installondemand.in-progressPassword:==&gt; Installing Command Line Tools (macOS Mojave version 10.14) for Xcode-10.0==&gt; /usr/bin/sudo /usr/sbin/softwareupdate -i Command\ Line\ Tools\ (macOS\ Mojave\ version\ 10.14)\ for\ Xcode-10.0Software Update ToolDownloading Command Line Tools (macOS Mojave version 10.14) for XcodeDownloaded Command Line Tools (macOS Mojave version 10.14) for XcodeInstalling Command Line Tools (macOS Mojave version 10.14) for XcodeDone with Command Line Tools (macOS Mojave version 10.14) for XcodeDone.==&gt; /usr/bin/sudo /bin/rm -f /tmp/.com.apple.dt.CommandLineTools.installondemand.in-progress==&gt; /usr/bin/sudo /usr/bin/xcode-select --switch /Library/Developer/CommandLineTools==&gt; Downloading and installing Homebrew...remote: Enumerating objects: 30, done.remote: Counting objects: 100% (30/30), done.remote: Compressing objects: 100% (27/27), done.remote: Total 111012 (delta 11), reused 11 (delta 3), pack-reused 110982Receiving objects: 100% (111012/111012), 25.26 MiB | 884.00 KiB/s, done.Resolving deltas: 100% (81258/81258), done.From https://github.com/Homebrew/brew * [new branch] master -&gt; origin/master * [new tag] 0.1 -&gt; 0.1 * [new tag] 0.2 -&gt; 0.2 * [new tag] 0.3 -&gt; 0.3 * [new tag] 0.4 -&gt; 0.4 * [new tag] 0.5 -&gt; 0.5 * [new tag] 0.6 -&gt; 0.6 * [new tag] 0.7 -&gt; 0.7 * [new tag] 0.7.1 -&gt; 0.7.1 * [new tag] 0.8 -&gt; 0.8 * [new tag] 0.8.1 -&gt; 0.8.1 * [new tag] 0.9 -&gt; 0.9 * [new tag] 0.9.1 -&gt; 0.9.1 * [new tag] 0.9.2 -&gt; 0.9.2 * [new tag] 0.9.3 -&gt; 0.9.3 * [new tag] 0.9.4 -&gt; 0.9.4 * [new tag] 0.9.5 -&gt; 0.9.5 * [new tag] 0.9.8 -&gt; 0.9.8 * [new tag] 0.9.9 -&gt; 0.9.9 * [new tag] 1.0.0 -&gt; 1.0.0 * [new tag] 1.0.1 -&gt; 1.0.1 * [new tag] 1.0.2 -&gt; 1.0.2 * [new tag] 1.0.3 -&gt; 1.0.3 * [new tag] 1.0.4 -&gt; 1.0.4 * [new tag] 1.0.5 -&gt; 1.0.5 * [new tag] 1.0.6 -&gt; 1.0.6 * [new tag] 1.0.7 -&gt; 1.0.7 * [new tag] 1.0.8 -&gt; 1.0.8 * [new tag] 1.0.9 -&gt; 1.0.9 * [new tag] 1.1.0 -&gt; 1.1.0 * [new tag] 1.1.1 -&gt; 1.1.1 * [new tag] 1.1.10 -&gt; 1.1.10 * [new tag] 1.1.11 -&gt; 1.1.11 * [new tag] 1.1.12 -&gt; 1.1.12 * [new tag] 1.1.13 -&gt; 1.1.13 * [new tag] 1.1.2 -&gt; 1.1.2 * [new tag] 1.1.3 -&gt; 1.1.3 * [new tag] 1.1.4 -&gt; 1.1.4 * [new tag] 1.1.5 -&gt; 1.1.5 * [new tag] 1.1.6 -&gt; 1.1.6 * [new tag] 1.1.7 -&gt; 1.1.7 * [new tag] 1.1.8 -&gt; 1.1.8 * [new tag] 1.1.9 -&gt; 1.1.9 * [new tag] 1.2.0 -&gt; 1.2.0 * [new tag] 1.2.1 -&gt; 1.2.1 * [new tag] 1.2.2 -&gt; 1.2.2 * [new tag] 1.2.3 -&gt; 1.2.3 * [new tag] 1.2.4 -&gt; 1.2.4 * [new tag] 1.2.5 -&gt; 1.2.5 * [new tag] 1.2.6 -&gt; 1.2.6 * [new tag] 1.3.0 -&gt; 1.3.0 * [new tag] 1.3.1 -&gt; 1.3.1 * [new tag] 1.3.2 -&gt; 1.3.2 * [new tag] 1.3.3 -&gt; 1.3.3 * [new tag] 1.3.4 -&gt; 1.3.4 * [new tag] 1.3.5 -&gt; 1.3.5 * [new tag] 1.3.6 -&gt; 1.3.6 * [new tag] 1.3.7 -&gt; 1.3.7 * [new tag] 1.3.8 -&gt; 1.3.8 * [new tag] 1.3.9 -&gt; 1.3.9 * [new tag] 1.4.0 -&gt; 1.4.0 * [new tag] 1.4.1 -&gt; 1.4.1 * [new tag] 1.4.2 -&gt; 1.4.2 * [new tag] 1.4.3 -&gt; 1.4.3 * [new tag] 1.5.0 -&gt; 1.5.0 * [new tag] 1.5.1 -&gt; 1.5.1 * [new tag] 1.5.10 -&gt; 1.5.10 * [new tag] 1.5.11 -&gt; 1.5.11 * [new tag] 1.5.12 -&gt; 1.5.12 * [new tag] 1.5.13 -&gt; 1.5.13 * [new tag] 1.5.14 -&gt; 1.5.14 * [new tag] 1.5.2 -&gt; 1.5.2 * [new tag] 1.5.3 -&gt; 1.5.3 * [new tag] 1.5.4 -&gt; 1.5.4 * [new tag] 1.5.5 -&gt; 1.5.5 * [new tag] 1.5.6 -&gt; 1.5.6 * [new tag] 1.5.7 -&gt; 1.5.7 * [new tag] 1.5.8 -&gt; 1.5.8 * [new tag] 1.5.9 -&gt; 1.5.9 * [new tag] 1.6.0 -&gt; 1.6.0 * [new tag] 1.6.1 -&gt; 1.6.1 * [new tag] 1.6.10 -&gt; 1.6.10 * [new tag] 1.6.11 -&gt; 1.6.11 * [new tag] 1.6.12 -&gt; 1.6.12 * [new tag] 1.6.13 -&gt; 1.6.13 * [new tag] 1.6.14 -&gt; 1.6.14 * [new tag] 1.6.15 -&gt; 1.6.15 * [new tag] 1.6.16 -&gt; 1.6.16 * [new tag] 1.6.17 -&gt; 1.6.17 * [new tag] 1.6.2 -&gt; 1.6.2 * [new tag] 1.6.3 -&gt; 1.6.3 * [new tag] 1.6.4 -&gt; 1.6.4 * [new tag] 1.6.5 -&gt; 1.6.5 * [new tag] 1.6.6 -&gt; 1.6.6 * [new tag] 1.6.7 -&gt; 1.6.7 * [new tag] 1.6.8 -&gt; 1.6.8 * [new tag] 1.6.9 -&gt; 1.6.9 * [new tag] 1.7.0 -&gt; 1.7.0 * [new tag] 1.7.1 -&gt; 1.7.1 * [new tag] 1.7.2 -&gt; 1.7.2 * [new tag] 1.7.3 -&gt; 1.7.3 * [new tag] 1.7.4 -&gt; 1.7.4 * [new tag] 1.7.5 -&gt; 1.7.5 * [new tag] 1.7.6 -&gt; 1.7.6HEAD is now at b41d2e525 Merge pull request #4995 from sjackman/gcc==&gt; Homebrew is run entirely by unpaid volunteers. Please consider donating: https://github.com/Homebrew/brew#donations==&gt; Tapping homebrew/coreCloning into &apos;/usr/local/Homebrew/Library/Taps/homebrew/homebrew-core&apos;...remote: Enumerating objects: 4860, done.remote: Counting objects: 100% (4860/4860), done.remote: Compressing objects: 100% (4655/4655), done.remote: Total 4860 (delta 55), reused 343 (delta 15), pack-reused 0Receiving objects: 100% (4860/4860), 4.08 MiB | 870.00 KiB/s, done.Resolving deltas: 100% (55/55), done.Tapped 2 commands and 4646 formulae (4,903 files, 12.7MB).==&gt; Migrating /Library/Caches/Homebrew to /Users/tf/Library/Caches/Homebrew...==&gt; Deleting /Library/Caches/Homebrew...Already up-to-date.==&gt; Installation successful!==&gt; Homebrew has enabled anonymous aggregate formulae and cask analytics.Read the analytics documentation (and how to opt-out) here: https://docs.brew.sh/Analytics.html==&gt; Homebrew is run entirely by unpaid volunteers. Please consider donating: https://github.com/Homebrew/brew#donations==&gt; Next steps:- Run `brew help` to get started- Further documentation: https://docs.brew.sh 使用使用跟其它包管理工具类似，如先查找包keepassxc，然后brew install安装.brew cask 用来安装一些macos app,字体，插件及一些第三方非开源软件。 123456789101112131415161718192021192:~ tf$ brew search keepassxc==&gt; Caskshomebrew/cask/keepassxc192:~ tf$ brew cask install keepassxcUpdating Homebrew...==&gt; Auto-updated Homebrew!Updated 1 tap (homebrew/cask).No changes to formulae.==&gt; Satisfying dependencies==&gt; Downloading https://github.com/keepassxreboot/keepassxc/releases/download/2.3.4/KeePassXC-2.3.4.dmg==&gt; Downloading from https://github-production-release-asset-2e65be.s3.amazonaws.com/52729242/4b068f00-a70b-11e8-9301-d3a2d7e33ccd?X-Amz-Algorithm=AWS4-HMAC-SHA256&amp;X-Amz-Credentia######################################################################## 100.0%==&gt; Verifying SHA-256 checksum for Cask &apos;keepassxc&apos;.==&gt; Installing Cask keepassxc==&gt; Moving App &apos;KeePassXC.app&apos; to &apos;/Applications/KeePassXC.app&apos;.🍺 keepassxc was successfully installed! 参考：Homebrew官方网站 https://brew.sh]]></content>
      <tags>
        <tag>macOS</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ssh免密码登陆的一些注意点]]></title>
    <url>%2F2018%2F08%2F03%2Fssh%E5%85%8D%E5%AF%86%E7%A0%81%E7%99%BB%E9%99%86%E7%9A%84%E4%B8%80%E4%BA%9B%E6%B3%A8%E6%84%8F%E7%82%B9%2F</url>
    <content type="text"><![CDATA[#环境 os: OpenSUSE Tumbleweed pc: Apple macbook 13’ pro 2015 #描述Linux 系统用户免密码使用key登陆有时还会提示要输入密码。 #修复生成key 12345678910111213141516171819202122232425[root@localhost jenkins]# su - jenkins-bash-4.2$ ssh-keyssh-keygen ssh-keyscan -bash-4.2$ ssh-keygen Generating public/private rsa key pair.Enter file in which to save the key (/var/lib/jenkins/.ssh/id_rsa): Created directory &apos;/var/lib/jenkins/.ssh&apos;.Enter passphrase (empty for no passphrase): Enter same passphrase again: Your identification has been saved in /var/lib/jenkins/.ssh/id_rsa.Your public key has been saved in /var/lib/jenkins/.ssh/id_rsa.pub.The key fingerprint is:SHA256:KklV05QIfjCcFfvP7g8id+wfV+DthbY5ojXsLo5hiOM jenkins@localhost.localdomainThe key&apos;s randomart image is:+---[RSA 2048]----+| .++==.. || .o+.oo || o o . || . . . . + || . S . + +|| . o o = . +o|| = o + o @ = o|| . o . =.O + + || E ..o+*oo |+----[SHA256]-----+ 将生成的pubkey文件内容添加到目标主机用户的authorized_keys文件中，可以选择复制或使用下面的方式 1234567891011121314-bash-4.2$ ssh-copy-id -i ~/.ssh/id_rsa.pub git@10.10.105.118/bin/ssh-copy-id: INFO: Source of key(s) to be installed: &quot;/var/lib/jenkins/.ssh/id_rsa.pub&quot;The authenticity of host &apos;10.10.105.118 (10.10.105.118)&apos; can&apos;t be established.ECDSA key fingerprint is SHA256:hKMm0UBSHnJSMJoIW904lN2qhsasOMk8QheyIvYMqzE.ECDSA key fingerprint is MD5:5b:7c:a0:be:50:a8:b3:91:03:2b:e4:2d:de:f5:7b:10.Are you sure you want to continue connecting (yes/no)? yes/bin/ssh-copy-id: INFO: attempting to log in with the new key(s), to filter out any that are already installed/bin/ssh-copy-id: INFO: 1 key(s) remain to be installed -- if you are prompted now it is to install the new keysgit@10.10.105.118&apos;s password: Number of key(s) added: 1Now try logging into the machine, with: &quot;ssh &apos;git@10.10.105.118&apos;&quot;and check to make sure that only the key(s) you wanted were added. 确认已经存在目标主机的authorized_keys文件中后执行登陆操作 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869-bash-4.2$ ssh -v -l git 10.10.105.118 OpenSSH_7.4p1, OpenSSL 1.0.2k-fips 26 Jan 2017debug1: Reading configuration data /etc/ssh/ssh_configdebug1: /etc/ssh/ssh_config line 58: Applying options for *debug1: Connecting to 10.10.105.118 [10.10.105.118] port 22.debug1: Connection established.debug1: identity file /var/lib/jenkins/.ssh/id_rsa type 1debug1: key_load_public: No such file or directorydebug1: identity file /var/lib/jenkins/.ssh/id_rsa-cert type -1debug1: key_load_public: No such file or directorydebug1: identity file /var/lib/jenkins/.ssh/id_dsa type -1debug1: key_load_public: No such file or directorydebug1: identity file /var/lib/jenkins/.ssh/id_dsa-cert type -1debug1: key_load_public: No such file or directorydebug1: identity file /var/lib/jenkins/.ssh/id_ecdsa type -1debug1: key_load_public: No such file or directorydebug1: identity file /var/lib/jenkins/.ssh/id_ecdsa-cert type -1debug1: key_load_public: No such file or directorydebug1: identity file /var/lib/jenkins/.ssh/id_ed25519 type -1debug1: key_load_public: No such file or directorydebug1: identity file /var/lib/jenkins/.ssh/id_ed25519-cert type -1debug1: Enabling compatibility mode for protocol 2.0debug1: Local version string SSH-2.0-OpenSSH_7.4debug1: Remote protocol version 2.0, remote software version OpenSSH_7.4debug1: match: OpenSSH_7.4 pat OpenSSH* compat 0x04000000debug1: Authenticating to 10.10.105.118:22 as &apos;git&apos;debug1: SSH2_MSG_KEXINIT sentdebug1: SSH2_MSG_KEXINIT receiveddebug1: kex: algorithm: curve25519-sha256debug1: kex: host key algorithm: ecdsa-sha2-nistp256debug1: kex: server-&gt;client cipher: chacha20-poly1305@openssh.com MAC: &lt;implicit&gt; compression: nonedebug1: kex: client-&gt;server cipher: chacha20-poly1305@openssh.com MAC: &lt;implicit&gt; compression: nonedebug1: kex: curve25519-sha256 need=64 dh_need=64debug1: kex: curve25519-sha256 need=64 dh_need=64debug1: expecting SSH2_MSG_KEX_ECDH_REPLYdebug1: Server host key: ecdsa-sha2-nistp256 SHA256:hKMm0UBSHnJSMJoIW904lN2qhsasOMk8QheyIvYMqzEdebug1: Host &apos;10.10.105.118&apos; is known and matches the ECDSA host key.debug1: Found key in /var/lib/jenkins/.ssh/known_hosts:1debug1: rekey after 134217728 blocksdebug1: SSH2_MSG_NEWKEYS sentdebug1: expecting SSH2_MSG_NEWKEYSdebug1: SSH2_MSG_NEWKEYS receiveddebug1: rekey after 134217728 blocksdebug1: SSH2_MSG_EXT_INFO receiveddebug1: kex_input_ext_info: server-sig-algs=&lt;rsa-sha2-256,rsa-sha2-512&gt;debug1: SSH2_MSG_SERVICE_ACCEPT receiveddebug1: Authentications that can continue: publickey,gssapi-keyex,gssapi-with-mic,passworddebug1: Next authentication method: gssapi-keyexdebug1: No valid Key exchange contextdebug1: Next authentication method: gssapi-with-micdebug1: Unspecified GSS failure. Minor code may provide more informationNo Kerberos credentials available (default cache: KEYRING:persistent:997)debug1: Unspecified GSS failure. Minor code may provide more informationNo Kerberos credentials available (default cache: KEYRING:persistent:997)debug1: Next authentication method: publickeydebug1: Offering RSA public key: /var/lib/jenkins/.ssh/id_rsadebug1: Server accepts key: pkalg rsa-sha2-512 blen 279debug1: Authentication succeeded (publickey).Authenticated to 10.10.105.118 ([10.10.105.118]:22).debug1: channel 0: new [client-session]debug1: Requesting no-more-sessions@openssh.comdebug1: Entering interactive session.debug1: pledge: networkdebug1: client_input_global_request: rtype hostkeys-00@openssh.com want_reply 0debug1: Sending environment.debug1: Sending env LANG = en_US.UTF-8Last login: Fri Aug 3 02:08:43 2018 from 10.10.105.118 如果多次登陆还是需要密码，确认以下文件的权限是否正确: .ssh目录的权限0600 目标主机的authorized_keys文件权限为0600. 1234567-bash-4.2$ ls -ld .ssh/drwx------. 2 jenkins jenkins 57 Aug 3 02:27 .ssh/-bash-4.2$ ls -l .ssh/total 12-rw-------. 1 jenkins jenkins 1679 Aug 3 02:21 id_rsa-rw-r--r--. 1 jenkins jenkins 411 Aug 3 02:21 id_rsa.pub-rw-r--r--. 1 jenkins jenkins 175 Aug 3 02:27 known_hosts]]></content>
      <tags>
        <tag>openssl</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[音节音标笔记]]></title>
    <url>%2F2018%2F06%2F08%2F%E9%9F%B3%E8%8A%82%E9%9F%B3%E6%A0%87%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[#环境 os: CentOS 7 pc: Apple macbook 13’ pro 2015 #描述 1234567891011121314151617181920212223242526272829303132音位-音节-音素 48个音素(音节的最小单位) - 元音:20 - 单元音:12 - 前元音: /iː/， /ɪ/， /e/， /æ/ - 中元音: /ɜː/， /ə/ - 后元音: /ɑː/， /ʌ/， /ɔː/， /ɒ/，/uː/，/ʊ/ - 双元音(diphthongs):8 - 合口双元音: /aɪ/， /eɪ/， /aʊ/， /əʊ/， /ɔɪ/ - 集中双元音: /ɪə/， /eə/ ，/ʊə/ - 辅音:28 - 清辅音 - 10 - /p/ /t/ /k/ /f/ /s/ /θ/ /ʃ/ /tʃ/ /ts/ /tr/ - 浊辅音 - 10 - /b/ /d/ /g/ /v/ /z/ /ð/ /ʒ/ /dʒ/ /dz/ /dr/ - other:8 - /m/，/n/，/l/，/ŋ/，/h/，/r/，/j/，/w/ 音节(音位的最小结构单位) - 划分音节是按元音来划的,元音音素是构成音节的主体，辅音是音节的分界线 - 元音音素可以构成音节，辅音音素不响亮，不能构成音节。但英语辅音音素中有 4 个辅音[m]，[n]，[ng]，[l]是响音，它们和辅音音素结合，也可构成音节。它们构成的音节往往出现在词尾，一般是非重读音节。 - 音节的核心是元音,元音可以单独构成音节,也可以与辅音字母一起构成音节 - 两元音音素之间有一个辅音音素时，辅音音素归后一音节 - 有两个辅音音素时，一个辅音音素归前一音节，一个归后一音节 - 开音节(以元音字母结束的音节)在开音节中，发音的元音字母发 “字母”本身的音 - 绝对开音节(以发音的元音字母结束的音节) - 相对开音节(元音字母+辅音字母+不发音的e字母) - 闭音节(以一个或几个辅音字母（r 除外）结尾而中间只有一个元音音素的音节)在闭音节中，元音字母不发 “字母”本身的音。 - 重读 指在双音节或多音节词中有一个发音特别响亮的音节 - 非重读]]></content>
      <tags>
        <tag>english</tag>
        <tag>音标</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[yum安装提示NOKEY]]></title>
    <url>%2F2018%2F05%2F31%2Fyum%E5%AE%89%E8%A3%85%E6%8F%90%E7%A4%BAnokey%2F</url>
    <content type="text"><![CDATA[#环境 os: CentOS 7 pc: VirtualBox #故障描述安装过程中已经导入一个PUBKEY,但还是提示NOKEY 1234567891011121314-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------Total 1.5 MB/s | 83 MB 00:00:56 Retrieving key from https://packages.cloud.google.com/yum/doc/yum-key.gpgImporting GPG key 0xA7317B0F: Userid : &quot;Google Cloud Packages Automatic Signing Key &lt;gc-team@google.com&gt;&quot; Fingerprint: d0bc 747f d8ca f711 7500 d6fa 3746 c208 a731 7b0f From : https://packages.cloud.google.com/yum/doc/yum-key.gpgIs this ok [y/N]: yPublic key for 571c54a5e4049647541a24d77337898fb4243f6b39c7f3df5d92ab180055bd87-kubectl-1.10.3-0.x86_64.rpm is not installed Failing package is: kubectl-1.10.3-0.x86_64 GPG Keys are configured as: https://packages.cloud.google.com/yum/doc/yum-key.gpgwarning: /var/cache/yum/x86_64/7/kubernetes/packages/571c54a5e4049647541a24d77337898fb4243f6b39c7f3df5d92ab180055bd87-kubectl-1.10.3-0.x86_64.rpm: Header V4 RSA/SHA512 Signature, key ID 3e1ba8d5: NOKEY #修复查看下载下来的rpm文件的信息 12[root@k8s-node-b pki]# rpm -K /var/cache/yum/x86_64/7/kubernetes/packages/571c54a5e4049647541a24d77337898fb4243f6b39c7f3df5d92ab180055bd87-kubectl-1.10.3-0.x86_64.rpm/var/cache/yum/x86_64/7/kubernetes/packages/571c54a5e4049647541a24d77337898fb4243f6b39c7f3df5d92ab180055bd87-kubectl-1.10.3-0.x86_64.rpm: RSA sha1 ((MD5) PGP) md5 NOT OK (MISSING KEYS: (MD5) PGP#3e1ba8d5) 查看当前系统是否已经导入相应的key文件 123[root@k8s-node-b pki]# rpm -q gpg-pubkey-*gpg-pubkey-f4a80eb5-53a7ff4bgpg-pubkey-ba07f4fb-5ac168db 回看之前安装过程中导入的key与rpm的并不相附,应该是还有key没有导入;查看repo文件 123456789[root@k8s-node-b pki]# cat /etc/yum.repos.d/kubernetes.repo [kubernetes]name=Kubernetesbaseurl=http://yum.kubernetes.io/repos/kubernetes-el7-x86_64enabled=1gpgcheck=1repo_gpgcheck=1gpgkey=https://packages.cloud.google.com/yum/doc/yum-key.gpghttps://packages.cloud.google.com/yum/doc/rpm-package-key.gpg 应该是写入repo文件时换行了,导入没有导入正确的key文件修复repo文件,也可手工导入相应的key文件 12345[root@k8s-node-b pki]# rpm --import https://packages.cloud.google.com/yum/doc/rpm-package-key.gpg[root@k8s-node-b pki]# rpm -q gpg-pubkey-*gpg-pubkey-f4a80eb5-53a7ff4bgpg-pubkey-ba07f4fb-5ac168dbgpg-pubkey-3e1ba8d5-558ab6a8 删除key使用下面的命令 1[root@k8s-node-b pki]# rpm -e --allmatches gpg-pubkey-3e1ba8d5-558ab6a8 重新执行安装 1234567891011121314151617Downloading packages:warning: /var/cache/yum/x86_64/7/kubernetes/packages/571c54a5e4049647541a24d77337898fb4243f6b39c7f3df5d92ab180055bd87-kubectl-1.10.3-0.x86_64.rpm: Header V4 RSA/SHA512 Signature, key ID 3e1ba8d5: NOKEYRetrieving key from https://packages.cloud.google.com/yum/doc/yum-key.gpgImporting GPG key 0xA7317B0F: Userid : &quot;Google Cloud Packages Automatic Signing Key &lt;gc-team@google.com&gt;&quot; Fingerprint: d0bc 747f d8ca f711 7500 d6fa 3746 c208 a731 7b0f From : https://packages.cloud.google.com/yum/doc/yum-key.gpgIs this ok [y/N]: yRetrieving key from https://packages.cloud.google.com/yum/doc/rpm-package-key.gpgImporting GPG key 0x3E1BA8D5: Userid : &quot;Google Cloud Packages RPM Signing Key &lt;gc-team@google.com&gt;&quot; Fingerprint: 3749 e1ba 95a8 6ce0 5454 6ed2 f09c 394c 3e1b a8d5 From : https://packages.cloud.google.com/yum/doc/rpm-package-key.gpgIs this ok [y/N]: yRunning transaction checkRunning transaction testTransaction test succeeded]]></content>
      <tags>
        <tag>yum</tag>
        <tag>gpg</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[kubernetes删除Terminating的pod]]></title>
    <url>%2F2018%2F05%2F29%2Fkubernetes%E5%88%A0%E9%99%A4Terminating%E7%9A%84pod%2F</url>
    <content type="text"><![CDATA[#环境 os: CentOS 7 pc: VirtualBox #描述创建的dashboard pod无法删除 #修复使用–grace-period=0 –force 参数参见官方文档https://kubernetes.io/docs/tasks/run-application/force-delete-stateful-set-pod/ 12345678910111213141516171819202122232425262728293031323334353637[root@k8s-master ~]# kubectl get all -n kube-systemNAME READY STATUS RESTARTS AGEpod/calico-etcd-7jdbr 1/1 Running 0 22hpod/calico-kube-controllers-685755779f-wvh48 1/1 Running 0 22hpod/calico-node-mg7j2 2/2 Running 1 22hpod/calico-node-mjggr 2/2 Running 1 22hpod/etcd-k8s-master 1/1 Running 0 22hpod/kube-apiserver-k8s-master 1/1 Running 0 22hpod/kube-controller-manager-k8s-master 1/1 Running 0 22hpod/kube-dns-86f4d74b45-clw69 2/3 Running 210 22hpod/kube-proxy-jks5s 1/1 Running 0 22hpod/kube-proxy-xl2b7 1/1 Running 0 22hpod/kube-scheduler-k8s-master 1/1 Running 0 22hpod/kubernetes-dashboard-5d676fccd5-2vwnx 1/1 Terminating 77 20hpod/kubernetes-dashboard-7d5dcdb6d9-j7m75 1/1 Terminating 0 21hpod/kubernetes-dashboard-7d5dcdb6d9-lxlvn 1/1 Terminating 11 22hpod/kubernetes-dashboard-f56559df6-4bjj5 1/1 Terminating 205 5h...[root@k8s-master ~]# kubectl -n kube-system delete $(kubectl -n kube-system get pod -o name | grep dashboard) --grace-period=0 --forcewarning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.pod &quot;kubernetes-dashboard-5d676fccd5-2vwnx&quot; deletedpod &quot;kubernetes-dashboard-7d5dcdb6d9-j7m75&quot; deletedpod &quot;kubernetes-dashboard-7d5dcdb6d9-lxlvn&quot; deletedpod &quot;kubernetes-dashboard-f56559df6-4bjj5&quot; deleted[root@k8s-master ~]# kubectl get all -n kube-systemNAME READY STATUS RESTARTS AGEpod/calico-etcd-7jdbr 1/1 Running 0 22hpod/calico-kube-controllers-685755779f-wvh48 1/1 Running 0 22hpod/calico-node-mg7j2 2/2 Running 1 22hpod/calico-node-mjggr 2/2 Running 1 22hpod/etcd-k8s-master 1/1 Running 0 22hpod/kube-apiserver-k8s-master 1/1 Running 0 22hpod/kube-controller-manager-k8s-master 1/1 Running 0 22hpod/kube-dns-86f4d74b45-clw69 2/3 Running 210 22hpod/kube-proxy-jks5s 1/1 Running 0 22hpod/kube-proxy-xl2b7 1/1 Running 0 22hpod/kube-scheduler-k8s-master 1/1 Running 0 22h]]></content>
      <tags>
        <tag>kubernetes</tag>
        <tag>k8s</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[KDE5 konsole终端配置高亮当前tabbar]]></title>
    <url>%2F2018%2F04%2F10%2Fkonsole_tabbar%E9%85%8D%E7%BD%AE%E9%AB%98%E4%BA%AE%E5%BD%93%E5%89%8D%2F</url>
    <content type="text"><![CDATA[#环境 os: OpenSUSE Tumbleweed pc: Apple macbook 13’ pro 2015 #故障描述konsole默认的当前激活tab与非激活tab的区别不是很大,在一些切换的情况下很难一眼分辨出活动tab #修复配置活动tab的底色为绿色,字体加粗 在当前用户的home目录下的.config/konsolerc文件中的TabBar选项中添加如下配置 123tianfei@openSuSeLinux:~&gt; vi .config/konsolerc[TabBar]TabBarStyleSheet=QTabBar::tab &#123; min-width: 2em ; max-width: 25em &#125; QTabBar::tab:selected &#123;font: bold; color: darkblue; background-color: yellowgreen&#125; 还有一种方法是写入一个css文件中,新版本的konsole支持使用style文件,具体写法可参考kde官方文档https://docs.kde.org/stable5/en/applications/konsole/tabbarstylsheet.html如下图所示: 123456haotianfei@tianfei-opensuse:~/github/tianfei/talenhao.github.io.hexo/source/img&gt; cat ~/bin/konsole.cssQTabBar::tab:selected &#123; background: yellowgreen; font: bold; color: darkblue&#125;]]></content>
      <tags>
        <tag>opensuse</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Firefox下载中文名文件为乱码的一种解决方法]]></title>
    <url>%2F2018%2F01%2F25%2FFirefox%E4%B8%8B%E8%BD%BD%E4%B8%AD%E6%96%87%E5%90%8D%E6%96%87%E4%BB%B6%E4%B8%BA%E4%B9%B1%E7%A0%81%E7%9A%84%E4%B8%80%E7%A7%8D%E8%A7%A3%E5%86%B3%E6%96%B9%E6%B3%95%2F</url>
    <content type="text"><![CDATA[#环境 os: OpenSUSE Tumbleweed pc: Apple macbook 13’ pro 2015 #故障描述从百度网盘直接下载的中文pdf文件显示为乱码,具体是显示url编码后的中文名 #修复查看当前目录下的文件 1234567tianfei@openSuSeLinux:~/Downloads/pdf&gt; lltotal 61420-rw-r--r-- 1 tianfei users 12848877 Jan 25 10:10 %5B%E7%91%9E%E5%85%B8%E5%8F%B2%28%E4%B8%8A%E4%B8%8B%E5%86%8C%29%5D.%28%E7%91%9E%E5%85%B8%29%E5%AE%89%E5%BE%B7%E7%94%9F.%E6%89%AB%E6%8F%8F%E7%89%88.pdf-rw-r--r-- 1 tianfei users 6683784 Jan 12 14:52 Docker in Practice.pdf-rw-r--r-- 1 tianfei users 283995 Jan 16 11:50 dotguide.pdf-rw-r--r-- 1 tianfei users 0 Jan 23 11:35 %E6%9C%9D%E9%B2%9C%E7%AE%80%E5%8F%B2.pdf-rw-r--r-- 1 tianfei users 43070424 Jan 19 17:38 亚洲历史 许海山.pdf 其中第一,四个pdf文件显示乱码,写了一个url解码脚本进行修复 1234567891011121314151617(venv3.6) tianfei@openSuSeLinux:~/Downloads/pdf&gt; cat ~/devops/ScriptsForTianfei/decode_urlcode_filename.py#!/usr/bin/env python3# -*- coding:UTF-8 -*-import osimport urllib.parsedef convert_filename(files): for file in files: unquote_file_name = urllib.parse.unquote(file) os.rename(file, unquote_file_name)if __name__ == &apos;__main__&apos;: files = os.listdir() convert_filename(files) 在当前目录下执行脚本之后,文件名显示正确的UTF-8格式 1234567(venv3.6) tianfei@openSuSeLinux:~/Downloads/pdf&gt; lltotal 61420-rw-r--r-- 1 tianfei users 6683784 Jan 12 14:52 Docker in Practice.pdf-rw-r--r-- 1 tianfei users 283995 Jan 16 11:50 dotguide.pdf-rw-r--r-- 1 tianfei users 12848877 Jan 25 10:10 [瑞典史(上下册)].(瑞典)安德生.扫描版.pdf-rw-r--r-- 1 tianfei users 43070424 Jan 19 17:38 亚洲历史 许海山.pdf-rw-r--r-- 1 tianfei users 0 Jan 23 11:35 朝鲜简史.pdf %5B%E7%91%9E%E5%85%B8%E5%8F%B2%28%E4%B8%8A%E4%B8%8B%E5%86%8C%29%5D.%28%E7%91%9E%E5%85%B8%29%E5%AE%89%E5%BE%B7%E7%94%9F.%E6%89%AB%E6%8F%8F%E7%89%88.pdf显示为[瑞典史(上下册)].(瑞典)安德生.扫描版.pdf,%E6%9C%9D%E9%B2%9C%E7%AE%80%E5%8F%B2.pdf显示为朝鲜简史.pdf 脚本下载在我的github： https://github.com/talenhao/ScriptsForTianfei/tree/master/decode_urlcode_filename]]></content>
      <tags>
        <tag>firefox</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[修复opensuse不能进入睡眠模式(suspend)]]></title>
    <url>%2F2018%2F01%2F18%2Ffix_opensuse_tumbleweed_cat_not_suspend%2F</url>
    <content type="text"><![CDATA[#环境 os: OpenSUSE Tumbleweed pc: Apple macbook 13’ pro 2015 #故障描述电源管理设置成合上屏进入睡眠模式,但发现笔记本从包里拿出来时很烫 #修复查看当前唤醒的设备 123456789101112131415tianfei@openSuSeLinux:~&gt; cat /proc/acpi/wakeup Device S-state Status Sysfs nodePEG0 S3 *disabledEC S3 *disabled platform:PNP0C09:00HDEF S3 *disabled pci:0000:00:1b.0RP01 S3 *disabled pci:0000:00:1c.0RP02 S3 *disabled pci:0000:00:1c.1RP03 S4 *disabled pci:0000:00:1c.2ARPT S4 *enabled pci:0000:03:00.0RP05 S3 *disabled pci:0000:00:1c.4RP06 S3 *disabled pci:0000:00:1c.5SPIT S3 *disabled spi:spi-APP000D:00XHC1 S3 *enabled pci:0000:00:14.0ADP1 S3 *disabled platform:ACPI0003:00LID0 S3 *enabled platform:PNP0C0D:00 其中enable的是可执行唤醒的设备,S3 state是suspend的状态.保留使用电源键及开屏唤醒 123456789## disabling wakeup on USB --- use just PWRB#for device in XHC EHC1 EHC2; do grep $device /proc/acpi/wakeup | grep enabled &gt; /dev/null &amp;&amp; &#123; echo Disabling wakeup on $device echo $device &gt; /proc/acpi/wakeup &#125;done 将脚本内容放置在/etc/init.d/boot.local中就可以了. 参考:https://askubuntu.com/questions/552345/can-not-suspend-my-laptop-asus]]></content>
      <tags>
        <tag>opensuse</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[为什么wireshark抓取ethernet II前导8字符与FCS]]></title>
    <url>%2F2017%2F09%2F28%2Fwireshark-preamble-fcs%2F</url>
    <content type="text"><![CDATA[今天使用wireshark抓取frame,对照帧格式发现wireshark抓取出的帧少了两个部分如图:红圈是目标地址,蓝圈是源地址,绿圈是类型(这是ehternet II区别802.3的地方,可以识别上层协议) 查找资料好觉得这篇文章说得很清楚明了(http://blog.sina.com.cn/s/blog_5e8ca2db0100vopc.html) 在物理层上网卡要先去掉前导同步码和帧开始定界符，然后对帧进行CRC检验，如果帧校验和错，就丢弃此帧。如果校验和正确，就判断帧的目 的硬件地址是否符合自己的接收条件（目的地址是自己的物理硬件地址、广播地址、可接收的多播硬件地址等），如果符合，就将帧交“设备驱动程序”做进一步处 理。这时我们的抓包软件才能抓到数据，因此，抓包软件抓到的是去掉前导同步码、帧开始分界符、FCS之外的数据， 帧格式图, 参考:http://blog.sina.com.cn/s/blog_5e8ca2db0100vopc.html]]></content>
      <tags>
        <tag>wireshark</tag>
        <tag>ethernet II frame</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[supervisord 从入门到放弃]]></title>
    <url>%2F2017%2F09%2F27%2Fsupervisor%2F</url>
    <content type="text"><![CDATA[#supervisord 从入门到放弃 Supervisor 在在类UNIX系统上控制进程运行的一个应用.通过fock子进程的方式管理服务的运行,在服务stop时自动重启.这几天简单试用了下supervisord,使用中发现几个问题: 只能支持非后台的进程(they should run in the foreground, not be daemons) 由于是fock的方式管理,只支持由supervisor自己启动的服务,对于已经在线运行的大量服务,不好意思,无法管理.(这个很蛋疼,现网那么多服务,总不能都重启一遍吧?!) 有些服务即使非后台运行,也无法正常操作成功.我试用了使用superviser启动graylog2,使用graylog2的前台运行graylogctl run运行服务. supervisor对服务的侵入性(intrusive)硬伤,目前我用supervisor只能做些简单服务的管理.下一步试下non-intrusive的monit.]]></content>
      <tags>
        <tag>supervisor</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[sublime3光标移动快捷键自定义设置]]></title>
    <url>%2F2017%2F09%2F25%2Fsublime%E5%BF%AB%E6%8D%B7%E9%94%AE%2F</url>
    <content type="text"><![CDATA[在pycharm下setting-keymap下可以设置上下左右移动时的快捷键,人个不太喜欢用上下左右键,手要离开中心区域.为了不冲突,使用shift+vim的移动快捷键设置总是觉得pycharm太重型了,虽然我的笔记本是ssd硬盘,但每次启动时风扇总是运行一下.在众多编辑器中选择了sublime3,安装一些python开发的插件.sublime的设置跟pycharm有很大的不同,在proferences-&gt;key bindings,需要编辑配置文件,不过还算简单,在从左侧的键盘移动键复制到右侧的user配置中,修改成 1234567[ &#123; &quot;keys&quot;: [&quot;ctrl+h&quot;], &quot;command&quot;: &quot;move&quot;, &quot;args&quot;: &#123;&quot;by&quot;: &quot;characters&quot;, &quot;forward&quot;: false&#125; &#125;, &#123; &quot;keys&quot;: [&quot;ctrl+l&quot;], &quot;command&quot;: &quot;move&quot;, &quot;args&quot;: &#123;&quot;by&quot;: &quot;characters&quot;, &quot;forward&quot;: true&#125; &#125;, &#123; &quot;keys&quot;: [&quot;ctrl+k&quot;], &quot;command&quot;: &quot;move&quot;, &quot;args&quot;: &#123;&quot;by&quot;: &quot;lines&quot;, &quot;forward&quot;: false&#125; &#125;, &#123; &quot;keys&quot;: [&quot;ctrl+j&quot;], &quot;command&quot;: &quot;move&quot;, &quot;args&quot;: &#123;&quot;by&quot;: &quot;lines&quot;, &quot;forward&quot;: true&#125; &#125;, ]]]></content>
      <tags>
        <tag>sublime3</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[geymotion2.8 opensuse 启动报错处理]]></title>
    <url>%2F2017%2F09%2F20%2Fgeymotion2.8_opensuse_%E5%90%AF%E5%8A%A8%E6%8A%A5%E9%94%99%E5%A4%84%E7%90%86%2F</url>
    <content type="text"><![CDATA[报错如下: 12htf@linux-rzt3:~/bin/genymotion2.8/genymotion&gt; ./genymotion./genymotion: symbol lookup error: /usr/lib64/libX11.so.6: undefined symbol: xcb_wait_for_reply64 查找了https://stackoverflow.com/questions/40998027/genymotion-genymotion-symbol-lookup-error-usr-lib64-libgl-so-1-undefined删除rm libxcb.so.1可行.同时又报了drm的一个错误,相同 的方法解决 12345678htf@linux-rzt3:~/bin/genymotion2.8/genymotion&gt; rm libxcb.so.1libxcb.so.1htf@linux-rzt3:~/bin/genymotion2.8/genymotion&gt; rm libdrm.so.2libdrm.so.2htf@linux-rzt3:~/bin/genymotion2.8/genymotion&gt; ./genymotionLogging activities to file: /home/htf/.Genymobile/genymotion.logLogging activities to file: /home/htf/.Genymobile/genymotion.logLogging activities to file: /home/htf/.Genymobile/Genymotion/deployed/Google Nexus 5 - 5.1.0 - API 22 - 1080x1920/genymotion-player.log]]></content>
      <tags>
        <tag>genymotion</tag>
        <tag>opensuse</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python3.6 networkx使用pygraphviz绘图报TypeError]]></title>
    <url>%2F2017%2F09%2F13%2Fnetworkx%E4%BD%BF%E7%94%A8pygraphviz%E7%BB%98%E5%9B%BE%E6%8A%A5TypeError%2F</url>
    <content type="text"><![CDATA[报错如下: 123456789101112131415161718Traceback (most recent call last): File &quot;/home/htf/pyproject/sce/ser_con_evo/serconevo/netgraph/__init__.py&quot;, line 139, in &lt;module&gt; main() File &quot;/home/htf/pyproject/sce/ser_con_evo/serconevo/agent/service_collect_agent.py&quot;, line 97, in warper func(*args, **kwargs) File &quot;/home/htf/pyproject/sce/ser_con_evo/serconevo/agent/service_collect_agent.py&quot;, line 320, in warper fun(*args, **kwargs) File &quot;/home/htf/pyproject/sce/ser_con_evo/serconevo/agent/service_collect_agent.py&quot;, line 69, in warper return func(*args, **kwargs) File &quot;/home/htf/pyproject/sce/ser_con_evo/serconevo/agent/service_collect_agent.py&quot;, line 88, in warper func(*args, **kwargs) File &quot;/home/htf/pyproject/sce/ser_con_evo/serconevo/netgraph/__init__.py&quot;, line 124, in main A.draw(&apos;pyv.png&apos;, format=&apos;png&apos;) File &quot;/home/htf/pyproject/sce/lib/python3.6/site-packages/pygraphviz/agraph.py&quot;, line 1474, in draw data = self._run_prog(prog, args) File &quot;/home/htf/pyproject/sce/lib/python3.6/site-packages/pygraphviz/agraph.py&quot;, line 1338, in _run_prog warnings.warn(b&quot;&quot;.join(errors), RuntimeWarning)TypeError: cannot use a string pattern on a bytes-like object 查了下使用的networkx版本,networkx (1.11),networkx在2.0版本才开始支持3.6,怀疑版本问题 NetworkX 2.0 Release date: TBD Support for Python 3.6 added, drop support for Python 3.3. 12345678910111213(sce) htf@linux-rzt3:~/pyproject/sce/ser_con_evo/serconevo/netgraph&gt; pip install networkx==2.0rc1Collecting networkx==2.0rc1 Using cached networkx-2.0rc1.zipRequirement already satisfied: decorator&gt;=4.1.0 in /home/htf/pyproject/sce/lib/python3.6/site-packages (from networkx==2.0rc1)Building wheels for collected packages: networkx Running setup.py bdist_wheel for networkx ... done Stored in directory: /home/htf/.cache/pip/wheels/c9/28/7a/00a40c74cd75194c6997fa7a58f99a6029f0dcb3f2d94ba0daSuccessfully built networkxInstalling collected packages: networkx Found existing installation: networkx 1.11 Uninstalling networkx-1.11: Successfully uninstalled networkx-1.11Successfully installed networkx-2.0rc1 升级完后发现还是报错,查看报错信息,觉得还是跟pygraphviz有关系,升级到最新的1.4rc1,升级进要指定一些参数.默认–library-path获取到的为None,我手工指定路径 1pip install pygraphviz==1.4rc1 --install-option=&quot;--include-path=/usr/include/graphviz&quot; --install-option=&quot;--library-path=/usr/lib64/graphviz/ 再次执行.成功出图.]]></content>
      <tags>
        <tag>pip</tag>
        <tag>python3.6</tag>
        <tag>networkx</tag>
        <tag>pygraphviz</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[pip_install_pygraphviz_cgraph.h_problem]]></title>
    <url>%2F2017%2F09%2F12%2Fpip_install_pygraphviz_cgraph.h_problem%2F</url>
    <content type="text"><![CDATA[pip 安装pygraphviz报出cgraph.h找不到的问题,ubuntu有pygraphviz-dev包,opensuse要使用pygraphviz-devel包 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091929394(v_python3.6) htf@linux-rzt3:/tmp&gt; pip install pygraphvizCollecting pygraphviz Using cached pygraphviz-1.3.1.zipBuilding wheels for collected packages: pygraphviz Running setup.py bdist_wheel for pygraphviz ... error Complete output from command /home/htf/.virtualenvs/v_python3.6/bin/python3.6 -u -c &quot;import setuptools, tokenize;__file__=&apos;/tmp/pip-build-29gpsytb/pygraphviz/setup.py&apos;;f=getattr(tokenize, &apos;open&apos;, open)(__file__);code=f.read().replace(&apos;\r\n&apos;, &apos;\n&apos;);f.close();exec(compile(code, __file__, &apos;exec&apos;))&quot; bdist_wheel -d /tmp/tmpqyu0lzlwpip-wheel- --python-tag cp36: running bdist_wheel running build running build_py creating build creating build/lib.linux-x86_64-3.6 creating build/lib.linux-x86_64-3.6/pygraphviz copying pygraphviz/release.py -&gt; build/lib.linux-x86_64-3.6/pygraphviz copying pygraphviz/__init__.py -&gt; build/lib.linux-x86_64-3.6/pygraphviz copying pygraphviz/graphviz.py -&gt; build/lib.linux-x86_64-3.6/pygraphviz copying pygraphviz/agraph.py -&gt; build/lib.linux-x86_64-3.6/pygraphviz copying pygraphviz/version.py -&gt; build/lib.linux-x86_64-3.6/pygraphviz creating build/lib.linux-x86_64-3.6/pygraphviz/tests copying pygraphviz/tests/test_edge_attributes.py -&gt; build/lib.linux-x86_64-3.6/pygraphviz/tests copying pygraphviz/tests/test_string.py -&gt; build/lib.linux-x86_64-3.6/pygraphviz/tests copying pygraphviz/tests/test_subgraph.py -&gt; build/lib.linux-x86_64-3.6/pygraphviz/tests copying pygraphviz/tests/test_readwrite.py -&gt; build/lib.linux-x86_64-3.6/pygraphviz/tests copying pygraphviz/tests/test_clear.py -&gt; build/lib.linux-x86_64-3.6/pygraphviz/tests copying pygraphviz/tests/test_attribute_defaults.py -&gt; build/lib.linux-x86_64-3.6/pygraphviz/tests copying pygraphviz/tests/test_attributes.py -&gt; build/lib.linux-x86_64-3.6/pygraphviz/tests copying pygraphviz/tests/test_node_attributes.py -&gt; build/lib.linux-x86_64-3.6/pygraphviz/tests copying pygraphviz/tests/test_layout.py -&gt; build/lib.linux-x86_64-3.6/pygraphviz/tests copying pygraphviz/tests/test_graph.py -&gt; build/lib.linux-x86_64-3.6/pygraphviz/tests copying pygraphviz/tests/test.py -&gt; build/lib.linux-x86_64-3.6/pygraphviz/tests copying pygraphviz/tests/__init__.py -&gt; build/lib.linux-x86_64-3.6/pygraphviz/tests copying pygraphviz/tests/test_unicode.py -&gt; build/lib.linux-x86_64-3.6/pygraphviz/tests copying pygraphviz/tests/test_html.py -&gt; build/lib.linux-x86_64-3.6/pygraphviz/tests copying pygraphviz/tests/test_drawing.py -&gt; build/lib.linux-x86_64-3.6/pygraphviz/tests running egg_info writing pygraphviz.egg-info/PKG-INFO writing dependency_links to pygraphviz.egg-info/dependency_links.txt writing top-level names to pygraphviz.egg-info/top_level.txt reading manifest file &apos;pygraphviz.egg-info/SOURCES.txt&apos; reading manifest template &apos;MANIFEST.in&apos; warning: no previously-included files matching &apos;*~&apos; found anywhere in distribution warning: no previously-included files matching &apos;*.pyc&apos; found anywhere in distribution warning: no previously-included files matching &apos;.svn&apos; found anywhere in distribution no previously-included directories found matching &apos;doc/build&apos; writing manifest file &apos;pygraphviz.egg-info/SOURCES.txt&apos; copying pygraphviz/graphviz.i -&gt; build/lib.linux-x86_64-3.6/pygraphviz copying pygraphviz/graphviz_wrap.c -&gt; build/lib.linux-x86_64-3.6/pygraphviz running build_ext building &apos;pygraphviz._graphviz&apos; extension creating build/temp.linux-x86_64-3.6 creating build/temp.linux-x86_64-3.6/pygraphviz gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -fmessage-length=0 -grecord-gcc-switches -O2 -Wall -D_FORTIFY_SOURCE=2 -fstack-protector-strong -funwind-tables -fasynchronous-unwind-tables -g -DOPENSSL_LOAD_CONF -fmessage-length=0 -grecord-gcc-switches -O2 -Wall -D_FORTIFY_SOURCE=2 -fstack-protector-strong -funwind-tables -fasynchronous-unwind-tables -g -fmessage-length=0 -grecord-gcc-switches -O2 -Wall -D_FORTIFY_SOURCE=2 -fstack-protector-strong -funwind-tables -fasynchronous-unwind-tables -g -fPIC -I/usr/include/python3.6m -c pygraphviz/graphviz_wrap.c -o build/temp.linux-x86_64-3.6/pygraphviz/graphviz_wrap.o pygraphviz/graphviz_wrap.c:2954:10: fatal error: graphviz/cgraph.h: No such file or directory #include &quot;graphviz/cgraph.h&quot; ^~~~~~~~~~~~~~~~~~~ compilation terminated. error: command &apos;gcc&apos; failed with exit status 1 ---------------------------------------- Failed building wheel for pygraphviz Running setup.py clean for pygraphvizFailed to build pygraphvizInstalling collected packages: pygraphviz Running setup.py install for pygraphviz ... error Complete output from command /home/htf/.virtualenvs/v_python3.6/bin/python3.6 -u -c &quot;import setuptools, tokenize;__file__=&apos;/tmp/pip-build-29gpsytb/pygraphviz/setup.py&apos;;f=getattr(tokenize, &apos;open&apos;, open)(__file__);code=f.read().replace(&apos;\r\n&apos;, &apos;\n&apos;);f.close();exec(compile(code, __file__, &apos;exec&apos;))&quot; install --record /tmp/pip-aiuj4thp-record/install-record.txt --single-version-externally-managed --compile --install-headers /home/htf/.virtualenvs/v_python3.6/include/site/python3.6/pygraphviz: running install Trying pkg-config Package libcgraph was not found in the pkg-config search path. Perhaps you should add the directory containing `libcgraph.pc&apos; to the PKG_CONFIG_PATH environment variable No package &apos;libcgraph&apos; found Traceback (most recent call last): File &quot;&lt;string&gt;&quot;, line 1, in &lt;module&gt; File &quot;/tmp/pip-build-29gpsytb/pygraphviz/setup.py&quot;, line 87, in &lt;module&gt; tests_require=[&apos;nose&gt;=0.10.1&apos;, &apos;doctest-ignore-unicode&gt;=0.1.0&apos;,], File &quot;/usr/lib64/python3.6/distutils/core.py&quot;, line 148, in setup dist.run_commands() File &quot;/usr/lib64/python3.6/distutils/dist.py&quot;, line 955, in run_commands self.run_command(cmd) File &quot;/usr/lib64/python3.6/distutils/dist.py&quot;, line 974, in run_command cmd_obj.run() File &quot;/tmp/pip-build-29gpsytb/pygraphviz/setup_commands.py&quot;, line 44, in modified_run self.include_path, self.library_path = get_graphviz_dirs() File &quot;/tmp/pip-build-29gpsytb/pygraphviz/setup_extra.py&quot;, line 121, in get_graphviz_dirs include_dirs, library_dirs = _pkg_config() File &quot;/tmp/pip-build-29gpsytb/pygraphviz/setup_extra.py&quot;, line 44, in _pkg_config output = S.check_output([&apos;pkg-config&apos;, &apos;--libs-only-L&apos;, &apos;libcgraph&apos;]) File &quot;/usr/lib64/python3.6/subprocess.py&quot;, line 336, in check_output **kwargs).stdout File &quot;/usr/lib64/python3.6/subprocess.py&quot;, line 418, in run output=stdout, stderr=stderr) subprocess.CalledProcessError: Command &apos;[&apos;pkg-config&apos;, &apos;--libs-only-L&apos;, &apos;libcgraph&apos;]&apos; returned non-zero exit status 1. ----------------------------------------Command &quot;/home/htf/.virtualenvs/v_python3.6/bin/python3.6 -u -c &quot;import setuptools, tokenize;__file__=&apos;/tmp/pip-build-29gpsytb/pygraphviz/setup.py&apos;;f=getattr(tokenize, &apos;open&apos;, open)(__file__);code=f.read().replace(&apos;\r\n&apos;, &apos;\n&apos;);f.close();exec(compile(code, __file__, &apos;exec&apos;))&quot; install --record /tmp/pip-aiuj4thp-record/install-record.txt --single-version-externally-managed --compile --install-headers /home/htf/.virtualenvs/v_python3.6/include/site/python3.6/pygraphviz&quot; failed with error code 1 in /tmp/pip-build-29gpsytb/pygraphviz/ 123456789101112131415161718192021(v_python3.6) htf@linux-rzt3:/tmp&gt; sudo zypper install graphviz-develRetrieving repository &apos;tsinghua-packman&apos; metadata ....................................................................................................................[done]Building repository &apos;tsinghua-packman&apos; cache .........................................................................................................................[done]Loading repository data...Reading installed packages...Resolving package dependencies...The following 56 NEW packages are going to be installed: autoconf automake cairo-devel damageproto-devel fixesproto-devel fontconfig-devel freetype2-devel glib2-devel graphite2-devel graphviz-devel harfbuzz-devel kbproto-devel libbz2-devel libcairo-script-interpreter2 libdrm-devel libexpat-devel libglvnd-devel libicu-devel libjpeg62-devel libLASi1 libLASi-devel libpcrecpp0 libpcreposix0 libpixman-1-0-devel libpng16-compat-devel libpng16-devel libstdc++6-devel-gcc7 libstdc++-devel libtool libX11-devel libXau-devel libxcb-devel libxcb-res0 libxcb-screensaver0 libxcb-xf86dri0 libxcb-xtest0 libxcb-xv0 libxcb-xvmc0 libXdamage-devel libXext-devel libXfixes-devel libXft-devel libXrender-devel libXxf86vm-devel Mesa-libEGL-devel Mesa-libGL-devel pango-devel pcre-devel pthread-stubs-devel renderproto-devel tcl-devel tk-devel xextproto-devel xf86vidmodeproto-devel xproto-devel zlib-develThe following 2 recommended packages were automatically selected: libpng16-compat-devel Mesa-libGL-devel56 new packages to install.Overall download size: 19.3 MiB. Already cached: 0 B. After the operation, additional 104.2 MiB will be used.Continue? [y/n/...? shows all options] (y): y 再次安装成功 1234567(sce) htf@linux-rzt3:~/pyproject/sce/ser_con_evo/pip_download&gt; pip install pygraphviz-1.3.1.zipProcessing ./pygraphviz-1.3.1.zip Requirement already satisfied (use --upgrade to upgrade): pygraphviz==1.3.1 from file:///home/htf/pyproject/sce/ser_con_evo/pip_download/pygraphviz-1.3.1.zip in /home/htf/pyproject/sce/lib/python3.6/site-packagesBuilding wheels for collected packages: pygraphviz Running setup.py bdist_wheel for pygraphviz ... done Stored in directory: /home/htf/.cache/pip/wheels/24/e7/76/6e3ea1649ae65c36eb23a62a319c15fcf568647c0cbe14966bSuccessfully built pygraphviz]]></content>
      <tags>
        <tag>pip</tag>
        <tag>python3.6</tag>
        <tag>pygraphviz</tag>
        <tag>cgraph</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[pip安装psutil报错]]></title>
    <url>%2F2017%2F09%2F05%2Fpip%E5%AE%89%E8%A3%85psutil%E6%8A%A5%E9%94%99%2F</url>
    <content type="text"><![CDATA[123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899(v_python3.6) htf@linux-rzt3:~/PycharmProjects/python3.6/ServiceConnectEvolution&gt; pip install psutilCollecting psutil Using cached psutil-5.3.0.tar.gzBuilding wheels for collected packages: psutil Running setup.py bdist_wheel for psutil ... error Complete output from command /home/htf/.virtualenvs/v_python3.6/bin/python3.6 -u -c &quot;import setuptools, tokenize;__file__=&apos;/tmp/pip-build-dzgqgruh/psutil/setup.py&apos;;f=getattr(tokenize, &apos;open&apos;, open)(__file__);code=f.read().replace(&apos;\r\n&apos;, &apos;\n&apos;);f.close();exec(compile(code, __file__, &apos;exec&apos;))&quot; bdist_wheel -d /tmp/tmpsz_sd5awpip-wheel- --python-tag cp36: running bdist_wheel running build running build_py creating build creating build/lib.linux-x86_64-3.6 creating build/lib.linux-x86_64-3.6/psutil copying psutil/_compat.py -&gt; build/lib.linux-x86_64-3.6/psutil copying psutil/_psosx.py -&gt; build/lib.linux-x86_64-3.6/psutil copying psutil/_psposix.py -&gt; build/lib.linux-x86_64-3.6/psutil copying psutil/_pssunos.py -&gt; build/lib.linux-x86_64-3.6/psutil copying psutil/__init__.py -&gt; build/lib.linux-x86_64-3.6/psutil copying psutil/_psbsd.py -&gt; build/lib.linux-x86_64-3.6/psutil copying psutil/_common.py -&gt; build/lib.linux-x86_64-3.6/psutil copying psutil/_pswindows.py -&gt; build/lib.linux-x86_64-3.6/psutil copying psutil/_pslinux.py -&gt; build/lib.linux-x86_64-3.6/psutil creating build/lib.linux-x86_64-3.6/psutil/tests copying psutil/tests/test_posix.py -&gt; build/lib.linux-x86_64-3.6/psutil/tests copying psutil/tests/test_bsd.py -&gt; build/lib.linux-x86_64-3.6/psutil/tests copying psutil/tests/test_memory_leaks.py -&gt; build/lib.linux-x86_64-3.6/psutil/tests copying psutil/tests/test_connections.py -&gt; build/lib.linux-x86_64-3.6/psutil/tests copying psutil/tests/test_process.py -&gt; build/lib.linux-x86_64-3.6/psutil/tests copying psutil/tests/test_misc.py -&gt; build/lib.linux-x86_64-3.6/psutil/tests copying psutil/tests/test_contracts.py -&gt; build/lib.linux-x86_64-3.6/psutil/tests copying psutil/tests/test_windows.py -&gt; build/lib.linux-x86_64-3.6/psutil/tests copying psutil/tests/test_sunos.py -&gt; build/lib.linux-x86_64-3.6/psutil/tests copying psutil/tests/test_system.py -&gt; build/lib.linux-x86_64-3.6/psutil/tests copying psutil/tests/__main__.py -&gt; build/lib.linux-x86_64-3.6/psutil/tests copying psutil/tests/__init__.py -&gt; build/lib.linux-x86_64-3.6/psutil/tests copying psutil/tests/test_unicode.py -&gt; build/lib.linux-x86_64-3.6/psutil/tests copying psutil/tests/test_osx.py -&gt; build/lib.linux-x86_64-3.6/psutil/tests copying psutil/tests/test_linux.py -&gt; build/lib.linux-x86_64-3.6/psutil/tests running build_ext building &apos;psutil._psutil_linux&apos; extension creating build/temp.linux-x86_64-3.6 creating build/temp.linux-x86_64-3.6/psutil gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -fmessage-length=0 -grecord-gcc-switches -O2 -Wall -D_FORTIFY_SOURCE=2 -fstack-protector-strong -funwind-tables -fasynchronous-unwind-tables -g -DOPENSSL_LOAD_CONF -fmessage-length=0 -grecord-gcc-switches -O2 -Wall -D_FORTIFY_SOURCE=2 -fstack-protector-strong -funwind-tables -fasynchronous-unwind-tables -g -fmessage-length=0 -grecord-gcc-switches -O2 -Wall -D_FORTIFY_SOURCE=2 -fstack-protector-strong -funwind-tables -fasynchronous-unwind-tables -g -fPIC -DPSUTIL_POSIX=1 -DPSUTIL_VERSION=530 -DPSUTIL_LINUX=1 -I/usr/include/python3.6m -c psutil/_psutil_common.c -o build/temp.linux-x86_64-3.6/psutil/_psutil_common.o psutil/_psutil_common.c:9:10: fatal error: Python.h: No such file or directory #include &lt;Python.h&gt; ^~~~~~~~~~ compilation terminated. error: command &apos;gcc&apos; failed with exit status 1 ---------------------------------------- Failed building wheel for psutil Running setup.py clean for psutilFailed to build psutilInstalling collected packages: psutil Running setup.py install for psutil ... error Complete output from command /home/htf/.virtualenvs/v_python3.6/bin/python3.6 -u -c &quot;import setuptools, tokenize;__file__=&apos;/tmp/pip-build-dzgqgruh/psutil/setup.py&apos;;f=getattr(tokenize, &apos;open&apos;, open)(__file__);code=f.read().replace(&apos;\r\n&apos;, &apos;\n&apos;);f.close();exec(compile(code, __file__, &apos;exec&apos;))&quot; install --record /tmp/pip-h40wc998-record/install-record.txt --single-version-externally-managed --compile --install-headers /home/htf/.virtualenvs/v_python3.6/include/site/python3.6/psutil: running install running build running build_py creating build creating build/lib.linux-x86_64-3.6 creating build/lib.linux-x86_64-3.6/psutil copying psutil/_compat.py -&gt; build/lib.linux-x86_64-3.6/psutil copying psutil/_psosx.py -&gt; build/lib.linux-x86_64-3.6/psutil copying psutil/_psposix.py -&gt; build/lib.linux-x86_64-3.6/psutil copying psutil/_pssunos.py -&gt; build/lib.linux-x86_64-3.6/psutil copying psutil/__init__.py -&gt; build/lib.linux-x86_64-3.6/psutil copying psutil/_psbsd.py -&gt; build/lib.linux-x86_64-3.6/psutil copying psutil/_common.py -&gt; build/lib.linux-x86_64-3.6/psutil copying psutil/_pswindows.py -&gt; build/lib.linux-x86_64-3.6/psutil copying psutil/_pslinux.py -&gt; build/lib.linux-x86_64-3.6/psutil creating build/lib.linux-x86_64-3.6/psutil/tests copying psutil/tests/test_posix.py -&gt; build/lib.linux-x86_64-3.6/psutil/tests copying psutil/tests/test_bsd.py -&gt; build/lib.linux-x86_64-3.6/psutil/tests copying psutil/tests/test_memory_leaks.py -&gt; build/lib.linux-x86_64-3.6/psutil/tests copying psutil/tests/test_connections.py -&gt; build/lib.linux-x86_64-3.6/psutil/tests copying psutil/tests/test_process.py -&gt; build/lib.linux-x86_64-3.6/psutil/tests copying psutil/tests/test_misc.py -&gt; build/lib.linux-x86_64-3.6/psutil/tests copying psutil/tests/test_contracts.py -&gt; build/lib.linux-x86_64-3.6/psutil/tests copying psutil/tests/test_windows.py -&gt; build/lib.linux-x86_64-3.6/psutil/tests copying psutil/tests/test_sunos.py -&gt; build/lib.linux-x86_64-3.6/psutil/tests copying psutil/tests/test_system.py -&gt; build/lib.linux-x86_64-3.6/psutil/tests copying psutil/tests/__main__.py -&gt; build/lib.linux-x86_64-3.6/psutil/tests copying psutil/tests/__init__.py -&gt; build/lib.linux-x86_64-3.6/psutil/tests copying psutil/tests/test_unicode.py -&gt; build/lib.linux-x86_64-3.6/psutil/tests copying psutil/tests/test_osx.py -&gt; build/lib.linux-x86_64-3.6/psutil/tests copying psutil/tests/test_linux.py -&gt; build/lib.linux-x86_64-3.6/psutil/tests running build_ext building &apos;psutil._psutil_linux&apos; extension creating build/temp.linux-x86_64-3.6 creating build/temp.linux-x86_64-3.6/psutil gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -fmessage-length=0 -grecord-gcc-switches -O2 -Wall -D_FORTIFY_SOURCE=2 -fstack-protector-strong -funwind-tables -fasynchronous-unwind-tables -g -DOPENSSL_LOAD_CONF -fmessage-length=0 -grecord-gcc-switches -O2 -Wall -D_FORTIFY_SOURCE=2 -fstack-protector-strong -funwind-tables -fasynchronous-unwind-tables -g -fmessage-length=0 -grecord-gcc-switches -O2 -Wall -D_FORTIFY_SOURCE=2 -fstack-protector-strong -funwind-tables -fasynchronous-unwind-tables -g -fPIC -DPSUTIL_POSIX=1 -DPSUTIL_VERSION=530 -DPSUTIL_LINUX=1 -I/usr/include/python3.6m -c psutil/_psutil_common.c -o build/temp.linux-x86_64-3.6/psutil/_psutil_common.o psutil/_psutil_common.c:9:10: fatal error: Python.h: No such file or directory #include &lt;Python.h&gt; ^~~~~~~~~~ compilation terminated. error: command &apos;gcc&apos; failed with exit status 1 ----------------------------------------Command &quot;/home/htf/.virtualenvs/v_python3.6/bin/python3.6 -u -c &quot;import setuptools, tokenize;__file__=&apos;/tmp/pip-build-dzgqgruh/psutil/setup.py&apos;;f=getattr(tokenize, &apos;open&apos;, open)(__file__);code=f.read().replace(&apos;\r\n&apos;, &apos;\n&apos;);f.close();exec(compile(code, __file__, &apos;exec&apos;))&quot; install --record /tmp/pip-h40wc998-record/install-record.txt --single-version-externally-managed --compile --install-headers /home/htf/.virtualenvs/v_python3.6/include/site/python3.6/psutil&quot; failed with error code 1 in /tmp/pip-build-dzgqgruh/psutil/ 缺少Python.h 12345678910htf@linux-rzt3: ~ &gt; sudo zypper install python3-devel(v_python3.6) htf@linux-rzt3:~/PycharmProjects/python3.6/ServiceConnectEvolution&gt; pip install psutilCollecting psutil Using cached psutil-5.3.0.tar.gzBuilding wheels for collected packages: psutil Running setup.py bdist_wheel for psutil ... done Stored in directory: /home/htf/.cache/pip/wheels/ba/1d/54/5954c0b7822f7135fe793c08aadc423513bda607782235e33fSuccessfully built psutilInstalling collected packages: psutilSuccessfully installed psutil-5.3.0]]></content>
      <tags>
        <tag>python</tag>
        <tag>pip</tag>
        <tag>psutil</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[pip_require_tls_ssl问题]]></title>
    <url>%2F2017%2F09%2F05%2Fpip_require_tls_ssl%E9%97%AE%E9%A2%98%2F</url>
    <content type="text"><![CDATA[salt推送报pip is configured with locations that require TLS/SSL, however the ssl module in Python is not available. 123456789101112131415161718192021222324252627cmd_|-python_requirements_|-/usr/local/_python3.6.1/bin/pip3 install -r sce_requirements.txt_|-run: ---------- __run_num__: 5 changes: ---------- pid: 26431 retcode: 1 stderr: pip is configured with locations that require TLS/SSL, however the ssl module in Python is not available. Could not find a version that satisfies the requirement psutil==5.3.0 (from -r sce_requirements.txt (line 1)) (from versions: ) No matching distribution found for psutil==5.3.0 (from -r sce_requirements.txt (line 1)) stdout: Collecting psutil==5.3.0 (from -r sce_requirements.txt (line 1)) Could not fetch URL https://pypi.python.org/simple/psutil/: There was a problem confirming the ssl certificate: Can&apos;t connect to HTTPS URL because the SSL module is not available. - skipping comment: Command &quot;/usr/local/_python3.6.1/bin/pip3 install -r sce_requirements.txt&quot; run duration: 514.995 name: /usr/local/_python3.6.1/bin/pip3 install -r sce_requirements.txt result: False start_time: 20:13:40.393491 应该是openssl相关的包有问题 12[root@192_168_1_1 bin]# rpm -qa |grep opensslopenssl-1.0.1e-57.el6.x86_64 没有devel包 1# yum install -y openssl-devel]]></content>
      <tags>
        <tag>python</tag>
        <tag>pip</tag>
        <tag>psutil</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[minikube安装试用]]></title>
    <url>%2F2017%2F09%2F03%2Fkubernetes%E6%89%8B%E5%8A%A8%E5%AE%89%E8%A3%85%2F</url>
    <content type="text"><![CDATA[下载kubernetes源码包 123[root@localhost ~]# cd /usr/local/src/[root@localhost src]# yum install unzip wget[root@localhost src]# wget https://github.com/kubernetes/kubernetes/archive/v1.7.5.zip]]></content>
      <tags>
        <tag>kubernetes</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[elasticsearch_request_time_collect]]></title>
    <url>%2F2017%2F08%2F19%2Felasticsearch_request_time_collect%2F</url>
    <content type="text"><![CDATA[elasticsearch_request_time_collecthttps://github.com/talenhao/elasticsearch_request_time_collect收集es中指定索引中的所有request_time及request字段,并处理成报表. elasticsearch_request_time_collect脚本使用说明激活python环境source /virtual_python3.6.1/bin/activate 用法：123456789/elasticsearch_request_time_collect.py [--命令选项] [参数]命令选项： --help, -H 帮助 --version, -V 输出版本号 --index-regex -i 索引,支持正则 eg:in.access.log --date, -d 收集的日期 eg:2017.08.16 --es-ip -h Elasticsearch IP地址 --es-port -p Elasticsearch 端口 默认参数为:12345# default argses_host = &quot;192.168.1.1&quot;es_port = &apos;9200&apos;search_date = todayindex_regex = &quot;*access.log&quot; eg:12345678910time python elasticsearch_request_time_collect.py -i *access.log -d 2017.08.16 -h 192.168.1.1...api: &apos;/adfafaf/sfdaf&apos;api: &apos;/client/timeline/hadfasfafafasf&apos;api: &apos;/client/adfasfsafasfasfasfaf&apos;real 0m32.262suser 0m25.998ssys 0m1.919s]]></content>
      <tags>
        <tag>elasticsearch</tag>
        <tag>nginx</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[rundeck日报发送脚本]]></title>
    <url>%2F2017%2F08%2F19%2FRundeckJobResult%2F</url>
    <content type="text"><![CDATA[RundeckJobResult rundeck 日报发送脚本使用指南 收集rundeck任务运行结果并做个报表,日报,发送邮件给指定联系人.* source ~/.virtualenvs/rundeck3.6/bin/activate usage12345678910111213用法：RdJobResult.py [--命令选项] [参数]命令选项： --help, -h 帮助。 --version, -V 输出版本号。 --mailaddr, -m 用户名@邮件域名,用户名@邮件域名,... 接收邮件的地址。eg: python3.6 rundeck_job_status.py -m talenhao@gmail.com,talenhao2@gmail.com,... log文件 /tmp/rundeck_job_status.py.log.${date},${hour.min} eg: /tmp/rundeck_job_status.py.log.2017-06-27,16.22 在rundeck上做成一个job每日23:59分执行 邮件内容 订阅 说明 常规订阅: 如果需要添加日报订阅者，直接rundeck_result.start任务，option上添加订阅者邮箱即可，使用”,”号分割。 临时订阅: 如果是临时订阅，在任务运行界面mailto参数上点击”New Value”，输入订阅者邮件地址。]]></content>
      <tags>
        <tag>rundeck</tag>
        <tag>ETL</tag>
      </tags>
  </entry>
</search>
